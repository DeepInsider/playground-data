{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf2-keras-regression.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMk02HwYE66yHbUBk8q5DGw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeepInsider/playground-data/blob/master/docs/articles/tf2_keras_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgg9EBlaZvlL",
        "colab_type": "text"
      },
      "source": [
        "##### Copyright 2020 Digital Advantage - Deep Insider."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEOZOBUCZmIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9f3P9vJa_ny",
        "colab_type": "text"
      },
      "source": [
        "# 「回帰問題（全1回）」 ― 連載『TensorFlow 2.0＋Keras（ tf.keras）入門』のノートブック（3）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FPq6jqNbbRF",
        "colab_type": "text"
      },
      "source": [
        "<table valign=\"middle\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.atmarkit.co.jp/ait/subtop/features/di/tf2keras_index.html\"> <img src=\"https://re.deepinsider.jp/img/ml-logo/manabu.svg\"/>Deep Insiderで記事を読む</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/DeepInsider/playground-data/blob/master/docs/articles/tf2_keras_regression.ipynb\"> <img src=\"https://re.deepinsider.jp/img/ml-logo/gcolab.svg\" />Google Colabで実行する</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/DeepInsider/playground-data/blob/master/docs/articles/tf2_keras_regression.ipynb\"> <img src=\"https://re.deepinsider.jp/img/ml-logo/github.svg\" />GitHubでソースコードを見る</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPxuZnIgbi5g",
        "colab_type": "text"
      },
      "source": [
        "※上から順に実行してください。上のコードで実行したものを再利用しているところがあるため、すべて実行しないとエラーになるコードがあります。  \n",
        "　すべてのコードを一括実行したい場合は、メニューバーから［ランタイム］－［すべてのセルを実行］をクリックしてください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQ5Dbdm7bkxF",
        "colab_type": "text"
      },
      "source": [
        "※「Python 3」を利用してください。  \n",
        "　Python 3を利用するには、メニューバーから［ランタイム］－［ランタイムのタイプを変更］を選択すると表示される［ノートブックの設定］ダイアログの、［ランタイムのタイプ］欄で「Python 3」に選択し、その右下にある［保存］ボタンをクリックしてください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYonXhqkb5JO",
        "colab_type": "text"
      },
      "source": [
        "# 第7回　回帰問題をディープラーニング（基本のDNN）で解こう"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZnbsnJncAKQ",
        "colab_type": "text"
      },
      "source": [
        "## ■本稿の目的と方針"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OOY3rbJcDFT",
        "colab_type": "text"
      },
      "source": [
        "ディープラーニングの基本形である「DNN（ディープニューラルネットワーク」をTensorFlow 2.xで実装する方法を示す。これにより、連載第1回～第3回ですでに身に付けたニューラルネットワーク＆ディープラーニングの知識だけでも、さまざまな機械学習が行えることを確認する。\n",
        "\n",
        "- 前提知識は、基本的なニューラルネットワークを組めること。具体的には『[TensorFlow 2＋Keras（tf.keras）入門 - ＠IT](https://www.atmarkit.co.jp/ait/subtop/features/di/tf2keras_index.html)』の第1回～第6回の知識レベルが必要\n",
        "- 今回の課題： 「マルチガウシアン」座標点データセット（後述）の推論を、第1回～第3回のDNN知識および、第4回～第6回の書き方の知識だけで解決してみよう\n",
        "- 第1回～第3回は、これまでのSequentialモデルではなく、サブクラスモデル（Subclassing API）で実装する（学習／訓練は、カスタムループではなく、簡単に利用できる`compile()`＆`fit()`メソッドを利用する）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2ZZrCd9cxJU",
        "colab_type": "text"
      },
      "source": [
        "## ■本稿で説明する大まかな流れ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qy0qGfJGcy6u",
        "colab_type": "text"
      },
      "source": [
        "- （0）本ノートブックを実行するための事前準備\n",
        "- （1）データの準備\n",
        "- （2）モデルの定義\n",
        "- （3）学習／最適化（オプティマイザー）\n",
        "- （4）評価／精度検証\n",
        "- （5）推論／未知データによるテスト"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNqkjmv5dokQ",
        "colab_type": "text"
      },
      "source": [
        "## ■（0）本ノートブックを実行するための事前準備"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fap2oUjZd9AC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Google Colabで最新の2.xを使う場合、2.xに切り替える（Colab専用）\n",
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ash0jDJkdziw",
        "colab_type": "text"
      },
      "source": [
        "### ●前提条件"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEBGZlmJc16X",
        "colab_type": "text"
      },
      "source": [
        "### 【チェック】Pythonバージョン（※3系を使うこと）\n",
        "Colabにインストール済みのものを使う。もし2系になっている場合は、メニューバーの［ランタイム］－［ランタイムのタイプを変更］をクリックして切り替えてほしい。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2t7XPyFbc4Wh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "print('Python', sys.version)\n",
        "# Python 3.6.9 (default, Apr 18 2020, 01:56:04)   …… などと表示される"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wgd5Lomrc6M7",
        "colab_type": "text"
      },
      "source": [
        "### 【チェック】TensorFlowバージョン（※2系を使うこと）\n",
        "基本的にはColabにインストール済みのものを使う。もし2系になっている場合は、リスト4-0を実行してバージョン2.0を使う。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VR4lIe01c8IX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "print('TensorFlow', tf.__version__)\n",
        "# TensorFlow 2.2.0 ……などと表示される"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgOpPdrEc_Wu",
        "colab_type": "text"
      },
      "source": [
        "### リスト0-1　［オプション］ライブラリ「TensorFlow」最新バージョンのインストール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JUkOoiGdIYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Google Colabで最新の2.xを使う場合（Colab専用）\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "# 最新バージョンにアップグレードする場合\n",
        "!pip install --upgrade tensorflow\n",
        "\n",
        "# バージョンを明示してアップグレードする場合\n",
        "#!pip install --upgrade tensorflow===2.1.0\n",
        "\n",
        "# 最新バージョンをインストールする場合\n",
        "#!pip install tensorflow\n",
        "\n",
        "# バージョンを明示してインストールする場合\n",
        "#!pip install tensorflow===2.1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0bzDzHsdG7X",
        "colab_type": "text"
      },
      "source": [
        "### ［オプション］【チェック】TensorFlowバージョン（※インストール後の確認）\n",
        "バージョン2.xになっているか再度チェックする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5jv2PVmeKKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "print('TensorFlow', tf.__version__)\n",
        "# TensorFlow 2.2.0 ……などと表示される"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-58AiIA-eyd9",
        "colab_type": "text"
      },
      "source": [
        "## ■（1）データの準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i9hnIbWe02L",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "「[第1回　初めてのニューラルネットワーク実装、まずは準備をしよう ― 仕組み理解×初実装（前編）：TensorFlow 2＋Keras（tf.keras）入門 - ＠IT](https://www.atmarkit.co.jp/ait/articles/1909/19/news026.html)」の記事と同じように、シンプルな座標点データを生成して使う。具体的には「マルチガウシアン」の座標点データセットとして「[playground-data · PyPI](https://pypi.org/project/playground-data/)」を使用する。playground-dataパッケージの使い方は、前述の記事を参照してほしい。\n",
        "\n",
        "なお、座標点データは、「[ニューラルネットワーク Playground - Deep Insider](https://deepinsider.github.io/playground/)」（以下、Playground）と同じ生成仕様となっている。\n",
        "\n",
        "![「マルチガウシアン」座標点データセットの例](https://image.itmedia.co.jp/ait/articles/1909/19/l_di-02-4.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9C1oBOIGgMqy",
        "colab_type": "text"
      },
      "source": [
        "#### リスト1-1　ライブラリ「playground-data」のインストール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMi01mjdgXYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 座標点データを生成するライブラリのインストール\n",
        "!pip install playground-data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4X_KhJK6Ehbk",
        "colab_type": "text"
      },
      "source": [
        "### リスト1-2　「マルチガウシアン」座標点データの生成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJdufL5_gSFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# playground-dataライブラリのplygdataパッケージを「pg」という別名でインポート\n",
        "import plygdata as pg\n",
        "\n",
        "# 設定値を定数として定義\n",
        "PROBLEM_DATA_TYPE = pg.DatasetType.RegressGaussian # 問題種別：「回帰（Regress）」、データ種別：「マルチガウシアン（Gaussian）」を選択\n",
        "TRAINING_DATA_RATIO = 0.5  # データの何％を訓練【Training】用に？ (残りは精度検証【Validation】用) ： 50％\n",
        "DATA_NOISE = 0.0           # ノイズ： 0％\n",
        "\n",
        "# 定義済みの定数を引数に指定して、データを生成する\n",
        "data_list = pg.generate_data(PROBLEM_DATA_TYPE, DATA_NOISE)\n",
        "\n",
        "# データを「訓練用」と「精度検証用」を指定の比率で分割し、さらにそれぞれを「データ（X）」と「教師ラベル（y）」に分ける\n",
        "X_train, y_train, X_valid, y_valid = pg.split_data(data_list, training_size=TRAINING_DATA_RATIO)\n",
        "\n",
        "# データ分割後の各変数の内容例として、それぞれ5件ずつ出力（※出力内容は実行ごとに異なる）\n",
        "print('X_train:'); print(X_train[:5]) # [[-2.38054557 -4.32394847], ……]\n",
        "print('y_train:'); print(y_train[:5]) # [[ 0.        ], [-0.2487588 ], ……]\n",
        "print('X_valid:'); print(X_valid[:5]) # [[-0.02550047 -0.53284492], ……]\n",
        "print('y_valid:'); print(y_valid[:5]) # [[ 0.01633982], [ 0.        ], ……]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uliiZwxLEsOh",
        "colab_type": "text"
      },
      "source": [
        "### リスト1-3　入力データの描画"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyDL2sPJkpEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pg.plot_points_with_playground_style(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I103gDcNhzaJ",
        "colab_type": "text"
      },
      "source": [
        "このコードのポイント：\n",
        "\n",
        "- 「マルチガウシアン」座標点データセットは、前述したPyPIパッケージ「playground-data」（別名として`pg`を定義）の[`pg.generate_data()`関数](https://github.com/DeepInsider/playground-data/blob/master/plygdata/dataset.py#L101)で取得できる\n",
        "- `generate_data(PROBLEM_DATA_TYPE, DATA_NOISE)`関数の、第1引数には[`pg.DatasetType`クラス変数](https://github.com/DeepInsider/playground-data/blob/master/plygdata/state.py#L36)で問題種別を、第2引数にはfloat値で座標点生成時のノイズを指定する。戻り値は［X座標、Y座標、正解ラベル］が1200件（回帰の場合。分類の場合は500件）ほど格納されたPython多次元リストとなっている\n",
        "- この座標点データを訓練用と精度検証用に分割したい場合は、[`pg.split_data(data_list, training_size=TRAINING_DATA_RATIO)`関数](https://github.com/DeepInsider/playground-data/blob/master/plygdata/datahelper.py#L34)を使えばよい。第1引数には先ほど生成したPython多次元リストを、引数`training_size`にはfloat値で訓練用データの割合を指定すればよい。\n",
        "- 座標点データのサンプル出力では、グラフ描画用の`pg.plot_points_with_playground_style(X_train, y_train)`関数を利用している。第1引数に訓練用データの入力データ（＝特徴量）を、第2引数には訓練用データのラベルを指定する。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgQ85AFymIBh",
        "colab_type": "text"
      },
      "source": [
        "### ●バッチデータの作成について\n",
        "\n",
        "今回は、tf.kerasの基本である`compile()`＆`fit()`メソッドを使用する。その場合、`fit()`メソッドがデータをミニバッチ学習用に自動分割したり、トレーニング時にエポックごとのループ処理を自動的に行ってくれたりするため、手動でバッチデータ化する必要がない。そのため、本ノートブックでは「バッチデータの作成」は割愛する。\n",
        "\n",
        "なお、エキスパート向けである「`tf.GradientTape`クラスを使ったカスタムループ」を実装する場合は、バッチデータを作成する必要がある。その方法は、「[第5回　お勧めの、TensorFlow 2.0最新の書き方入門（エキスパート向け） (2ページ目)](https://www.atmarkit.co.jp/ait/articles/2003/10/news016_2.html)」で説明している。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uWEXF8lmh8s",
        "colab_type": "text"
      },
      "source": [
        "## ■（2）モデルの定義"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ce8AGCumn-9",
        "colab_type": "text"
      },
      "source": [
        "既に何度か説明しているが、以下の通りで進めていく。\n",
        "- `tf.keras.Model`クラスを**サブクラス化**してモデルを定義する（**初中級者以上にお勧め**）\n",
        "- tf.kerasの基本である`compile()`＆`fit()`メソッドを使用する（今回はカスタムループの実装は不要なため）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SruJESirhjCH",
        "colab_type": "text"
      },
      "source": [
        "### ●ディープニューラルネットワークのモデル設計\n",
        "- 入力の数（`INPUT_FEATURES`）は、$X_1$と$X_2$で**2つ**\n",
        "- 隠れ層のレイヤー数は、**2つ**\n",
        "  - 隠れ層にある1つ目のニューロンの数（`LAYER1_NEURONS`）は、**4つ**\n",
        "  - 隠れ層にある2つ目のニューロンの数（`LAYER2_NEURONS`）は、**3つ**\n",
        "- 出力層にあるニューロンの数（`OUTPUT_RESULTS`）は、**1つ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gn6Ha0DVzb66",
        "colab_type": "text"
      },
      "source": [
        "### リスト2-1　モデルの定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWnt6R4qexwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf  # ライブラリ「TensorFlow」のtensorflowパッケージをインポート\n",
        "from tensorflow.keras import layers       # 「レイヤーズ」モジュールのインポート\n",
        "from IPython.display import Image\n",
        "\n",
        "\n",
        "# 定数（モデル定義時に必要となるもの）\n",
        "INPUT_FEATURES = 2    # 入力（特徴）の数： 2（＝X座標とY座標）\n",
        "LAYER1_NEURONS = 4    # ニューロンの数： 4\n",
        "LAYER2_NEURONS = 3    # ニューロンの数： 3\n",
        "OUTPUT_RESULTS = 1    # 出力結果の数： 1（＝結果は基本的に「-1.0」～「1.0」の数値）\n",
        "\n",
        "# 変数（モデル定義時に必要となるもの）\n",
        "activation1 = layers.Activation('tanh' # 活性化関数（隠れ層用）： tanh関数（変更可能）\n",
        "    , name='activation1'               # 名前付け\n",
        "    )\n",
        "activation2 = layers.Activation('tanh' # 活性化関数（隠れ層用）： tanh関数（変更可能）\n",
        "    , name='activation2'               \n",
        "    )\n",
        "acti_out = layers.Activation('linear'  # 活性化関数（出力層用）： そのまま出力（固定）\n",
        "    , name='acti_out'                  \n",
        "    )\n",
        "\n",
        "# tf.keras.Modelによるモデルの定義\n",
        "class NeuralNetwork(tf.keras.Model):\n",
        "\n",
        "  # ### レイヤーを定義 ###\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "\n",
        "    # 入力層は定義「不要」。実際の入力によって決まるので\n",
        "\n",
        "    # 隠れ層：1つ目のレイヤー（layer）\n",
        "    self.layer1 = layers.Dense(    # 全結合層（線形変換）\n",
        "      #input_shape=(INPUT_FEATURES,),  # 入力層（定義不要）\n",
        "      LAYER1_NEURONS,              # 次のレイヤーへの出力ユニット数\n",
        "      name='layer1')\n",
        "\n",
        "    # 隠れ層：2つ目のレイヤー（layer）\n",
        "    self.layer2 = layers.Dense(    # 全結合層\n",
        "      LAYER2_NEURONS,              # 次のレイヤーへの出力ユニット数\n",
        "      name='layer2')\n",
        "\n",
        "    # 出力層\n",
        "    self.layer_out = layers.Dense( # 全結合層\n",
        "      OUTPUT_RESULTS,              # 出力結果への出力ユニット数\n",
        "      name='layer_out')\n",
        "\n",
        "  # ### フォワードパスを定義 ###\n",
        "  def call(self, inputs, training=None):   # 入力と、訓練／評価モード\n",
        "    # 「出力＝活性化関数（第n層（入力））」の形式で記述\n",
        "    x1 = activation1(self.layer1(inputs))  # 活性化関数は変数として定義\n",
        "    x2 = activation2(self.layer2(x1))      # 同上\n",
        "    outputs = acti_out(self.layer_out(x2)) # そのまま出力（＝「恒等関数」）\n",
        "    return outputs\n",
        "\n",
        "  # モデル内容の出力を行う独自メソッド\n",
        "  def get_functional_model(self):\n",
        "    x = layers.Input(shape=(INPUT_FEATURES,), name='input_features')\n",
        "    static_model = tf.keras.Model(inputs=[x], outputs=self.call(x)) \n",
        "    return static_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2Ly2Prnm-2K",
        "colab_type": "text"
      },
      "source": [
        "このコードのポイント：\n",
        "- このコードは、「[第5回　お勧めの、TensorFlow 2.0最新の書き方入門（エキスパート向け） (1/2)：TensorFlow 2＋Keras（tf.keras）入門 - ＠IT](https://www.atmarkit.co.jp/ait/articles/2003/10/news016.html)」で説明したものとほぼ同じ書き方（サブクラス型）である\n",
        "- ニューラルネットワークモデルの定義方法は、「[第2回　ニューラルネットワーク最速入門 ― 仕組み理解×初実装（中編）：TensorFlow 2＋Keras（tf.keras）入門 - ＠IT](https://www.atmarkit.co.jp/ait/articles/1910/17/news026.html)」で説明した通り\n",
        "- 隠れ層の活性化関数は、今回も[Tanh関数](https://www.atmarkit.co.jp/ait/articles/2003/19/news015.html)を使用した。これはオレンジ色（＝-1.0）～青色（＝1.0）の範囲で数値を出力できるためである。より一般的な[ReLU関数](https://www.atmarkit.co.jp/ait/articles/2003/11/news016.html)（`\"relu\"`という文字列を指定）を使ってもよい\n",
        "- 出力層の活性化関数は、今回は[線形関数（＝恒等関数）](https://www.atmarkit.co.jp/ait/articles/2004/01/news045.html)を指定している。この関数はそのまま出力するという意味なので、活性化関数自体は使わなくても同じ意味となる\n",
        "- `get_functional_model()`メソッドは、次のリスト2-2でモデル内容を描画するために用意した独自の関数である（本来の処理には不要）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfdhd4ohzh1Q",
        "colab_type": "text"
      },
      "source": [
        "### リスト2-2　モデル内容（テキスト）の確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--HUU8B-E6d0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# モデル（NeuralNetworkクラス）のインスタンス化\n",
        "model = NeuralNetwork()\n",
        "f_model = model.get_functional_model()\n",
        "f_model.summary() # モデルの内容を出力"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBIjx5i1E9N1",
        "colab_type": "text"
      },
      "source": [
        "### リスト2-3　モデル内容（図）の確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgoeOvvxnArM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# モデル概要の図を描画する\n",
        "filename = 'model.png';\n",
        "tf.keras.utils.plot_model(s_model, show_shapes=True, show_layer_names=True, to_file=filename)\n",
        "from IPython.display import Image\n",
        "Image(retina=False, filename=filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYJugkH-nG74",
        "colab_type": "text"
      },
      "source": [
        "## ■（3）学習／最適化（オプティマイザー）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LXXiURp-0W-",
        "colab_type": "text"
      },
      "source": [
        "これまでに学んで来た内容とほぼ変わらないため、説明を割愛する。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7jI_TmCpdfk",
        "colab_type": "text"
      },
      "source": [
        "### リスト3-1　学習方法（損失関数／最適化／学習率）の定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dULWvXF7pe_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 定数（学習方法設計時に必要となるもの）\n",
        "LOSS = 'mean_squared_error'  # 損失関数：平均二乗誤差\n",
        "OPTIMIZER = tf.keras.optimizers.SGD  # 最適化：確率的勾配降下法\n",
        "LEARNING_RATE = 0.01     # 学習率： 0.01\n",
        "\n",
        "# 学習方法を定義する\n",
        "model.compile(optimizer=OPTIMIZER(learning_rate=LEARNING_RATE),\n",
        "              loss=LOSS,\n",
        "              metrics=[])  # 精度（分類では正解率。回帰では損失）"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGQcHIPUqfZ2",
        "colab_type": "text"
      },
      "source": [
        "### リスト3-2　トレーニング（ミニバッチ学習）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Rzif4OkqeKI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 定数（ミニバッチ学習時に必要となるもの）\n",
        "BATCH_SIZE = 15   # バッチサイズ： 15（選択肢は「1」～「30」）\n",
        "EPOCHS = 300     # エポック数： 300\n",
        "\n",
        "# 早期終了（今回はコメントアウト）\n",
        "#es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "# 学習する\n",
        "hist = model.fit(x=X_train,                          # 訓練用データ\n",
        "                 y=y_train,                          # 訓練用ラベル\n",
        "                 validation_data=(X_valid, y_valid), # 精度検証用\n",
        "                 batch_size=BATCH_SIZE,              # バッチサイズ\n",
        "                 epochs=EPOCHS,                      # エポック数\n",
        "                 verbose=1,                          # 実行状況表示\n",
        "                 callbacks=[])                       # コールバック（早期終了しない場合）\n",
        "                 #callbacks=[es])                    # コールバック（早期終了する場合）"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImMFiqK8nkup",
        "colab_type": "text"
      },
      "source": [
        "## ■（4）評価／精度検証"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_0OS2mt_Btl",
        "colab_type": "text"
      },
      "source": [
        "これも、これまでの記事とほぼ同じ内容なので説明を割愛する。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3UolziXnm9e",
        "colab_type": "text"
      },
      "source": [
        "### リスト4-1　損失値の推移グラフ描画"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb-3ert_nqWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 学習結果（損失）のグラフを描画\n",
        "train_loss = hist.history['loss']\n",
        "valid_loss = hist.history['val_loss']\n",
        "epochs = len(train_loss)\n",
        "plt.plot(range(epochs), train_loss, marker='.', label='loss (Training data)')\n",
        "plt.plot(range(epochs), valid_loss, marker='.', label='loss (validation data)')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5SX6m8Qnoy_",
        "colab_type": "text"
      },
      "source": [
        "実行結果のポイント：\n",
        "- 損失（loss）は訓練データでも精度検証データでも同様に下がっている"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvkBhFbKrhzg",
        "colab_type": "text"
      },
      "source": [
        "## ■（5）推論／未知データによるテスト"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFlB998sBL5T",
        "colab_type": "text"
      },
      "source": [
        "### リスト5-1　入力データの描画（リスト1-3の再掲）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzOWnFCkBRLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pg.plot_points_with_playground_style(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQGV20CFBaQs",
        "colab_type": "text"
      },
      "source": [
        "このコードのポイント：\n",
        "- 「playground-data」PyPIパッケージには、入力データを描画するための`plot_points_with_playground_style()`関数が用意されており、上記のコードのようにして使える"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfFPZWnDBUIh",
        "colab_type": "text"
      },
      "source": [
        "### リスト5-2　未知データによるテスト（推論）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsBgGK6AB-QM",
        "colab_type": "text"
      },
      "source": [
        "上のグラフで青い部分の座標を指定して推論してみよう。例えば次のコードでは、(0.0, -3.0)の座標の結果値を推論してみている。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4D9Z7-xq1-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 推論（予測）する\n",
        "model.predict([[0.0, -3.0]])\n",
        "# array([[0.19012895]], dtype=float32) ……などと出力される"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtsHJqNt6Zva",
        "colab_type": "text"
      },
      "source": [
        "実行結果のポイント：\n",
        "- 「0.19012895」と出力され、やや青色になっている"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHAgH1mgC-_w",
        "colab_type": "text"
      },
      "source": [
        "### リスト5-3　学習結果（決定境界／ヒートマップ）の描画"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFxGOpp8D0Ey",
        "colab_type": "text"
      },
      "source": [
        "全ての座標点でこのようなこの出力結果を背景色として描画すると、（分類問題における決定境界のような）ヒートマップのグラフを描画できる。「playground-data」PyPIパッケージには、学習結果（決定境界／ヒートマップ）を描画するための`draw_decision_boundary()`関数が用意されており、次のコードのようにして使える。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZj-PPLLC3l8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 決定境界のグラフを描画する\n",
        "fig = pg.get_playground_figure()\n",
        "ax = pg.get_playground_axes(fig)\n",
        "pg.draw_decision_boundary(fig, ax, trained_model=model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whqm5XgBnx86",
        "colab_type": "text"
      },
      "source": [
        "# お疲れさまでした。第7回は修了です。"
      ]
    }
  ]
}