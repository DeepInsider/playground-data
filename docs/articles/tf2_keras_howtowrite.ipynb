{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf2-keras-howtowrite.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPWjQSe31vjzne+cSVkbkOl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeepInsider/playground-data/blob/master/docs/articles/tf2_keras_howtowrite.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrXUPcCWRzTL",
        "colab_type": "text"
      },
      "source": [
        "##### Copyright 2020 Digital Advantage - Deep Insider."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXnYORgX8UHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpiqfKZH8kvb",
        "colab_type": "text"
      },
      "source": [
        "# 「TensorFlow 2.0最新の書き方入門（全3回）」 ― 連載『TensorFlow 2.0＋Keras（ tf.keras）入門』のノートブック（2）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJQ94tq_8teO",
        "colab_type": "text"
      },
      "source": [
        "<table valign=\"middle\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.atmarkit.co.jp/ait/subtop/features/di/tf2keras_index.html\"> <img src=\"https://re.deepinsider.jp/img/ml-logo/manabu.svg\"/>Deep Insiderで記事を読む</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/DeepInsider/playground-data/blob/master/docs/articles/tf2_keras_howtowrite.ipynb\"> <img src=\"https://re.deepinsider.jp/img/ml-logo/gcolab.svg\" />Google Colabで実行する</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/DeepInsider/playground-data/blob/master/docs/articles/tf2_keras_howtowrite.ipynb\"> <img src=\"https://re.deepinsider.jp/img/ml-logo/github.svg\" />GitHubでソースコードを見る</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNvW2O8uR6xq",
        "colab_type": "text"
      },
      "source": [
        "※上から順に実行してください。上のコードで実行したものを再利用しているところがあるため、すべて実行しないとエラーになるコードがあります。  \n",
        "　すべてのコードを一括実行したい場合は、メニューバーから［ランタイム］－［すべてのセルを実行］をクリックしてください（※TensofFlowのバージョン2.xでない場合、エラーになります）。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pN0BBckBSRKz",
        "colab_type": "text"
      },
      "source": [
        "※「Python 3」を利用してください。  \n",
        "　Python 3を利用するには、メニューバーから［ランタイム］－［ランタイムのタイプを変更］を選択すると表示される［ノートブックの設定］ダイアログの、［ランタイムのタイプ］欄で「Python 3」に選択し、その右下にある［保存］ボタンをクリックしてください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoW15afO8xBX",
        "colab_type": "text"
      },
      "source": [
        "# 第4回　知ってる？！ TensorFlow 2.0最新の書き方入門（初中級者向け）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXt-tmpH9Lls",
        "colab_type": "text"
      },
      "source": [
        "## ■TensorFlowにおける、3種類／6通りのモデルの書き方"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJksPiJx9Ng-",
        "colab_type": "text"
      },
      "source": [
        "TensorFlow 2.0のモデルの書き方には下記の6通りある。本稿ではこの書き方を説明する。\n",
        "\n",
        "**【Sequentialモデル】**（第4回）\n",
        "- （1）`tf.keras.models.Sequential`クラスの**コンストラクター利用**\n",
        "- （2）`tf.keras.models.Sequential`オブジェクトの`add`**メソッドで追加**\n",
        "\n",
        "**【Functional API】**（第4回）\n",
        "- （3）`tf.keras.Model`クラスの**コンストラクター利用**\n",
        "\n",
        "**【Subclassingモデル】**（第5回と第6回）\n",
        "- （4）`tf.keras.Model`クラスの**サブクラス化**\n",
        "- （5）`TensorFlow低水準API`で**カスタム実装**\n",
        "\n",
        "**【作成済みEstimators】**（第6回）\n",
        "- （6）`tf.estimator.Estimator`が提供する**作成済みモデル**（**Pre-made Estimators**）の利用"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVbuh4ZBybiC",
        "colab_type": "text"
      },
      "source": [
        "### ●TensorFlow 2.0最新の書き方入門の記事構成（全3回）について"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPflhIuPywds",
        "colab_type": "text"
      },
      "source": [
        "- [「第4回　知ってる？！ TensorFlow 2.0最新の書き方入門（初中級者向け）](https://www.atmarkit.co.jp/ait/articles/2002/27/news021.html)」……（1）～（3）\n",
        "- 「第5回　お勧めの、TensorFlow 2.0最新の書き方入門（エキスパート向け）」……（4）\n",
        "- 「第6回　カスタマイズするための、TensorFlow 2.0最新の書き方入門（エキスパート向け）」……（5）～（6）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8BZxKjqkxTD",
        "colab_type": "text"
      },
      "source": [
        "### ●TensorFlowのエコシステム／機能構成図\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MFgq_gh0jNx",
        "colab_type": "text"
      },
      "source": [
        "![TensorFlow全体の機能構成図](https://github.com/DeepInsider/playground-data/raw/master/docs/articles/tensorflow-ecosystem-2.0.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vT2IIbxs1mPe",
        "colab_type": "text"
      },
      "source": [
        "## ■コードの書き方を実行するための準備"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQOXnxrjIhHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Google Colabで最新の2.xを使う場合、2.xに切り替える（Colab専用）\n",
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_0iqMHC4E2o",
        "colab_type": "text"
      },
      "source": [
        "### ●前提条件"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vo7QQTfqHG9",
        "colab_type": "text"
      },
      "source": [
        "### 【チェック】Pythonバージョン（※3系を使うこと）\n",
        "Colabにインストール済みのものを使う。もし2系になっている場合は、メニューバーの［ランタイム］－［ランタイムのタイプを変更］をクリックして切り替えてほしい。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4PO0HWIqMQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "print('Python', sys.version)\n",
        "# Python 3.6.9 (default, Nov  7 2019, 10:44:02)  …… などと表示される"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzRCOJw6AOop",
        "colab_type": "text"
      },
      "source": [
        "### 【チェック】TensorFlowバージョン（※2系を使うこと）\n",
        "基本的にはColabにインストール済みのものを使う。もし2系になっている場合は、リスト4-0を実行してバージョン2.0を使う。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYqIF_SCAQeH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "print('TensorFlow', tf.__version__)\n",
        "# TensorFlow 1.15.0 ……などと表示される"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sg36M_-ATxR",
        "colab_type": "text"
      },
      "source": [
        "#### リスト0-1　［オプション］ライブラリ「TensorFlow」最新バージョンのインストール"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ak9jig-eEWg4",
        "colab_type": "text"
      },
      "source": [
        "※Google Colabでを使う場合は、「%tensorflow_version 2.x」というマジックコマンドを使用してください。  \n",
        "　「TensorFlow 2.x selected.」と表示されればOKです。\n",
        "　「TensorFlow is already loaded. Please restart the runtime to change versions.」と表示される場合は、メニューバーから［ランタイム］－［ランタイムを再起動］を実行した上で、再度マジックコマンドの実行結果を確かめてください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJgCZ6-KAYtw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Google Colabで最新の2.xを使う場合（Colab専用）\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "# 最新バージョンにアップグレードする場合\n",
        "!pip install --upgrade tensorflow\n",
        "\n",
        "# バージョンを明示してアップグレードする場合\n",
        "#!pip install --upgrade tensorflow===2.1.0\n",
        "\n",
        "# 最新バージョンをインストールする場合\n",
        "#!pip install tensorflow\n",
        "\n",
        "# バージョンを明示してインストールする場合\n",
        "#!pip install tensorflow===2.1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhO5Mj7YAeAG",
        "colab_type": "text"
      },
      "source": [
        "### ［オプション］【チェック】TensorFlowバージョン（※インストール後の確認）\n",
        "バージョン2.xになっているか再度チェックする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6eq67BTAgM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "print('TensorFlow', tf.__version__)\n",
        "# TensorFlow 2.1.0 ……などと表示される"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkIfaer6-RFY",
        "colab_type": "text"
      },
      "source": [
        "### ●データについて"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3n6D3vKUpDJS",
        "colab_type": "text"
      },
      "source": [
        "「[第1回　初めてのニューラルネットワーク実装、まずは準備をしよう ― 仕組み理解×初実装（前編）：TensorFlow 2＋Keras（tf.keras）入門 - ＠IT](https://www.atmarkit.co.jp/ait/articles/1909/19/news026.html)」の記事と同じように、シンプルな座標点データを生成して使う。使い方は、前述の記事を参照してほしい。\n",
        "\n",
        "なお、座標点データは、「[ニューラルネットワーク Playground - Deep Insider](https://deepinsider.github.io/playground/)」（以下、Playground）と同じ生成仕様となっている。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfxpuUIw-bz1",
        "colab_type": "text"
      },
      "source": [
        "#### リスト0-x　座標点データの生成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ij95BzkypJZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 座標点データを生成するライブラリのインストール\n",
        "!pip install playground-data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH9qg4Qt-dER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# playground-dataライブラリのplygdataパッケージを「pg」という別名でインポート\n",
        "import plygdata as pg\n",
        "\n",
        "# 設定値を定数として定義\n",
        "PROBLEM_DATA_TYPE = pg.DatasetType.ClassifyCircleData # 問題種別：「分類（Classification）」、データ種別：「円（CircleData）」を選択\n",
        "TRAINING_DATA_RATIO = 0.5  # データの何％を訓練【Training】用に？ (残りは精度検証【Validation】用) ： 50％\n",
        "DATA_NOISE = 0.0           # ノイズ： 0％\n",
        "\n",
        "# 定義済みの定数を引数に指定して、データを生成する\n",
        "data_list = pg.generate_data(PROBLEM_DATA_TYPE, DATA_NOISE)\n",
        "\n",
        "# データを「訓練用」と「精度検証用」を指定の比率で分割し、さらにそれぞれを「データ（X）」と「教師ラベル（y）」に分ける\n",
        "X_train, y_train, X_valid, y_valid = pg.split_data(data_list, training_size=TRAINING_DATA_RATIO)\n",
        "\n",
        "# データ分割後の各変数の内容例として、それぞれ5件ずつ出力（※出力内容は実行ごとに異なる）\n",
        "print('X_train:'); print(X_train[:5]) # [[-0.07940614  1.15175421], ……]\n",
        "print('y_train:'); print(y_train[:5]) # [[ 1.], ……  [-1.]]\n",
        "print('X_valid:'); print(X_valid[:5]) # [[ 0.10066901  1.19950826], ……]\n",
        "print('y_valid:'); print(y_valid[:5]) # [[ 1.], ……  [-1.]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtsZKVi0ujx5",
        "colab_type": "text"
      },
      "source": [
        "### ●ディープニューラルネットワークのモデル設計\n",
        "- 入力の数（`INPUT_FEATURES`）は、$X_1$と$X_2$で**2つ**\n",
        "- 隠れ層のレイヤー数は、**2つ**\n",
        "  - 隠れ層にある1つ目のニューロンの数（`LAYER1_NEURONS`）は、**3つ**\n",
        "  - 隠れ層にある2つ目のニューロンの数（`LAYER2_NEURONS`）は、**3つ**\n",
        "- 出力層にあるニューロンの数（`OUTPUT_RESULTS`）は、**1つ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVEH9qMkCRjG",
        "colab_type": "text"
      },
      "source": [
        "#### リスト0-2　インポートと変数の宣言（全ての書き方に共通）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRGiReEFrFHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ライブラリ「TensorFlow」のtensorflowパッケージを「tf」という別名でインポート\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers       # 「レイヤーズ」モジュールのインポート\n",
        "\n",
        "# 定数（モデル定義時に必要となる数値）\n",
        "INPUT_FEATURES = 2  # 入力（特徴）の数： 2\n",
        "LAYER1_NEURONS = 3  # ニューロンの数： 3\n",
        "LAYER2_NEURONS = 3  # ニューロンの数： 3\n",
        "OUTPUT_RESULTS = 1  # 出力結果の数： 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDiENTZrTfZ8",
        "colab_type": "text"
      },
      "source": [
        "#### リスト0-3　正解率（精度）のカスタム指標（全ての書き方に共通）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MX6Y7A1DTdjh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.keras.backend as K\n",
        "\n",
        "def tanh_accuracy(y_true, y_pred):           # y_trueは正解、y_predは予測（出力）\n",
        "  threshold = K.cast(0.0, y_pred.dtype)              # -1か1かを分ける閾値を作成\n",
        "  y_pred = K.cast(y_pred >= threshold, y_pred.dtype) # 閾値未満で0、以上で1に変換\n",
        "  # 2倍して-1.0することで、0／1を-1.0／1.0にスケール変換して正解率を計算\n",
        "  return K.mean(K.equal(y_true, y_pred * 2 - 1.0), axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqSKaBZzpk1u",
        "colab_type": "text"
      },
      "source": [
        "「[第5回　お勧めの、TensorFlow 2.0最新の書き方入門（エキスパート向け）](#scrollTo=PBSGSzs-RWFu)」の（4）以降に進む場合は、左記のリンクをクリックしてください。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiuBRdfareeA",
        "colab_type": "text"
      },
      "source": [
        "## ■（1）Sequentialクラスのコンストラクター利用［tf.keras - Sequential API］"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGNkm0lZLqMB",
        "colab_type": "text"
      },
      "source": [
        "### ●モデル設計の書き方（初中級向け）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIUy5Fck8UaM",
        "colab_type": "text"
      },
      "source": [
        "#### リスト1-1　Sequentialクラスのコンストラクターを利用した書き方"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vu4KYYhCqwCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([    # モデルの生成\n",
        "\n",
        "  # 隠れ層：1つ目のレイヤー\n",
        "  layers.Dense(                 # 全結合層\n",
        "      input_shape=(INPUT_FEATURES,),       # 入力の形状（＝入力層）\n",
        "      name='layer1',                       # 表示用に名前付け\n",
        "      kernel_initializer='glorot_uniform', # 重さの初期化（一様分布のランダム値）\n",
        "      bias_initializer='zeros',            # バイアスの初期化（0）\n",
        "      units=LAYER1_NEURONS,                # ユニットの数      \n",
        "      activation='tanh'),                  # 活性化関数\n",
        "\n",
        "  # 隠れ層：2つ目のレイヤー\n",
        "  layers.Dense(                 # 全結合層\n",
        "      name='layer2',                       # 表示用に名前付け\n",
        "      kernel_initializer='glorot_uniform', # 重さの初期化\n",
        "      bias_initializer='zeros',            # バイアスの初期化\n",
        "      units=LAYER2_NEURONS,                # ユニットの数\n",
        "      activation='tanh'),                  # 活性化関数\n",
        "\n",
        "  # 出力層\n",
        "  layers.Dense(                 # 全結合層\n",
        "      name='layer_out',                    # 表示用に名前付け\n",
        "      kernel_initializer='glorot_uniform', # 重さの初期化\n",
        "      bias_initializer='zeros',            # バイアスの初期化\n",
        "      units=OUTPUT_RESULTS,                # ユニットの数\n",
        "      activation='tanh'),                  # 活性化関数\n",
        "\n",
        "], name='sequential_constructor'           # モデルにも名前付け\n",
        ")\n",
        "\n",
        "# 以上でモデル設計は完了\n",
        "model.summary()                            # モデルの内容を出力"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mgb1lix1MKuH",
        "colab_type": "text"
      },
      "source": [
        "#### リスト1-2　モデル構成図を表示するコード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAe2bE4jLD1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True, to_file='model.png')\n",
        "from IPython.display import Image\n",
        "Image(retina=False, filename='model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vEZEkj7Mv4W",
        "colab_type": "text"
      },
      "source": [
        "### ●重み／バイアスの初期化指定【応用】"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d60n1mj3Pwj7",
        "colab_type": "text"
      },
      "source": [
        "#### リスト1-3　重み／バイアスを初期化するための独自イニシャライザー"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnwcjMqiM1ny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_init = tf.keras.initializers.RandomUniform(\n",
        "    minval=-1.0, maxval=1.0) # 下限と上限を指定した一様分布でランダム値"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CIMUuMtQdqj",
        "colab_type": "text"
      },
      "source": [
        "### ●学習と推論： 書き方入門（初中級者向け）で共通"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofCov2fKRVh7",
        "colab_type": "text"
      },
      "source": [
        "#### リスト1-4　学習方法を設定、学習、推論（予測）するコード（共通）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DKTr9pscl1y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 学習方法を設定し、学習し、推論（予測）する\n",
        "model.compile(tf.keras.optimizers.SGD(learning_rate=0.03), 'mean_squared_error', [tanh_accuracy])\n",
        "hist = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), batch_size=15, epochs=100, verbose=1)\n",
        "model.predict([[0.1,-0.2]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMfREMSmnL50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 学習結果（損失）のグラフを描画\n",
        "train_loss = hist.history['loss']\n",
        "valid_loss = hist.history['val_loss']\n",
        "epochs = len(train_loss)\n",
        "plt.plot(range(epochs), train_loss, marker='.', label='loss (Training data)')\n",
        "plt.plot(range(epochs), valid_loss, marker='.', label='loss (validation data)')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpLef31zT99O",
        "colab_type": "text"
      },
      "source": [
        "モデルの書き方だけでなく、学習に関するコードも、下記のように2種類ある。\n",
        "\n",
        "- **初中級者向けの書き方：** リスト1-4のように`compile()`＆`fit()`メソッドを呼び出す、簡単で手軽な書き方\n",
        "- **エキスパート向けの書き方：** 次回説明するが、`tf.GradientTape`クラス（自動微分の記録機能）を使った柔軟で拡張性の高い書き方（PyTorchの書き方に近い）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlfUU17pU0Dg",
        "colab_type": "text"
      },
      "source": [
        "### ●作成済みモデルのリセット"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wplbU3-eVYxF",
        "colab_type": "text"
      },
      "source": [
        "#### リスト1-5　次に進む前にモデルをリセットするコード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMvG2oRsvHDJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session() # 計算グラフを破棄する\n",
        "del model                        # 変数を削除する"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpyomA8ErqNa",
        "colab_type": "text"
      },
      "source": [
        "## ■（2）Sequentialオブジェクトのaddメソッドで追加［tf.keras - Sequential API］"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ8yX3Z8MNok",
        "colab_type": "text"
      },
      "source": [
        "### ●モデル設計の書き方（初中級向け）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7sNPO8hV7zV",
        "colab_type": "text"
      },
      "source": [
        "#### リスト2-1　Sequentialオブジェクトのaddメソッドを利用した書き方"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ExiZydu2WFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential(  # モデルの生成\n",
        "    name='sequential_add_method'     # モデルにも名前付け\n",
        ")\n",
        "\n",
        "# 隠れ層：1つ目のレイヤー\n",
        "model.add(layers.Dense(        # 全結合層\n",
        "    input_shape=(INPUT_FEATURES,),   # 入力の形状（＝入力層）\n",
        "    name='layer1',                   # 表示用に名前付け\n",
        "    units=LAYER1_NEURONS,            # ユニットの数\n",
        "    activation='tanh'))              # 活性化関数\n",
        "\n",
        "# 隠れ層：2つ目のレイヤー\n",
        "model.add(layers.Dense(        # 全結合層\n",
        "    name='layer2',                   # 表示用に名前付け\n",
        "    units=LAYER2_NEURONS,            # ユニットの数\n",
        "    activation='tanh'))              # 活性化関数\n",
        "\n",
        "# 出力層\n",
        "model.add(layers.Dense(        # 全結合層\n",
        "    name='layer_out',                # 表示用に名前付け\n",
        "    units=OUTPUT_RESULTS,            # ユニットの数\n",
        "    activation='tanh'))              # 活性化関数\n",
        "\n",
        "# 以上でモデル設計は完了\n",
        "model.summary()                      # モデルの内容を出力"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Udfm1JImWAvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# モデルの構成図を表示\n",
        "tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True, to_file='model.png')\n",
        "from IPython.display import Image\n",
        "Image(retina=False, filename='model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7_1K9L1caSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 学習方法を設定し、学習し、推論（予測）する\n",
        "model.compile(tf.keras.optimizers.SGD(learning_rate=0.03), 'mean_squared_error', [tanh_accuracy])\n",
        "hist = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), batch_size=15, epochs=100, verbose=1)\n",
        "model.predict([[0.1,-0.2]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c11EAhXSnH0z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 学習結果（損失）のグラフを描画\n",
        "train_loss = hist.history['loss']\n",
        "valid_loss = hist.history['val_loss']\n",
        "epochs = len(train_loss)\n",
        "plt.plot(range(epochs), train_loss, marker='.', label='loss (Training data)')\n",
        "plt.plot(range(epochs), valid_loss, marker='.', label='loss (validation data)')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ou0328ZYcM0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 次に進む前にモデルをリセット\n",
        "tf.keras.backend.clear_session() # グラフを破棄する\n",
        "del model                        # 変数を削除する"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQad_ZlBtP0O",
        "colab_type": "text"
      },
      "source": [
        "## ■（3）Modelクラスのコンストラクター利用［tf.keras - Functional API］"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHDxvOrRMeu0",
        "colab_type": "text"
      },
      "source": [
        "### ●モデル設計の書き方（初中級向け）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1q_Wo_kpapPY",
        "colab_type": "text"
      },
      "source": [
        "#### リスト3-1　Modelクラスのコンストラクターを利用した書き方"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yHaU8-q2TQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ### 活性化関数を変数（ハイパーパラメーター）として定義 ###\n",
        "# 変数（モデル定義時に必要となる数値）\n",
        "activation1 = layers.Activation('tanh' # 活性化関数（隠れ層用）： tanh関数（変更可能）\n",
        "    , name='activation1'               # 活性化関数にも名前付け\n",
        "    )\n",
        "activation2 = layers.Activation('tanh' # 活性化関数（隠れ層用）： tanh関数（変更可能）\n",
        "    , name='activation2'               # 活性化関数にも名前付け\n",
        "    )\n",
        "acti_out = layers.Activation('tanh'    # 活性化関数（出力層用）： tanh関数（固定）\n",
        "    , name='acti_out'                  # 活性化関数にも名前付け\n",
        "    )\n",
        "\n",
        "# ### レイヤーを定義 ###\n",
        "# input_shape引数の代わりに、Inputクラスを使うことも可能\n",
        "inputs = layers.Input(          # 入力層\n",
        "    name='layer_in',                 # 表示用に名前付け\n",
        "    shape=(INPUT_FEATURES,))         # 入力の形状\n",
        "\n",
        "# 隠れ層：1つ目のレイヤー\n",
        "layer1 = layers.Dense(          # 全結合層\n",
        "    #input_shape=(INPUT_FEATURES,),  # ※入力層は定義済みなので不要\n",
        "    name='layer1',                   # 表示用に名前付け\n",
        "    units=LAYER1_NEURONS)            # ユニットの数\n",
        "\n",
        "# 隠れ層：2つ目のレイヤー\n",
        "layer2 = layers.Dense(          # 全結合層\n",
        "    name='layer2',                   # 表示用に名前付け\n",
        "    units=LAYER2_NEURONS)            # ユニットの数\n",
        "\n",
        "# 出力層\n",
        "layer_out = layers.Dense(       # 全結合層\n",
        "    name='layer_out',                # 表示用に名前付け\n",
        "    units=OUTPUT_RESULTS)            # ユニットの数\n",
        "\n",
        "# ### フォワードパスを定義 ###\n",
        "# 「出力＝活性化関数（第n層（入力））」の形式で記述\n",
        "x1 = activation1(layer1(inputs))     # 活性化関数は変数として定義\n",
        "x2 = activation2(layer2(x1))         # 同上\n",
        "outputs = acti_out(layer_out(x2))    # ※活性化関数は「tanh」固定\n",
        "\n",
        "# ### モデルの生成 ###\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs\n",
        "    , name='model_constructor'       # モデルにも名前付け\n",
        ")\n",
        "\n",
        "# ### 以上でモデル設計は完了 ###\n",
        "model.summary()                      # モデルの内容を出力"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8urDYqda5Ov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# モデルの構成図を表示\n",
        "tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True, to_file='model.png')\n",
        "from IPython.display import Image\n",
        "Image(retina=False, filename='model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlySSL3AkNY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 学習方法を設定し、学習し、推論（予測）する\n",
        "model.compile(tf.keras.optimizers.SGD(learning_rate=0.03), 'mean_squared_error', [tanh_accuracy])\n",
        "hist = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), batch_size=15, epochs=100, verbose=1)\n",
        "model.predict([[0.1,-0.2]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg_F7IYumkI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 学習結果（損失）のグラフを描画\n",
        "train_loss = hist.history['loss']\n",
        "valid_loss = hist.history['val_loss']\n",
        "epochs = len(train_loss)\n",
        "plt.plot(range(epochs), train_loss, marker='.', label='loss (Training data)')\n",
        "plt.plot(range(epochs), valid_loss, marker='.', label='loss (validation data)')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzKfe4APisbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 次に進む前にモデルをリセット\n",
        "tf.keras.backend.clear_session() # グラフを破棄する\n",
        "del model                        # 変数を削除する"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBSGSzs-RWFu",
        "colab_type": "text"
      },
      "source": [
        "# 第5回　お勧めの、TensorFlow 2.0最新の書き方入門（エキスパート向け）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqfUAk4tpRCe",
        "colab_type": "text"
      },
      "source": [
        "以下のコードを実行するには、事前に「[■コードの書き方を実行するための準備](#scrollTo=vT2IIbxs1mPe)」の全てのコードを実行しておく必要があります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buAXoK_lR9xg",
        "colab_type": "text"
      },
      "source": [
        "## ■（4）Modelクラスのサブクラス化［tf.keras - Subclassing／Imperative API］"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5y73MCrMsG7",
        "colab_type": "text"
      },
      "source": [
        "### ●モデル設計の書き方（エキスパート向け）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4Y49sm1utF-",
        "colab_type": "text"
      },
      "source": [
        "#### リスト4-1　Modelクラスのサブクラス化を利用した書き方"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUk6sSJXu9qe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ### 活性化関数を変数（ハイパーパラメーター）として定義 ###\n",
        "# 変数（モデル定義時に必要となる数値）\n",
        "activation1 = layers.Activation('tanh' # 活性化関数（隠れ層用）： tanh関数（変更可能）\n",
        "    , name='activation1'               # 活性化関数にも名前付け\n",
        "    )\n",
        "activation2 = layers.Activation('tanh' # 活性化関数（隠れ層用）： tanh関数（変更可能）\n",
        "    , name='activation2'               # 活性化関数にも名前付け\n",
        "    )\n",
        "acti_out = layers.Activation('tanh'    # 活性化関数（出力層用）： tanh関数（固定）\n",
        "    , name='acti_out'                  # 活性化関数にも名前付け\n",
        "    )\n",
        "\n",
        "# tf.keras.Modelをサブクラス化してモデルを定義\n",
        "class NeuralNetwork(tf.keras.Model):\n",
        "\n",
        "  # ### レイヤーを定義 ###\n",
        "  def __init__(self, *args, **kwargs):\n",
        "    super(NeuralNetwork, self).__init__(*args, **kwargs)\n",
        "\n",
        "    # 入力層は定義「不要」。実際の入力によって決まるので\n",
        "\n",
        "    # 隠れ層：1つ目のレイヤー\n",
        "    self.layer1 = layers.Dense(          # 全結合層\n",
        "        #input_shape=(INPUT_FEATURES,),  # 入力層（定義不要）\n",
        "        name='layer1',                   # 表示用に名前付け\n",
        "        units=LAYER1_NEURONS)            # ユニットの数\n",
        "\n",
        "    # 隠れ層：2つ目のレイヤー\n",
        "    self.layer2 = layers.Dense(          # 全結合層\n",
        "        name='layer2',                   # 表示用に名前付け\n",
        "        units=LAYER2_NEURONS)            # ユニットの数\n",
        "\n",
        "    # 出力層\n",
        "    self.layer_out = layers.Dense(       # 全結合層\n",
        "        name='layer_out',                # 表示用に名前付け\n",
        "        units=OUTPUT_RESULTS)            # ユニットの数\n",
        "\n",
        "  # ### フォワードパスを定義 ###\n",
        "  def call(self, inputs, training=None): # 入力と、訓練／評価モード\n",
        "    # 「出力＝活性化関数（第n層（入力））」の形式で記述\n",
        "    x1 = activation1(self.layer1(inputs))     # 活性化関数は変数として定義\n",
        "    x2 = activation2(self.layer2(x1))         # 同上\n",
        "    outputs = acti_out(self.layer_out(x2))    # ※活性化関数は「tanh」固定\n",
        "    return outputs\n",
        "\n",
        "# ### モデルの生成 ###\n",
        "# model = tf.keras.Model(inputs=inputs, outputs=outputs\n",
        "#     , name='model_constructor'       # モデルにも名前付け\n",
        "# )\n",
        "model = NeuralNetwork()                # モデルの生成\n",
        "\n",
        "# ### 以上でモデル設計は完了 ###\n",
        "#model.summary()  # モデル内容の出力はできない！（後述）"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2IoXLiHsbQa",
        "colab_type": "text"
      },
      "source": [
        "### ●モデルの内容と構成図の出力について"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHuSZhtdspHL",
        "colab_type": "text"
      },
      "source": [
        "#### リスト4-2　計算グラフなしでは「model.summary()」は失敗する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhwrMXyp5iaT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# モデルの内容を出力\n",
        "#model.summary()     # エラー！ ← 計算グラフが構築できていないため\n",
        "\n",
        "# エラー出力例\n",
        "# ValueError: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLnHomqYi7gs",
        "colab_type": "text"
      },
      "source": [
        "「エラー出力例」の日本語翻訳： 「ValueError: このモデルはまだビルド（＝計算グラフが構築）されていません。`build()`を呼び出すか、データを指定して`fit()`を呼び出すか、自動ビルドのために最初のレイヤーで`input_shape`引数を指定するかして、先にモデルをビルドしてください。」"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WbVC_Qz_G-8",
        "colab_type": "text"
      },
      "source": [
        "### ○方法1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfG8MJo-zEWi",
        "colab_type": "text"
      },
      "source": [
        "#### リスト4-3　方法1：推論して動的に計算グラフを構築する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIunJsyS5tMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1 = NeuralNetwork(name='subclassing_model1') # モデルの生成\n",
        "\n",
        "# 方法1： 推論して動的にグラフを構築する\n",
        "temp_input = [[0.1,-0.2]]                         # 仮の入力値\n",
        "temp_output = model1.predict(temp_input)          # 推論の実行\n",
        "\n",
        "# モデルの内容を出力\n",
        "model1.summary()\n",
        "\n",
        "# モデルの構成図を表示\n",
        "tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True, to_file='model.png')\n",
        "from IPython.display import Image\n",
        "Image(retina=False, filename='model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CHz5PHF_Qa3",
        "colab_type": "text"
      },
      "source": [
        "### ○方法2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlMk2AnAzNjp",
        "colab_type": "text"
      },
      "source": [
        "#### リスト4-4　方法2：入力形状を指定して計算グラフを構築する（モデルのビルド）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNaTCZHRy1gu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = NeuralNetwork(name='subclassing_model2') # モデルの生成\n",
        "\n",
        "# 方法2： 入力形状を指定して計算グラフを構築する\n",
        "model2.build(                # モデルのビルド\n",
        "   input_shape=(None,2))     # 入力の形状（＝入力層）※タプル形式\n",
        "\n",
        "# モデルの内容を出力\n",
        "model2.summary()\n",
        "\n",
        "# モデルの構成図を表示\n",
        "tf.keras.utils.plot_model(model2, show_shapes=True, show_layer_names=True, to_file='model.png')\n",
        "from IPython.display import Image\n",
        "Image(retina=False, filename='model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MchxduOj_S-a",
        "colab_type": "text"
      },
      "source": [
        "### ○方法3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG4bz8qgzO1F",
        "colab_type": "text"
      },
      "source": [
        "#### リスト4-5　方法3：モデル構造の出力用に「仮のモデル」をFunctional APIで生成する（裏技テクニック）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVhsXoGc0j9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3 = NeuralNetwork()                # モデルの生成\n",
        "\n",
        "# 「仮のモデル」をFunctional APIで生成する独自関数\n",
        "def get_functional_model(model):\n",
        "  # このコードは、「リスト3-1のFunctional API」とほぼ同じ\n",
        "  x = layers.Input(shape=(INPUT_FEATURES,), name='layer_in')\n",
        "  temp_model = tf.keras.Model(\n",
        "      inputs=[x],\n",
        "      outputs=model.call(x),  # ※サブクラス化したモデルの`call`メソッドを指定\n",
        "      name='subclassing_model3')  # 仮モデルにも名前付け\n",
        "  return temp_model\n",
        "\n",
        "# Functional APIの「仮のモデル」を取得\n",
        "f_model = get_functional_model(model3)\n",
        "\n",
        "# モデルの内容を出力\n",
        "f_model.summary()\n",
        "\n",
        "# モデルの構成図を表示\n",
        "tf.keras.utils.plot_model(f_model, show_shapes=True, show_layer_names=True, to_file='model.png')\n",
        "from IPython.display import Image\n",
        "Image(retina=False, filename='model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hF_LqnqX6-8L",
        "colab_type": "text"
      },
      "source": [
        "### ●学習と推論： 書き方入門（エキスパート向け）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBnt_hHCNg4X",
        "colab_type": "text"
      },
      "source": [
        "【念のため、再説明】モデルの書き方だけでなく、学習に関するコードも、下記のように2種類ある。\n",
        "\n",
        "- **初中級者向けの書き方：** `compile()`＆`fit()`メソッドを呼び出す、簡単で手軽な書き方\n",
        "- **エキスパート向けの書き方：** `tf.GradientTape`クラス（自動微分の記録機能）を使った柔軟で拡張性の高い書き方（PyTorchの書き方に近い）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSviW03J_pCk",
        "colab_type": "text"
      },
      "source": [
        "### ○初中級者向け書き方の復習"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmMy1dnh7Z0H",
        "colab_type": "text"
      },
      "source": [
        "#### リスト4-6　学習方法を設定、学習、推論（予測）するコード（共通）の振り返り\n",
        "\n",
        "「リスト1-4　学習方法を設定、学習、推論（予測）するコード（共通）」と同じコードの再掲。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl2fUM5N7kWG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 学習方法を設定し、学習し、推論（予測）する\n",
        "model.compile(tf.keras.optimizers.SGD(learning_rate=0.03), 'mean_squared_error', [tanh_accuracy])\n",
        "hist = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), batch_size=15, epochs=100, verbose=1)\n",
        "model.predict([[0.1,-0.2]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmXJVO_nn9Nw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 学習結果（損失）のグラフを描画\n",
        "train_loss = hist.history['loss']\n",
        "valid_loss = hist.history['val_loss']\n",
        "epochs = len(train_loss)\n",
        "plt.plot(range(epochs), train_loss, marker='.', label='loss (Training data)')\n",
        "plt.plot(range(epochs), valid_loss, marker='.', label='loss (validation data)')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6iHlBlx5jaM",
        "colab_type": "text"
      },
      "source": [
        "### リスト4-x　次に進む前にモデルをリセットするコード\n",
        "\n",
        "「リスト1-5　次に進む前にモデルをリセットするコード」と同じコードの再掲（※同じモデルを使うので再度インスタンス化するコードも追加した）。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyIqlLcW5LfJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 次のコードのためにモデル（重みやバイアス）をリセットする\n",
        "tf.keras.backend.clear_session() # 計算グラフを破棄する\n",
        "del model                        # 変数を削除する\n",
        "\n",
        "model = NeuralNetwork()          # モデルの再生成"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWA_PT9ZEJlS",
        "colab_type": "text"
      },
      "source": [
        "#### リスト4-x　評価関数のカスタム実装"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "defrNU2RC9Xz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# カスタムの評価関数を実装（TensorFlow低水準API利用）\n",
        "# （tf.keras.metrics.binary_accuracy()の代わり）\n",
        "def tanh_accuracy(y_true, y_pred):           # y_trueは正解、y_predは予測（出力）\n",
        "  threshold = K.cast(0.0, y_pred.dtype)              # -1か1かを分ける閾値を作成\n",
        "  y_pred = K.cast(y_pred >= threshold, y_pred.dtype) # 閾値未満で0、以上で1に変換\n",
        "  # 2倍して-1.0することで、0／1を-1.0／1.0にスケール変換して正解率を計算\n",
        "  return K.mean(K.equal(y_true, y_pred * 2 - 1.0), axis=-1)\n",
        "\n",
        "# カスタムの評価関数クラスを実装（サブクラス化）\n",
        "# （tf.keras.metrics.BinaryAccuracy()の代わり）\n",
        "class TanhAccuracy(tf.keras.metrics.Mean):\n",
        "  def __init__(self, name='tanh_accuracy', dtype=None):\n",
        "    super(TanhAccuracy, self).__init__(name, dtype)\n",
        "\n",
        "  # 正解率の状態を更新する際に呼び出される関数をカスタマイズ\n",
        "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "    matches = tanh_accuracy(y_true, y_pred)\n",
        "    return super(TanhAccuracy, self).update_state(\n",
        "        matches, sample_weight=sample_weight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVHVk4O8_vyc",
        "colab_type": "text"
      },
      "source": [
        "### ○推論"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYpWAFFuvz-D",
        "colab_type": "text"
      },
      "source": [
        "#### リスト4-7　推論（エキスパート向け）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDXNJU28vqLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 【初中級者向けとの比較用】推論する\n",
        "# python_input2 = [[0.1,-0.2]]\n",
        "# predict2 = model.predict(python_input2)\n",
        "# print(predict2)\n",
        "# # [[0.9845763]] ……などと表示される\n",
        "\n",
        "# ###【エキスパート向け】推論する ###\n",
        "python_input1 = [[0.1,-0.2]]   # 入力値（Pythonリスト値／NumPy多次元配列値）\n",
        "\n",
        "# Pythonリスト値やNumPy多次元配列値はテンソルにいったん変換する必要がある\n",
        "tensor_input1 = tf.convert_to_tensor(python_input1, dtype=tf.float32)\n",
        "#tensor_input1 = tf.constant([[0.1,-0.2]])  # 入力値（定数）\n",
        "#tensor_input1 = tf.Variable([[0.1,-0.2]])  # 入力値（変数）\n",
        "\n",
        "predict1 = model(tensor_input1)         # ※テンソルの入力しか受け付けない\n",
        "\n",
        "print(predict1)                         # ※テンソルが出力される\n",
        "# tf.Tensor([[0.9845763]], shape=(1, 1), dtype=float32) ……などと表示される"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ilcl5G0APUS",
        "colab_type": "text"
      },
      "source": [
        "### ○オプティマイザ（最適化用オブジェクト）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocnZn9Ts7xo8",
        "colab_type": "text"
      },
      "source": [
        "#### リスト4-8-1　オプティマイザ（最適化用オブジェクト）の定義（エキスパート向け）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9aOx6wy8kkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 【初中級者向けとの比較用】学習方法を設定する\n",
        "# model.compile(\n",
        "#     tf.keras.optimizers.SGD(learning_rate=0.03),        # 最適化アルゴリズム\n",
        "#     ……損失関数……,\n",
        "#     ……評価関数……)\n",
        "\n",
        "# ###【エキスパート向け】最適化アルゴリズムを定義する ###\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.03)  # 更新時の学習率"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLpyjfWNAcAt",
        "colab_type": "text"
      },
      "source": [
        "### ○損失関数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7rF-a03TiWL",
        "colab_type": "text"
      },
      "source": [
        "#### リスト4-8-2　損失関数の定義（エキスパート向け）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEyvIkFTT2cp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 【初中級者向けとの比較用】学習方法を設定する\n",
        "# model.compile(\n",
        "#     ……最適化アルゴリズム……,\n",
        "#     'mean_squared_error',  # 損失関数\n",
        "#     ……評価関数……)\n",
        "\n",
        "# ###【エキスパート向け】損失関数を定義する ###\n",
        "criterion = tf.keras.losses.MeanSquaredError()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZShYyRglA3mL",
        "colab_type": "text"
      },
      "source": [
        "### ○評価関数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hIP4ayYTpWy",
        "colab_type": "text"
      },
      "source": [
        "#### リスト4-8-3　評価関数の定義（エキスパート向け）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yin1zbXdT4h6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 【初中級者向けとの比較用】学習方法を設定する\n",
        "# model.compile(\n",
        "#     ……最適化アルゴリズム……,\n",
        "#     ……損失関数……,\n",
        "#     [tanh_accuracy])   # 評価関数\n",
        "\n",
        "# ### 【エキスパート向け】評価関数を定義する ###\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = TanhAccuracy(name='train_accuracy')\n",
        "valid_loss = tf.keras.metrics.Mean(name='valid_loss')\n",
        "valid_accuracy = TanhAccuracy(name='valid_accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSBHffMUBAXi",
        "colab_type": "text"
      },
      "source": [
        "### ○tf.dataデータセット"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr2iwT227uoh",
        "colab_type": "text"
      },
      "source": [
        "#### リスト4-9-1　ミニバッチ用データセットの準備（エキスパート向け）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHnhSd_Jk3Q6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 【初中級者向けとの比較用】入力データを指定して学習する\n",
        "# model.fit(\n",
        "#     X_train, y_train,                    # 訓練データ\n",
        "#     validation_data=(X_valid, y_valid),  # 精度検証データ\n",
        "#     batch_size=15,                       # バッチサイズ\n",
        "#     ……エポック数……,\n",
        "#     ……実行状況の出力モード……)\n",
        "\n",
        "# ###【エキスパート向け】入力データを準備する ###\n",
        "\n",
        "# NumPy多次元配列のデータ型をデータセット（テンソル）用に統一する\n",
        "X_train_f32 = X_train.astype('float32') # np.float64型 → np.float32型\n",
        "y_train_f32 = y_train.astype('float32') # 同上\n",
        "X_valid_f32 = X_valid.astype('float32') # 同上\n",
        "y_valid_f32 = y_valid.astype('float32') # 同上\n",
        "\n",
        "# 「入力データ（X）」と「教師ラベル（y）」を、1つの「スライスデータセット（TensorSliceDataset）」にまとめる\n",
        "train_sliced = tf.data.Dataset.from_tensor_slices((X_train_f32, y_train_f32)) # 訓練用\n",
        "valid_sliced = tf.data.Dataset.from_tensor_slices((X_valid_f32, y_valid_f32)) # 精度検証用\n",
        "\n",
        "# シャッフルして（訓練データのみ）、ミニバッチ用の「バッチデータセット（BatchDataset）」にする\n",
        "train_dataset = train_sliced.shuffle(250).batch(15)\n",
        "valid_dataset = valid_sliced.batch(15)\n",
        "print(train_dataset)\n",
        "# <BatchDataset shapes: ((None, 2), (None, 1)), types: (tf.float32, tf.float32)> ……などと表示される"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsjJJhMSBOXG",
        "colab_type": "text"
      },
      "source": [
        "### ○学習（1回分）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVwAvwY8qKTn",
        "colab_type": "text"
      },
      "source": [
        "#### リスト4-9-2　1回分の「訓練」と「精度検証」の処理（エキスパート向け）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oohPFGM56Bcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# ###【エキスパート向け】訓練する（1回分） ###\n",
        "@tf.function\n",
        "def train_step(train_X, train_y):\n",
        "  # 訓練モードに設定\n",
        "  training = True\n",
        "  K.set_learning_phase(training)  # tf.keras内部にも伝える\n",
        "\n",
        "  with tf.GradientTape() as tape: # 勾配をテープに記録\n",
        "    # フォワードプロパゲーションで出力結果を取得\n",
        "    #train_X                                   # 入力データ\n",
        "    pred_y = model(train_X, training=training) # 出力結果\n",
        "    #train_y                                   # 正解ラベル\n",
        "\n",
        "    # 出力結果と正解ラベルから損失を計算し、勾配を求める\n",
        "    loss = criterion(pred_y, train_y)     # 誤差（出力結果と正解ラベルの差）から損失を取得\n",
        "  \n",
        "  # 逆伝播の処理として勾配を計算（自動微分）\n",
        "  gradient = tape.gradient(loss, model.trainable_weights)\n",
        "\n",
        "  # 勾配を使ってパラメーター（重みとバイアス）を更新\n",
        "  optimizer.apply_gradients(zip(gradient, model.trainable_weights)) # 指定されたデータ分の最適化を実施\n",
        "\n",
        "  # 損失と正解率を算出して保存\n",
        "  train_loss(loss)\n",
        "  train_accuracy(train_y, pred_y)\n",
        "\n",
        "# ###【エキスパート向け】精度検証する（1回分） ###\n",
        "@tf.function\n",
        "def valid_step(valid_X, valid_y):\n",
        "  # 評価モードに設定（※dropoutなどの挙動が評価用になる）\n",
        "  training = False\n",
        "  K.set_learning_phase(training)  # tf.keras内部にも伝える\n",
        "\n",
        "  # フォワードプロパゲーションで出力結果を取得\n",
        "  #valid_X                                   # 入力データ\n",
        "  pred_y = model(valid_X, training=training) # 出力結果\n",
        "  #valid_y                                   # 正解ラベル\n",
        "\n",
        "  # 出力結果と正解ラベルから損失を計算\n",
        "  loss = criterion(pred_y, valid_y)     # 誤差（出力結果と正解ラベルの差）から損失を取得\n",
        "  # ※評価時は勾配を計算しない\n",
        "\n",
        "  # 損失と正解率を算出して保存\n",
        "  valid_loss(loss)\n",
        "  valid_accuracy(valid_y, pred_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHQN7bp5Bsl5",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### ○学習（ループ処理）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXlnqR3M8HUM",
        "colab_type": "text"
      },
      "source": [
        "#### リスト4-10　「訓練」と「精度検証」をバッチサイズ単位でエポック回繰り返す（エキスパート向け）\n",
        "\n",
        "- 1つ目のforループでエポックを回している\n",
        "  - 2つ目のforループでバッチ単位分のデータを処理に渡している（ミニバッチ処理）\n",
        "    - `train_step`関数で訓練を、`valid_step`関数で評価を1回だけ実行する。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRe0OOsH8a0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 【初中級者向けとの比較用】入力データを指定して学習する\n",
        "# model.fit(\n",
        "#     ……訓練データ（入力）……, ……同（ラベル）……,\n",
        "#     ……精度検証データ……,\n",
        "#     ……バッチサイズ……,\n",
        "#     epochs=100,  # エポック数\n",
        "#     verbose=1)   # 実行状況の出力モード\n",
        "\n",
        "# ###【エキスパート向け】学習する ###\n",
        "\n",
        "# 定数（学習／評価時に必要となるもの）\n",
        "EPOCHS = 100             # エポック数： 100\n",
        "\n",
        "# 損失の履歴を保存するための変数\n",
        "train_history = []\n",
        "valid_history = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  # エポックのたびに、メトリクスの値をリセット\n",
        "  train_loss.reset_states()      # 「訓練」時における累計「損失値」\n",
        "  train_accuracy.reset_states()  # 「訓練」時における累計「正解率」\n",
        "  valid_loss.reset_states()      # 「評価」時における累計「損失値」\n",
        "  valid_accuracy.reset_states()  # 「評価」時における累計「正解率」\n",
        "\n",
        "  for train_X, train_y in train_dataset:\n",
        "    # 【重要】1ミニバッチ分の「訓練（学習）」を実行\n",
        "    train_step(train_X, train_y)\n",
        "          \n",
        "  for valid_X, valid_y in valid_dataset:\n",
        "    # 【重要】1ミニバッチ分の「評価（精度検証）」を実行\n",
        "    valid_step(valid_X, valid_y)\n",
        "\n",
        "  # ミニバッチ単位で累計してきた損失値や正解率の平均を取る\n",
        "  n = epoch + 1                          # 処理済みのエポック数\n",
        "  avg_loss = train_loss.result()         # 訓練用の平均損失値\n",
        "  avg_acc = train_accuracy.result()      # 訓練用の平均正解率\n",
        "  avg_val_loss = valid_loss.result()     # 訓練用の平均損失値\n",
        "  avg_val_acc = valid_accuracy.result()  # 訓練用の平均正解率\n",
        "\n",
        "  # グラフ描画のために損失の履歴を保存する\n",
        "  train_history.append(avg_loss)\n",
        "  valid_history.append(avg_val_loss)\n",
        "\n",
        "  # 損失や正解率などの情報を表示\n",
        "  print(f'[Epoch {n:3d}/{EPOCHS:3d}]' \\\n",
        "        f' loss: {avg_loss:.5f}, acc: {avg_acc:.5f}' \\\n",
        "        f' val_loss: {avg_val_loss:.5f}, val_acc: {avg_val_acc:.5f}')\n",
        "\n",
        "print('Finished Training')\n",
        "print(model.get_weights())  # 学習後のパラメーターの情報を表示"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNSxUIoVCG62",
        "colab_type": "text"
      },
      "source": [
        "### ○評価"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2ndQOZR8mHI",
        "colab_type": "text"
      },
      "source": [
        "#### リスト4-11　損失値の推移グラフ描画"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clgJCTeg8p1e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 学習結果（損失）のグラフを描画\n",
        "epochs = len(train_history)\n",
        "plt.plot(range(epochs), train_history, marker='.', label='loss (Training data)')\n",
        "plt.plot(range(epochs), valid_history, marker='.', label='loss (Validation data)')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HRf00Vc6C4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 次に進む前にモデルをリセット\n",
        "tf.keras.backend.clear_session() # グラフを破棄する\n",
        "del model                        # 変数を削除する"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLF5583Ob2Ja",
        "colab_type": "text"
      },
      "source": [
        "（つづく。以下に対応する記事は未公開です。数週間のうちに公開予定です。）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOwQMRH_JFFt",
        "colab_type": "text"
      },
      "source": [
        "# 第6回　カスタマイズするための、TensorFlow 2.0最新の書き方入門（エキスパート向け）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8vNYMDdmdGN",
        "colab_type": "text"
      },
      "source": [
        "## ■（5）TensorFlow低水準APIでカスタム実装［TensorFlow Low-level API］"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GzEBInJ_YpP",
        "colab_type": "text"
      },
      "source": [
        "### ●活性化関数のカスタム実装"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F9IGwb6KPrF",
        "colab_type": "text"
      },
      "source": [
        "活性化関数については、Sequentialモデル（リスト1-1／2-1）では`'tanh'`という文字列を、Functional API（リスト3-1）やSubclassingモデル（リスト4-1）では`tf.keras.layers.Activation`クラスを使用したが、`tf.keras.activations.tanh()`関数や`tf.nn.tanh()`関数を使用することも可能である。TensorFlow 2.xで利用可能な活性化関数（文字列／関数）には主に以下のものがある。\n",
        "- `'sigmoid'`： `tf.keras.activations.sigmoid()`関数\n",
        "- `'hard_sigmoid'`： `tf.keras.activations.hard_sigmoid()`関数\n",
        "- `'tanh'`： `tf.keras.activations.tanh()`関数\n",
        "- `'relu',`： `tf.keras.activations.relu()`関数\n",
        "- `'elu'`： `tf.keras.activations.elu()`関数\n",
        "- `'selu'`： `tf.keras.activations.selu()`関数\n",
        "- `'swish'`： `tf.keras.activations.swish()`関数\n",
        "- `'softsign'`： `tf.keras.activations.softsign()`関数\n",
        "- `'softplus'`： `tf.keras.activations.softplus()`関数\n",
        "- `'softmax'`： `tf.keras.activations.softmax()`関数\n",
        "- `'linear'`： `tf.keras.activations.linear()`関数\n",
        "- `'exponential'`： `tf.keras.activations.exponential()`関数\n",
        "- `tf.nn.sigmoid()`関数\n",
        "- `tf.nn.tanh()`関数\n",
        "- `tf.nn.relu()`関数\n",
        "- `tf.nn.relu6()`関数\n",
        "- `tf.nn.leaky_relu()`関数\n",
        "- `tf.nn.elu()`関数\n",
        "- `tf.nn.selu()`関数\n",
        "- `tf.nn.swish()`関数\n",
        "- `tf.nn.softsign()`関数\n",
        "- `tf.nn.softplus()`関数\n",
        "- `tf.nn.softmax()`関数\n",
        "\n",
        "詳しくは下記のリンク先を参照してほしい。\n",
        "- 詳細：[Module: tf.keras.activations ｜ TensorFlow Core v2.x](https://www.tensorflow.org/api_docs/python/tf/keras/activations)\n",
        "- 詳細：[Module: tf.nn  |  TensorFlow Core v2.x](https://www.tensorflow.org/api_docs/python/tf/nn)\n",
        "- 詳細：[Module: tf.keras.layers.Activation ｜ TensorFlow Core v2.x](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Activation)\n",
        "\n",
        "目的の活性化関数が見つからない場合は、次のようにしてカスタム（独自）のものを作成することが可能だ。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hrh6uq5c_Wc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# カスタムの活性化関数のPython関数を実装\n",
        "def custom_activation(x):\n",
        "    return (tf.exp(x)-tf.exp(-x))/(tf.exp(x)+tf.exp(-x))\n",
        "\n",
        "# # TensorFlow低水準APIではなく、Keras backend APIを使ってもOK\n",
        "# import tensorflow.keras.backend as K\n",
        "# # 上記のインポートを行ったうえで、以下の内容で上記のコードを書き換えるだけ\n",
        "# # 「tf.exp」 → 「K.exp」\n",
        "\n",
        "# カスタムの活性化関数クラスを実装（レイヤーのサブクラス化）\n",
        "# （tf.keras.layers.Activation()の代わり）\n",
        "class CustomActivation(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super(CustomActivation, self).__init__(**kwargs)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return custom_activation(inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef-fOqka_TZP",
        "colab_type": "text"
      },
      "source": [
        "### ●レイヤーのカスタム実装"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E57yr1UgBDS4",
        "colab_type": "text"
      },
      "source": [
        "レイヤーについては、Sequentialモデル／Functional API／Subclassingモデル（リスト1-1／2-1／3-1／4-1）いずれも`tf.keras.layers.Dense`クラスを使用したが、それ以外にも多種多様なものが用意されている。TensorFlow 2.xで利用可能な代表的なレイヤーには以下のものがある。\n",
        "- `Dense`クラス\n",
        "- `Activation`クラス\n",
        "- `Dropout`クラス\n",
        "  - `SpatialDropout1D`クラス\n",
        "  - `SpatialDropout2D`クラス\n",
        "  - `SpatialDropout3D`クラス\n",
        "- `Flatten`クラス\n",
        "- `InputLayer`クラス\n",
        "- `Reshape`クラス\n",
        "- `Permute`クラス\n",
        "- `RepeatVector`クラス\n",
        "- `Lambda`クラス\n",
        "- `ActivityRegularization`クラス\n",
        "- `Masking`クラス\n",
        "\n",
        "詳しくは下記のリンク先を参照してほしい。\n",
        "- 詳細：[Module: tf.keras.layers ｜ TensorFlow Core v2.x](https://www.tensorflow.org/api_docs/python/tf/keras/layers)\n",
        "\n",
        "目的のレイヤーが見つからない場合は、次のようにしてカスタム（独自）のものを作成することが可能だ。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8A4_5YNQEgvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# カスタムの全結合層（線形変換）のPython関数を実装\n",
        "def fully_connected(inputs, weights, bias):\n",
        "  return tf.matmul(inputs, weights) + bias\n",
        "\n",
        "# # TensorFlow低水準APIではなく、Keras backend APIを使ってもOK\n",
        "# import tensorflow.keras.backend as K\n",
        "# # 上記のインポートを行ったうえで、以下の内容で上記のコードを書き換えるだけ\n",
        "# 「tf.matmul」 → 「K.dot」\n",
        "\n",
        "# カスタムのレイヤークラスを実装（レイヤーのサブクラス化）\n",
        "# （tf.keras.layers.Dense()の代わり）\n",
        "class CustomLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, input_dim=None, **kwargs):\n",
        "    self.input_dim = input_dim  # 入力の次元数（＝レイヤーの入力数）\n",
        "    self.units = units          # ニューロン数（＝レイヤーの出力数）\n",
        "    super(CustomLayer, self).__init__(**kwargs)\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    #print(input_shape) # 入力形状。例えば「(2, 2)」＝2行2列なら入力の次元数は2列\n",
        "    input_data_dim = input_shape[-1] # 入力の次元数（＝レイヤーの入力数）\n",
        "\n",
        "    # 入力の次元数をチェック（デバッグ）\n",
        "    if self.input_dim != None:\n",
        "      assert input_data_dim == self.input_dim  # 指定された入力次元数と実際の入力次元数が異なります\n",
        "\n",
        "    # 重みにを追加する\n",
        "    self.kernel = self.add_weight(\n",
        "        shape=(input_data_dim, self.units),\n",
        "        name='kernel',\n",
        "        initializer='glorot_uniform',  # リスト1-3のような独自の関数も指定できる\n",
        "        trainable=True)\n",
        "\n",
        "    # バイアスを追加する\n",
        "    self.bias = self.add_weight(\n",
        "        shape=(self.units,),\n",
        "        name='bias',\n",
        "        initializer='zeros',\n",
        "        trainable=True)\n",
        "    \n",
        "    #self.built = True # Layerクラスでビルド済みどうかを管理するのに使われている（なくても大きな問題はない）\n",
        "    super(CustomLayer, self).build(input_shape) # 上と同じ意味。APIドキュメントで推奨されている書き方\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return fully_connected(inputs, self.kernel, self.bias)\n",
        "\n",
        "  # # for Keras to do automatic shape inference.\n",
        "  # def compute_output_shape(self, input_shape): # 純正Kerasは実装をするとよみみたいだが、tf.kerasでは呼ばれないようなので実装しなくてよい. tensorflow側のチュートリアルでは記載されていない\n",
        "  #   # [The inheriting keras.layers.Layer does not call a compute_output_shape after switching to tf.keras from keras · Issue #33785 · tensorflow/tensorflow](https://github.com/tensorflow/tensorflow/issues/33785)\n",
        "  #   #   print(input_shape)\n",
        "  #   return (input_shape[0], self.units) # （データの行数=None、出力ユニット数）一応実装\n",
        "  #   # 作成したレイヤーの内部で入力から出力でshapeを変更する場合には，ここでshape変換のロジックを指定する必要があります．こうすることでKerasが自動的にshapeを推定します．\n",
        "  # tf.kerasでは理由は明確には分からないが実装すべきメソッドとしては挙げられていない（compute_output_shape）"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46kCMuuv_QIw",
        "colab_type": "text"
      },
      "source": [
        "### ●オプティマイザ（最適化アルゴリズム）のカスタム実装"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_FMXwnEAfpQ",
        "colab_type": "text"
      },
      "source": [
        "- `tf.optimizers`はエイリアスで`tf.keras.optimizers`を指す\n",
        "\n",
        "オプティマイザ（最適化アルゴリズム）については、Sequentialモデル／Functional API／Subclassingモデル（リスト1-1／2-1／3-1／4-1）いずれも`tf.keras.optimizers.SGD`クラスを使用したが、それ以外にも用意されている。TensorFlow 2.xで利用可能な代表的なオプティマイザには以下のものがある。\n",
        "- `SGD`クラス（確率的勾配降下法）\n",
        "- `RMSprop`クラス\n",
        "- `Adagrad`クラス\n",
        "- `Adadelta`クラス\n",
        "- `Adam`クラス\n",
        "- `Adamax`クラス\n",
        "- `Nadam`クラス\n",
        "- `Ftrl`クラス\n",
        "\n",
        "詳しくは下記のリンク先を参照してほしい。\n",
        "- [Module: tf.keras.optimizers ｜ TensorFlow Core v2.x](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers)\n",
        "\n",
        "目的のオプティマイザが見つからない場合は、次のようにしてカスタム（独自）のものを作成することが可能だ。ただし簡単ではないので、説明は割愛する。基本的には、「[tensorflow/gradient_descent.py at master · tensorflow/tensorflow](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/optimizer_v2/gradient_descent.py)」をまねればよい。以下のコードも、SGDのコードを参考にして作ったものである。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeEQS3vf_mym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.optimizer_v2 import optimizer_v2\n",
        "from tensorflow.python.ops import resource_variable_ops\n",
        "from tensorflow.python.training import training_ops\n",
        "\n",
        "# カスタムの最適化アルゴリズムクラスを実装（オプティマイザのサブクラス化）\n",
        "# （tf.keras.optimizers.SGDの代わり）\n",
        "class CustomOptimizer(optimizer_v2.OptimizerV2):\n",
        "  def __init__(self, learning_rate=0.01, name=\"CustomOptimizer\", **kwargs):\n",
        "    super(CustomOptimizer, self).__init__(name, **kwargs)\n",
        "    self._set_hyper(\"learning_rate\", kwargs.get(\"lr\", learning_rate))\n",
        "\n",
        "  def _create_slots(self, var_list):\n",
        "    pass\n",
        "\n",
        "  def _prepare_local(self, var_device, var_dtype, apply_state):\n",
        "    super(CustomOptimizer, self)._prepare_local(var_device, var_dtype, apply_state)\n",
        "\n",
        "  def _resource_apply_dense(self, grad, var, apply_state=None):\n",
        "    var_device, var_dtype = var.device, var.dtype.base_dtype\n",
        "    coefficients = ((apply_state or {}).get((var_device, var_dtype))\n",
        "                    or self._fallback_apply_state(var_device, var_dtype))\n",
        "    return training_ops.resource_apply_gradient_descent(\n",
        "        var.handle, coefficients[\"lr_t\"], grad, use_locking=self._use_locking)\n",
        "\n",
        "  def _resource_apply_sparse_duplicate_indices(self, grad, var, indices, **kwargs):\n",
        "    var_device, var_dtype = var.device, var.dtype.base_dtype\n",
        "    coefficients = (kwargs.get(\"apply_state\", {}).get((var_device, var_dtype))\n",
        "                    or self._fallback_apply_state(var_device, var_dtype))\n",
        "    return resource_variable_ops.resource_scatter_add(\n",
        "        var.handle, indices, -grad * coefficients[\"lr_t\"])\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super(CustomOptimizer, self).get_config()\n",
        "    config.update({\n",
        "        \"learning_rate\": self._serialize_hyperparameter(\"learning_rate\")\n",
        "    })\n",
        "    return config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWWDrSIs_OBj",
        "colab_type": "text"
      },
      "source": [
        "### ●損失関数の定義のカスタム実装"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnGO6TgSAkXr",
        "colab_type": "text"
      },
      "source": [
        "- `tf.losses`はエイリアスで`tf.keras.losses`を指す\n",
        "\n",
        "損失関数については、初中級者向け（リスト1-1／2-1／3-1）では`'mean_squared_error'`という文字列を、エキスパート向け（リスト4-1）では`tf.keras.losses.MeanSquaredError`クラスを使用したが、`mean_squared_error()`関数を使用することも可能である。TensorFlow 2.xで利用可能な損失関数（文字列／関数／クラス）には主に以下のものがある。\n",
        "- `MeanSquaredError`クラス（略記：`MSE`）： `mean_squared_error()`関数\n",
        "- `MeanAbsoluteError`クラス（略記：`MAE`）： `mean_absolute_error()`関数\n",
        "- `MeanAbsolutePercentageError`クラス（略記：`MAPE`）： `mean_absolute_percentage_error()`関数\n",
        "- `MeanSquaredLogarithmicError`クラス（略記：`MSLE`）： `mean_squared_logarithmic_error()`関数\n",
        "- `SquaredHinge`クラス： `squared_hinge()`関数\n",
        "- `Hinge`クラス： `hinge()`関数\n",
        "- `CategoricalHinge`クラス： `categorical_hinge()`関数\n",
        "- `LogCosh`クラス： `logcosh()`関数\n",
        "- `Huber`クラス： `huber_loss()`関数\n",
        "- `CategoricalCrossentropy`クラス： `categorical_crossentropy()`関数\n",
        "- `SparseCategoricalCrossentropy`クラス： `sparse_categorical_crossentropy()`関数\n",
        "- `BinaryCrossentropy`クラス： `binary_crossentropy()`関数\n",
        "- `KLDivergence`クラス（略記：`KLD`）： `kullback_leibler_divergence()`関数\n",
        "- `Poisson`クラス： `poisson()`関数\n",
        "- `CosineSimilarity`クラス： `cosine_proximity()`関数\n",
        "\n",
        "詳しくは下記のリンク先を参照してほしい。\n",
        "- 詳細： [Module: tf.keras.losses ｜ TensorFlow Core v2.x](https://www.tensorflow.org/api_docs/python/tf/keras/losses)\n",
        "\n",
        "目的の損失関数が見つからない場合は、次のようにしてカスタム（独自）のものを作成することが可能だ。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTckK4xpOW1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# カスタムの損失関数のPython関数を実装\n",
        "def custom_loss(y_true, y_pred):\n",
        "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
        "\n",
        "# # TensorFlow低水準APIではなく、Keras backend APIを使ってもOK\n",
        "# import tensorflow.keras.backend as K\n",
        "# # 上記のインポートを行ったうえで、以下の内容で上記のコードを書き換えるだけ\n",
        "# # 「tf.reduce_mean」 → 「K.mean」\n",
        "# # 「tf.square」 → 「K.square」\n",
        "\n",
        "# カスタムの損失関数クラスを実装（レイヤーのサブクラス化）\n",
        "# （tf.keras.losses.MeanSquaredError()の代わり）\n",
        "class Customloss(tf.keras.losses.Loss):\n",
        "  def __init__(self, name=\"custom_loss\", **kwargs):\n",
        "    super(Customloss, self).__init__(name=name, **kwargs)\n",
        "\n",
        "  def call(self, y_true, y_pred):\n",
        "    y_pred = tf.convert_to_tensor(y_pred)  # 念のためTensor化\n",
        "    y_true = tf.cast(y_true, y_pred.dtype) # 念のため同じデータ型化\n",
        "    return custom_loss(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oeq_54m384nl",
        "colab_type": "text"
      },
      "source": [
        "### ●評価関数（正解率や損失）のカスタム実装"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0XslFegAnst",
        "colab_type": "text"
      },
      "source": [
        "- `tf.metrics`はエイリアスで`tf.keras.metrics`を指す\n",
        "\n",
        "評価関数については、初中級者向け（リスト1-1／2-1／3-1）では独自の`tanh_accuracy`関数を、エキスパート向け（リスト4-1）では`tf.keras.metrics.Mean`クラスなどを使用したが、`'binary_accuracy'`文字列や`binary_accuracy()`関数を使用することも可能である。TensorFlow 2.xで利用可能な評価関数（文字列／関数／クラス）には主に以下のものがある。\n",
        "- `Accuracy`クラス： `accuracy()`関数\n",
        "- `BinaryAccuracy`クラス： `binary_accuracy()`関数\n",
        "- `CategoricalAccuracy`クラス： `categorical_accuracy()`関数\n",
        "- `SparseCategoricalAccuracy`クラス： `sparse_categorical_accuracy()`関数\n",
        "- `TopKCategoricalAccuracy`クラス： `top_k_categorical_accuracy()`関数\n",
        "- `SparseTopKCategoricalAccuracy`クラス： `sparse_top_k_categorical_accuracy()`関数\n",
        "- `FalsePositives`クラス\n",
        "- `FalseNegatives`クラス\n",
        "- `TrueNegatives`クラス\n",
        "- `TruePositives`クラス\n",
        "- `Precision`クラス\n",
        "- `Recall`クラス\n",
        "- `SensitivityAtSpecificity`クラス\n",
        "- `SpecificityAtSensitivity`クラス\n",
        "- `PrecisionAtRecall`クラス\n",
        "- `AUC`クラス\n",
        "\n",
        "詳しくは下記のリンク先を参照してほしい。\n",
        "- 詳細：[Module: tf.keras.metrics ｜ TensorFlow Core v2.x](https://www.tensorflow.org/api_docs/python/tf/keras/metrics)\n",
        "\n",
        "目的の評価関数が見つからない場合は、次のようにしてカスタム（独自）のものを作成することが可能だ。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlhFd3qY4l4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 正解かどうかを判定する関数を実装\n",
        "def custom_matches(y_true, y_pred):         # y_trueは正解、y_predは予測（出力）\n",
        "  threshold = tf.cast(0.0, y_pred.dtype)              # -1か1かを分ける閾値を作成\n",
        "  y_pred = tf.cast(y_pred >= threshold, y_pred.dtype) # 閾値未満で0、以上で1に変換\n",
        "  # 2倍して-1.0することで、0／1を-1.0／1.0にスケール変換して正解率を計算\n",
        "  return tf.equal(y_true, y_pred * 2 - 1.0) # 正解かどうかのデータ（平均はしていない）\n",
        "\n",
        "# # TensorFlow低水準APIではなく、Keras backend APIを使ってもOK\n",
        "# import tensorflow.keras.backend as K\n",
        "# # 上記のインポートを行ったうえで、以下の内容で上記のコードを書き換えるだけ\n",
        "# 「tf.cast」 → 「K.cast」\n",
        "# 「tf.equal」 → 「K.equal」\n",
        "\n",
        "# カスタムの評価関数クラスを実装（サブクラス化）\n",
        "# （tf.keras.metrics.BinaryAccuracy()の代わり）\n",
        "class CustomAccuracy(tf.keras.metrics.Mean):\n",
        "  def __init__(self, name='custom_accuracy', dtype=None):\n",
        "    super(CustomAccuracy, self).__init__(name, dtype)\n",
        "\n",
        "  # 正解率の状態を更新する際に呼び出される関数をカスタマイズ\n",
        "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "    matches = custom_matches(y_true, y_pred)\n",
        "    return super(CustomAccuracy, self).update_state(\n",
        "        matches, sample_weight=sample_weight) # ※平均は内部で自動的に取ってくれる"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8f3Om_Z86ZR",
        "colab_type": "text"
      },
      "source": [
        "### ●ここまでのカスタム実装の使用例"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJPPvWyjw2uo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 活性化関数の定義\n",
        "activation1 = CustomActivation(name='activation1')\n",
        "activation2 = CustomActivation(name='activation2')\n",
        "acti_out = layers.Activation('tanh', name='acti_out')\n",
        "\n",
        "# モデルの設計\n",
        "class NeuralNetwork(tf.keras.Model):\n",
        "  def __init__(self, *args, **kwargs):\n",
        "    super(NeuralNetwork, self).__init__(*args, **kwargs)\n",
        "    self.layer1 = CustomLayer(units=LAYER1_NEURONS, name='layer1')\n",
        "    self.layer2 = CustomLayer(units=LAYER2_NEURONS, name='layer2')\n",
        "    self.layer_out = CustomLayer(units=OUTPUT_RESULTS, name='layer_out')\n",
        "  def call(self, inputs, training=None):\n",
        "    x1 = activation1(self.layer1(inputs))\n",
        "    x2 = activation2(self.layer2(x1))\n",
        "    outputs = acti_out(self.layer_out(x2))\n",
        "    return outputs\n",
        "\n",
        "# モデルの生成\n",
        "model = NeuralNetwork()\n",
        "\n",
        "# モデルの概要と構成図の出力\n",
        "def get_functional_model(model):\n",
        "  x = layers.Input(shape=(INPUT_FEATURES,), name='layer_in')\n",
        "  temp_model = tf.keras.Model(inputs=[x], outputs=model.call(x), name='cusotm_model')\n",
        "  return temp_model\n",
        "f_model = get_functional_model(model)\n",
        "f_model.summary()\n",
        "tf.keras.utils.plot_model(f_model, show_shapes=True, show_layer_names=True, to_file='model.png')\n",
        "from IPython.display import Image\n",
        "Image(retina=False, filename='model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEG1DQNRzWbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 最適化アルゴリズムと損失関数の定義\n",
        "optimizer = CustomOptimizer(learning_rate=0.03)\n",
        "criterion = Customloss()\n",
        "\n",
        "# 評価関数（損失と正解率）の定義\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = CustomAccuracy(name='train_accuracy')\n",
        "valid_loss = tf.keras.metrics.Mean(name='valid_loss')\n",
        "valid_accuracy = CustomAccuracy(name='valid_accuracy')\n",
        "\n",
        "# ミニバッチ用データの準備\n",
        "X_train_f32 = X_train.astype('float32')\n",
        "y_train_f32 = y_train.astype('float32')\n",
        "X_valid_f32 = X_valid.astype('float32')\n",
        "y_valid_f32 = y_valid.astype('float32')\n",
        "train_sliced = tf.data.Dataset.from_tensor_slices((X_train_f32, y_train_f32)) # 訓練用\n",
        "valid_sliced = tf.data.Dataset.from_tensor_slices((X_valid_f32, y_valid_f32)) # 精度検証用\n",
        "train_dataset = train_sliced.shuffle(60000).batch(15)\n",
        "valid_dataset = valid_sliced.batch(15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K-mMJjbxf0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# 1回分の訓練（学習）の処理\n",
        "@tf.function\n",
        "def train_step(train_X, train_y):\n",
        "  training = True\n",
        "  K.set_learning_phase(training)\n",
        "  with tf.GradientTape() as tape:\n",
        "    pred_y = model(train_X, training=training)\n",
        "    loss = criterion(pred_y, train_y)\n",
        "  gradient = tape.gradient(loss, model.trainable_weights)\n",
        "  optimizer.apply_gradients(zip(gradient, model.trainable_weights))\n",
        "  train_loss(loss)\n",
        "  train_accuracy(train_y, pred_y)\n",
        "\n",
        "# 1回分の精度検証（評価）の処理\n",
        "@tf.function\n",
        "def valid_step(valid_X, valid_y):\n",
        "  training = False\n",
        "  K.set_learning_phase(training)\n",
        "  pred_y = model(valid_X, training=training)\n",
        "  loss = criterion(pred_y, valid_y)\n",
        "  valid_loss(loss)\n",
        "  valid_accuracy(valid_y, pred_y)\n",
        "\n",
        "# エポック数分、訓練（学習）と精度検証（評価）を実行\n",
        "EPOCHS = 100\n",
        "train_history = []\n",
        "valid_history = []\n",
        "for epoch in range(EPOCHS):\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  valid_loss.reset_states()\n",
        "  valid_accuracy.reset_states()\n",
        "  for train_X, train_y in train_dataset:\n",
        "    train_step(train_X, train_y)\n",
        "  for valid_X, valid_y in valid_dataset:\n",
        "    valid_step(valid_X, valid_y)   \n",
        "  n = epoch + 1\n",
        "  avg_loss = train_loss.result()\n",
        "  avg_acc = train_accuracy.result()\n",
        "  avg_val_loss = valid_loss.result()\n",
        "  avg_val_acc = valid_accuracy.result()\n",
        "  train_history.append(avg_loss)\n",
        "  valid_history.append(avg_val_loss)\n",
        "  print(f'[Epoch {epoch+1:3d}/{EPOCHS:3d}]' \\\n",
        "        f' loss: {avg_loss:.5f}, acc: {avg_acc:.5f}' \\\n",
        "        f' val_loss: {avg_val_loss:.5f}, val_acc: {avg_val_acc:.5f}')\n",
        "print('Finished Training')\n",
        "print(model.get_weights())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHyZtz1lzsCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 学習結果（損失）のグラフを描画\n",
        "import matplotlib.pyplot as plt\n",
        "epochs = len(train_history)\n",
        "plt.plot(range(epochs), train_history, marker='.', label='loss (Training data)')\n",
        "plt.plot(range(epochs), valid_history, marker='.', label='loss (Validation data)')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnIoLyr35QAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 推論\n",
        "model(tf.constant([[0.1,-0.2]]))\n",
        "# <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.88659185]], dtype=float32)> ……などと表示される"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3b2hxaBoqji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 次に進む前にモデルをリセット\n",
        "tf.keras.backend.clear_session() # グラフを破棄する\n",
        "del model                        # 変数を削除する"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMqECIcuSCze",
        "colab_type": "text"
      },
      "source": [
        "## ■（6）作成済みEstimatorsの利用［tf.estimator］（※互換性のためで非推奨）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_U8_OVmU5_T",
        "colab_type": "text"
      },
      "source": [
        "「作成済みEstimators（Premade Estimators）」ファミリーの中では、以下はTensorFlow 2.0 APIでサポートされている。\n",
        "\n",
        "- `tf.estimator.LinearClassifier`： 線形モデル（分類用）\n",
        "- `tf.estimator.LinearRegressor`： 線形モデル（回帰用）\n",
        "- `tf.estimator.DNNClassifier`：ニューラルネットワークモデル（分類用）\n",
        "- `tf.estimator.DNNRegressor`：ニューラルネットワークモデル（回帰用）\n",
        "- `tf.estimator.DNNLinearCombinedClassifier`：ニューラルネットワークと線形の結合モデル（分類）\n",
        "- `tf.estimator.DNNLinearCombinedRegressor`：ニューラルネットワークと線形の結合モデル（回帰）\n",
        "\n",
        "この中で有用なのは、`DNNClassifier`と`DNNRegressor`の2つである。\n",
        "\n",
        "なお、結合モデルとは、線形モデル（Wideモデル）とニューラルネットワークモデル（Deepモデル）を結合させた**Wide＆Deepモデル**のことでである（詳しくは「[Google AI Blog: Wide & Deep Learning: Better Together with TensorFlow](https://ai.googleblog.com/2016/06/wide-deep-learning-better-together-with.html)」を参照してほしい）。\n",
        "\n",
        "tf.estimatorは、TensorFlow 2.x（2.0以降）でもサポートされているものの、TensorFlow 1.xからの移行用として残されている。将来的に廃止／削除される可能性は非常に高いと思われるので（※筆者の確認によると、実際に、コードが2019年8月以来、何も変更されずに放置されているようだった）、「基本的に使わない方がよい」だろう。公式ドキュメントでも、新規開発であればtf.keras（TensorFlow＋Keras）を使うことが推奨されている。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEzRO3jrVEWH",
        "colab_type": "text"
      },
      "source": [
        "ここでは、あくまで「Estimatorのコードを見たときに戸惑わない」ように、知識としてコードを紹介するにとどめる。コードの書き方も、あまり洗練されておらず、面倒くさい（と筆者は感じた）。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd6QXBrxYy8W",
        "colab_type": "text"
      },
      "source": [
        "### リスト6-1　データの準備（Pandasのデータフレーム）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsdaf26pY4bf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 列名を指定するため、ライブラリ「Pandas」のデータフレーム化\n",
        "import pandas as pd\n",
        "train_X = pd.DataFrame(X_train.astype('float32'), columns=['x', 'y'])\n",
        "train_y = pd.DataFrame(y_train.astype('float32'))\n",
        "valid_X = pd.DataFrame(X_valid.astype('float32'), columns=['x', 'y'])\n",
        "valid_y = pd.DataFrame(y_valid.astype('float32'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBLrPgkHb50O",
        "colab_type": "text"
      },
      "source": [
        "データは、訓練データ（`train`）と精度検証データ（`valid`＝評価）の2つに分割されており、それぞれ入力（＝特徴）データ（$X$：行列）とラベル（$y$：ベクトル）がある。これらを32bitの浮動小数点数値（float32）に変えた上で、データ解析支援ライブラリ「Pandas」のデータフレームにしている。`columns=['x', 'y']`引数は、列名として「x」と「y」（X座標とY座標）を指定している。わざわざPandasを使っている理由は、この列名指定が簡単であるのと、`tf.data`がPandasに対応しているからである。ちなみに`tf.data`は、前掲の「TensorFlowのエコシステム／機能構成図」にあるように、TensorFlow 2.x時代のデータ管理機能である。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEJoGm20bHM0",
        "colab_type": "text"
      },
      "source": [
        "### リスト6-2　Feature columns（フィーチャーカラム）の作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BI6ozcETbFNs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 先ほどの列名を使って、フィーチャーカラムのリスト値を作成\n",
        "my_feature_columns = []\n",
        "for key in train_X.keys():\n",
        "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
        "\n",
        "my_feature_columns\n",
        "# [NumericColumn(key='x', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
        "#  NumericColumn(key='y', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]  ……などと表示される"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWbRI1ydefJc",
        "colab_type": "text"
      },
      "source": [
        "Feature columns（フィーチャーカラム：特徴の列項目）は、ニューラルネットワークに入力する特徴データ（行列データ）における個々の列データを意味する。特徴は必ずしも連続的な数値とは限らない。具体的にはカテゴリ値、ハッシュ化値など他にも考えられる。フィーチャーカラムは、こういったさまざまな特徴データが取り扱える機能となっている。元々はtf.estimatorの機能であったが、tf.dataとともにTensorFlow 2.xの基本機能に取り込まれており、Kerasでも活用できる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyYBpcckbIFj",
        "colab_type": "text"
      },
      "source": [
        "### リスト6-3　作成済みEstimatorsを利用した書き方"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saFlIpy8bFqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 学習時のログ保存ディレクトリのパス名を定義\n",
        "import datetime\n",
        "current_time = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
        "train_log_dir = 'logs/estimator/' + current_time + '/train'\n",
        "\n",
        "# ハイパーパラメーターとなる変数（モデル定義時に必要となる数値） \n",
        "# ### 活性化関数（隠れ層用）の定義 ###\n",
        "activation = tf.nn.tanh # 活性化関数（隠れ層用）： tanh関数（変更可能）\n",
        "                        # 全レイヤーで共通。指定しない場合は「tf.nn.relu」\n",
        "# ### 活性化関数（出力用）は指定できない ###\n",
        "# 回帰（DNNRegressor）の場合、線形（Linear）関数（＝確率値のまま）\n",
        "# 分類（DNNClassifier）の場合、ソフトマックス（Softmax）関数\n",
        "\n",
        "# ### 損失関数も指定できない ###\n",
        "# 回帰（DNNRegressor）の場合、平均二乗誤差（Mean Squared Error）\n",
        "# 分類（DNNClassifier）の場合、交差エントロピー誤差（Cross Entropy）\n",
        "\n",
        "# ### 最適化アルゴリズムの定義 ###\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.03) # SGDで、学習率は0.03\n",
        "\n",
        "# モデルの設計\n",
        "model = tf.estimator.DNNRegressor(      # モデルの生成\n",
        "\n",
        "    # ### レイヤーを定義 ###\n",
        "    feature_columns=my_feature_columns, # 入力層\n",
        "    hidden_units=[                      # 隠れ層\n",
        "        LAYER1_NEURONS,  # 隠れ層：1つ目のレイヤー\n",
        "        LAYER2_NEURONS,  # 隠れ層：2つ目のレイヤー\n",
        "        OUTPUT_RESULTS],                # 出力層\n",
        "\n",
        "    activation_fn=activation,  # 活性化関数 \n",
        "                               # 損失関数は指定できない\n",
        "    optimizer=optimizer,       # 最適化  \n",
        "    model_dir=train_log_dir)   # 学習時のログ保存ディレクトリ"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGBehlkhlwsa",
        "colab_type": "text"
      },
      "source": [
        "### ●学習と推論： 書き方入門（tf.estimator専用）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqw0WVX4l-EC",
        "colab_type": "text"
      },
      "source": [
        "### リスト6-4　学習、精度検証（＝評価）するコード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GNR1RMol85j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# データの入力は「入力関数」として定義する必要がある\n",
        "def input_fn(features_X, labels_y, training=True, batch_size=15):\n",
        "  # 特徴データとラベルをtf.dataのデータセットとしてまとめる\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((dict(features_X), labels_y))\n",
        "\n",
        "  # 訓練時のみ、データセットをシャッフルする\n",
        "  if training:\n",
        "      dataset = dataset.shuffle(250, reshuffle_each_iteration=True).repeat()\n",
        "  # 精度検証（＝評価）時は、シャッフル不要\n",
        "  \n",
        "  # バッチサイズ分だけ返す\n",
        "  return dataset.batch(batch_size)\n",
        "\n",
        "# 学習前にログを空にする\n",
        "!rm -rf ./logs/\n",
        "\n",
        "# 学習する（＝モデルを訓練する）\n",
        "model.train(\n",
        "    input_fn=lambda: input_fn(train_X, train_y, training=True), # データ入力\n",
        "    steps=int(250/15)*100) # データ件数「250」／バッチサイズ「15」×「100」エポック＝「1600」ステップ\n",
        "\n",
        "# 評価する（＝モデルの精度を検証する）\n",
        "model.evaluate(\n",
        "    input_fn=lambda: input_fn(valid_X, valid_y, training=False))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcntYBSfnmg4",
        "colab_type": "text"
      },
      "source": [
        "`input_fn()`関数の`training`引数は、訓練時か精度検証（＝評価）時かで処理を分岐できるようにするために追加した独自のパラメーターである。引数`batch_size`はバッチサイズを指定できるようにしたもので、デフォルト値を**15**としている。\n",
        "tf.dataのデータセットを作成する場合は、`tf.data.Dataset.from_tensor_slices`メソッドを呼び出せばよい。tf.dataのデータセット（Datasetオブジェクト）は、Pythonイテラブルであり、Pythonイテレーションを通じてエポックを作成することができるというメリットがある。\n",
        "\n",
        "そのデータセットの`shuffle()`メソッドに指定している**250**は、バッファサイズである。バッファサイズは、データ件数以上を指定しないと完全にシャッフルできないので、今回はデータ件数である**250**を指定した。引数`reshuffle_each_iteration`はデータセットの末尾まで来たら再度シャッフルするかどうかを指定している。引数なしの`repeat()`メソッドにより、データセットは最後まで来ると再スタートして、無限に繰り返されるようになる。この書き方は、TensorFlow 1.x時代のtd.dataのエポック作成方法である。TensorFlow 2.x時代は`repeat()`せずにforループで回すのが一般的な書き方である。\n",
        "\n",
        "生成したモデルの`train()`／`evaluate()`メソッドの引数`input_fn`には、先ほど作成した`input_fn()`関数を指定するわけだが、`input_fn()`関数そのものは引数によって挙動をカスタマイズできるようにしているので、ラムダ（lambda）による匿名関数を作って、それを引数`input_fn`に指定している。ラムダ関数の中は、学習時と精度評価時で引数を変えて`input_fn()`関数を呼び出している。こうすることでコードを書く量を減らしている。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnaU2eSdm1VL",
        "colab_type": "text"
      },
      "source": [
        "### リスト6-5　テスト、推論（予測）するコード（共通）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0GVZ7BtbAgu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_fn(features, batch_size=15):\n",
        "  # ※テスト時はシャッフル不要\n",
        "  return tf.data.Dataset.from_tensor_slices(features).batch(batch_size)\n",
        "\n",
        "list(model.predict(input_fn=lambda: test_fn({ 'x': [0.1], 'y': [-0.2] })))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Fs9Wt-q7Yaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 次に進む前にモデルをリセット\n",
        "tf.keras.backend.clear_session() # グラフを破棄する\n",
        "del model                        # 変数を削除する"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJSe9Kgh_vGt",
        "colab_type": "text"
      },
      "source": [
        "# お疲れさまでした。『TensorFlow 2.0最新の書き方入門』は修了です。"
      ]
    }
  ]
}