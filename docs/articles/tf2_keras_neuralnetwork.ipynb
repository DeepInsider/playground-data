{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf2-keras-neuralnetwork.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeepInsider/playground-data/blob/master/docs/articles/tf2_keras_neuralnetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZhsEJSQM7Jh",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4JztMOxNIvu",
        "colab_type": "text"
      },
      "source": [
        "# 「ニューラルネットワーク ― 仕組みの理解×初めての実装（全3回）」 ― 連載『TensorFlow 2.0＋Keras（ tf.keras）入門』のノートブック"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FteEuY5_NVhO",
        "colab_type": "text"
      },
      "source": [
        "<table valign=\"middle\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.atmarkit.co.jp/ait/subtop/features/di/tf2keras_index.html\"> <img src=\"https://re.deepinsider.jp/img/ml-logo/manabu.svg\"/>Deep Insiderで記事を読む</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/DeepInsider/playground-data/blob/master/docs/articles/tf2_keras_neuralnetwork.ipynb\"> <img src=\"https://re.deepinsider.jp/img/ml-logo/gcolab.svg\" />Google Colabで実行する</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/DeepInsider/playground-data/blob/master/docs/articles/tf2_keras_neuralnetwork.ipynb\"> <img src=\"https://re.deepinsider.jp/img/ml-logo/github.svg\" />GitHubでソースコードを見る</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ueKLtX95oVW",
        "colab_type": "text"
      },
      "source": [
        "# 第1回　初めてのニューラルネットワーク実装の準備をしよう ― 仕組み理解×初実装（前編）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzMyXEPUNmKU",
        "colab_type": "text"
      },
      "source": [
        "## ■ディープラーニングの大まかな流れ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFOYuPJ6Ngnu",
        "colab_type": "text"
      },
      "source": [
        "- （1）データ準備\n",
        "- （2）問題種別\n",
        "- （3）前処理\n",
        "- （4）“手法” の選択： モデルの定義\n",
        "- （5）“学習方法” の設計： モデルの生成\n",
        "- （6）学習 ： トレーニング\n",
        "- （7）評価\n",
        "- （8）テスト"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlVhlTU3N17D",
        "colab_type": "text"
      },
      "source": [
        "## ■（1）データ準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMboLmdvjYaq",
        "colab_type": "text"
      },
      "source": [
        "### 【チェック】Pythonバージョン（※3系を使うこと）\n",
        "Colabにインストール済みのものを使う。もし2系になっている場合は、メニューバーの［ランタイム］－［ランタイムのタイプを変更］をクリックして切り替えてほしい。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SziRZWCujWXN",
        "colab_type": "code",
        "outputId": "a3fa49e6-7ad6-4d1b-f22a-6e4a78f6d24c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import sys\n",
        "print('Python', sys.version)\n",
        "# Python 3.6.8 (default, Jan 14 2019, 11:02:34) …… などと表示される"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.9 (default, Nov  7 2019, 10:44:02) \n",
            "[GCC 8.3.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2fU5kIiRher",
        "colab_type": "text"
      },
      "source": [
        "### リスト1　座標点データを生成するライブラリのインストール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnL886VJR-HB",
        "colab_type": "code",
        "outputId": "48ae5e18-461a-4a32-fdeb-41cc403ab1ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!pip install playground-data"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting playground-data\n",
            "  Downloading https://files.pythonhosted.org/packages/fb/27/9f1497a14c529759421438b25816ec90cf2b34cf6c0146cf29aa4ceee27a/playground-data-1.1.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from playground-data) (1.17.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from playground-data) (3.1.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->playground-data) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->playground-data) (2.6.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->playground-data) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->playground-data) (2.4.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->playground-data) (42.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->playground-data) (1.12.0)\n",
            "Building wheels for collected packages: playground-data\n",
            "  Building wheel for playground-data (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for playground-data: filename=playground_data-1.1.0-py2.py3-none-any.whl size=20827 sha256=5332eb27a88dec46b7bd1a9cee3825e3b5ad5f143f957b6183e09dcd34ee7217\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/07/a9/68dc3f1c2cca3ce57b735854edda3620fb089f3ac64b9acfd4\n",
            "Successfully built playground-data\n",
            "Installing collected packages: playground-data\n",
            "Successfully installed playground-data-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDTRqJ35OhXl",
        "colab_type": "text"
      },
      "source": [
        "## ■（2）問題種別"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqQsWTEPuTQa",
        "colab_type": "text"
      },
      "source": [
        "### リスト2　問題種別とデータ種別の選択"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M_-s3ooRmVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# playground-dataライブラリのplygdataパッケージを「pg」という別名でインポート\n",
        "import plygdata as pg\n",
        "\n",
        "# 問題種別で「分類（Classification）」を選択し、\n",
        "# データ種別で「2つのガウシアンデータ（TwoGaussData）」を選択する場合の、\n",
        "# 設定値を定数として定義\n",
        "PROBLEM_DATA_TYPE = pg.DatasetType.ClassifyTwoGaussData\n",
        "\n",
        "# ※実際のデータ生成は、後述の「pg.generate_data()関数の呼び出し」で行う"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO2bR6YxuZQb",
        "colab_type": "text"
      },
      "source": [
        "## ■（3）前処理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n42V67PUOJXm",
        "colab_type": "text"
      },
      "source": [
        "### リスト3　前処理としてのデータ分割"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A5hg4HbQvRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 各種設定を定数として定義\n",
        "TRAINING_DATA_RATIO = 0.5  # データの何％を訓練【Training】用に？ (残りは精度検証【Validation】用) ： 50％\n",
        "DATA_NOISE = 0.0           # ノイズ： 0％\n",
        "\n",
        "# 定義済みの定数を引数に指定して、データを生成する\n",
        "data_list = pg.generate_data(PROBLEM_DATA_TYPE, DATA_NOISE)\n",
        "\n",
        "# データを「訓練用」と「精度検証用」を指定の比率で分割し、さらにそれぞれを「データ（X）」と「教師ラベル（y）」に分ける\n",
        "X_train, y_train, X_valid, y_valid = pg.split_data(data_list, training_size=TRAINING_DATA_RATIO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rM61atkBkE-0",
        "colab_type": "text"
      },
      "source": [
        "### 【チェック】データ分割後の各変数の内容例"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihdjta06UTEd",
        "colab_type": "code",
        "outputId": "839575c5-fbab-43fd-91a9-a486468d497a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "# それぞれ5件ずつ出力\n",
        "print('X_train:'); print(X_train[:5])\n",
        "print('y_train:'); print(y_train[:5])\n",
        "print('X_valid:'); print(X_valid[:5])\n",
        "print('y_valid:'); print(y_valid[:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train:\n",
            "[[ 2.60705607  3.18180848]\n",
            " [-1.78263511 -1.80439237]\n",
            " [-1.49442318 -1.68884271]\n",
            " [-2.25127583 -2.24301428]\n",
            " [ 1.67867134  2.29377389]]\n",
            "y_train:\n",
            "[[ 1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [ 1.]]\n",
            "X_valid:\n",
            "[[-2.14218224 -1.99999585]\n",
            " [-1.51549029 -1.03161204]\n",
            " [-1.29757924 -1.8542762 ]\n",
            " [ 1.94858     0.93524059]\n",
            " [ 3.0082902   1.46211305]]\n",
            "y_valid:\n",
            "[[-1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [ 1.]\n",
            " [ 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IvcvfhndoFZ",
        "colab_type": "text"
      },
      "source": [
        "# 第2回　ニューラルネットワーク最速入門 ― 仕組み理解×初実装（中編）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFwgzpvAOsQo",
        "colab_type": "text"
      },
      "source": [
        "## ■（4）“手法”の選択とモデルの定義： ニューロン"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZivcroJDOuAe",
        "colab_type": "text"
      },
      "source": [
        "### 活性化関数のグラフ（前編）\n",
        "後掲する（後編）に続きます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDK-mz7rOwd4",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "0a6e6354-0d31-4565-9891-a023d4515f64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "#@title シグモイド関数\n",
        "# This code will be hidden when the notebook is loaded.\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "x = np.arange(-6.0, 6.0, 0.001)\n",
        "plt.plot(x, sigmoid(x), label = \"Sigmoid\")\n",
        "plt.xlim(-6, 6)\n",
        "plt.ylim(-0.2, 1.2)\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4_Ly_wBO6gA",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "9d10be2c-bfc8-42b5-8d67-86e44df7f2fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "#@title tanh関数\n",
        "# This code will be hidden when the notebook is loaded.\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "def tanh(x):\n",
        "  return np.tanh(x)\n",
        "\n",
        "x = np.arange(-6.0, 6.0, 0.001)\n",
        "plt.plot(x, sigmoid(x), label = \"Sigmoid\")\n",
        "plt.plot(x, tanh(x), label = \"tanh\")\n",
        "plt.xlim(-6, 6)\n",
        "plt.ylim(-1.2, 1.2)\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiSQljRoPDYF",
        "colab_type": "text"
      },
      "source": [
        "### 【チェック】TensorFlowバージョン（※2系を使うこと）\n",
        "基本的にはColabにインストール済みのものを使う。もし2系になっている場合は、リスト4-0を実行してバージョン2.0を使う。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOdS0iBJPF7n",
        "colab_type": "code",
        "outputId": "e3f39b8f-f19c-460c-e3ff-cc607e49e61a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print('TensorFlow', tf.__version__)\n",
        "# TensorFlow 1.15.0-rc3 ……などと表示される"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jBv9nSHU5mG",
        "colab_type": "text"
      },
      "source": [
        "### リスト4-0　［オプション］ライブラリ「TensorFlow」最新バージョンのインストール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSkcAJcUPL68",
        "colab_type": "code",
        "outputId": "b5438ac5-1098-4b5a-ab48-0b4bb2d75264",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 最新バージョンにアップグレードする場合\n",
        "!pip install --upgrade tensorflow\n",
        "\n",
        "# バージョンを明示してアップグレードする場合\n",
        "#!pip install --upgrade tensorflow==2.0.0\n",
        "\n",
        "# 最新バージョンをインストールする場合\n",
        "#!pip install tensorflow\n",
        "\n",
        "# バージョンを明示してインストールする場合\n",
        "#!pip install tensorflow==2.0.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 39kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.8)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.17.4)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.6)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 35.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.0)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 53.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (42.0.2)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.1)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/48/50934afa81c9ab6d68acc19c1c0543f765699fa4e3a36d675baa97816bb1/google_auth-1.8.1-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.2.7)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.8)\n",
            "\u001b[31mERROR: tensorboard 2.0.2 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.8.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: google-auth, tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: google-auth 1.4.2\n",
            "    Uninstalling google-auth-1.4.2:\n",
            "      Successfully uninstalled google-auth-1.4.2\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed google-auth-1.8.1 tensorboard-2.0.2 tensorflow-2.0.0 tensorflow-estimator-2.0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pikKWy-tHseG",
        "colab_type": "text"
      },
      "source": [
        "### ［オプション］【チェック】TensorFlowバージョン（※インストール後の確認）\n",
        "バージョン2.xになっているか再度チェックする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ofxIBjnHrun",
        "colab_type": "code",
        "outputId": "bc33a19e-08f3-4b30-a241-084af1ee8c73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print('TensorFlow', tf.__version__)\n",
        "# TensorFlow 2.0.0 ……などと表示される"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6aG55jaPQb5",
        "colab_type": "text"
      },
      "source": [
        "### リスト4-1　ニューロンのモデル設計\n",
        "- ニューロンへの入力＝$(w_1 \\times X_1)+(w_2 \\times X_2)+b$\n",
        "- ニューロンからの出力＝$a((w_1 \\times X_1)+(w_2 \\times X_2)+b)$\n",
        "  - $a()$は活性化関数を意味する。つまりニューロンの入力結果を、活性化関数で変換したうえで、出力する\n",
        "  - 今回の活性化関数は、**tanh**関数とする\n",
        "- $w_1=0.6$、$w_2=-0.2$、$b=0.8$と仮定して、ニューロンのモデルを定義\n",
        "  - ※これらの値は通常は学習により決定されるが、今回は未学習なので仮の固定数値としている\n",
        "  - 重さ（$w_1$と$w_2$）は2次元配列でまとめて表記する： `weight_array`\n",
        "    - 通常は、ニューロンは複数あるので、2次元配列で表記する\n",
        "    - 複数の重みが「行」を構成し、複数のニューロンが「列」を構成する\n",
        "    - 今回は、重みが**2つ**で、ニューロンが**1つ**なので、**2行1列**で記述する\n",
        "    -  `[[ 0.6],`<br>&nbsp;&nbsp;`[-0.2]]`\n",
        "  - バイアス（$b$）は1次元配列でまとめて表記する： `bias_array`\n",
        "    - `[0.8]`\n",
        "- そのニューロンに、座標$(X_1, X_2)$データを入力する\n",
        "  - 通常のデータは表形式（＝2次元配列）だが、今回は$(1.0, 2.0)$という1つのデータ\n",
        "    - 1つのデータでも2次元配列（具体的には**1行2列**）で表現する必要がある\n",
        "  - 入力の数（`INPUT_FEATURES`）は、$X_1$と$X_2$で**2つ**\n",
        "  - ニューロンの数（`LAYER1_NEURONS`）は、**1つ**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGz53J6VPZH3",
        "colab_type": "code",
        "outputId": "49f1c42c-2c73-4a8b-9b3e-a056bbdada9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# ライブラリ「TensorFlow」のtensorflowパッケージを「tf」という別名でインポート\n",
        "import tensorflow as tf\n",
        "# ライブラリ「NumPy」のnumpyパッケージを「np」という別名でインポート\n",
        "import numpy as np\n",
        "\n",
        "# 定数（モデル定義時に必要となるもの）\n",
        "INPUT_FEATURES = 2  # 入力（特徴）の数： 2\n",
        "LAYER1_NEURONS = 1  # ニューロンの数： 1\n",
        "\n",
        "# パラメーター（ニューロンへの入力で必要となるもの）\n",
        "weight_array = np.array([[ 0.6 ],\n",
        "                         [-0.2 ]])       # 重み\n",
        "bias_array   = np.array([  0.8 ])        # バイアス\n",
        "\n",
        "# 積層型のモデルの定義\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(\n",
        "    input_shape=(INPUT_FEATURES,),       # 入力の形状\n",
        "    units=LAYER1_NEURONS,                # ユニットの数\n",
        "    weights=[weight_array, bias_array],  # 重みとバイアスの初期値\n",
        "    activation='tanh')                   # 活性化関数\n",
        "])\n",
        "\n",
        "# このモデルに、データを入力して、出力を得る（＝予測：predictする）\n",
        "X_data = np.array([[1.0, 2.0]])          # 入力する座標データ（1.0、2.0）\n",
        "print(model.predict(X_data))             # 出力を得る\n",
        "# [[0.7615942]] ……などと表示される"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.7615942]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiQtSHb4jDZV",
        "colab_type": "text"
      },
      "source": [
        "## ■（4）“手法”の選択とモデルの定義： ニューラルネットワーク"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VT16L_p1o1R",
        "colab_type": "text"
      },
      "source": [
        "### リスト4-2　ニューラルネットワークのモデル設計\n",
        "- 入力の数（`INPUT_FEATURES`）は、$X_1$と$X_2$で**2つ**\n",
        "- 隠れ層のレイヤー数は、**2つ**\n",
        "  - 隠れ層にある1つ目のニューロンの数（`LAYER1_NEURONS`）は、**3つ**\n",
        "  - 隠れ層にある2つ目のニューロンの数（`LAYER2_NEURONS`）は、**3つ**\n",
        "- 出力層にあるニューロンの数（`OUTPUT_RESULTS`）は、**1つ**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Udhyk4YZ1rNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ライブラリ「TensorFlow」のtensorflowパッケージを「tf」という別名でインポート\n",
        "import tensorflow as tf\n",
        "# ライブラリ「NumPy」のnumpyパッケージを「np」という別名でインポート\n",
        "import numpy as np\n",
        "\n",
        "# 定数（モデル定義時に必要となる数値）\n",
        "INPUT_FEATURES = 2  # 入力（特徴）の数： 2\n",
        "LAYER1_NEURONS = 3  # ニューロンの数： 3\n",
        "LAYER2_NEURONS = 3  # ニューロンの数： 3\n",
        "OUTPUT_RESULTS = 1  # 出力結果の数： 1\n",
        "\n",
        "# 今度は重みとバイアスのパラメーターは指定しない（通常は指定しない）\n",
        "\n",
        "# 積層型のモデルの定義\n",
        "model = tf.keras.models.Sequential([\n",
        "  # 隠れ層：1つ目のレイヤー\n",
        "  tf.keras.layers.Dense(\n",
        "    input_shape=(INPUT_FEATURES,),       # 入力の形状（＝入力層）\n",
        "    units=LAYER1_NEURONS,                # ユニットの数\n",
        "    activation='tanh'),                  # 活性化関数\n",
        "  # 隠れ層：2つ目のレイヤー\n",
        "  tf.keras.layers.Dense(\n",
        "    units=LAYER2_NEURONS,                # ユニットの数\n",
        "    activation='tanh'),                  # 活性化関数\n",
        "  # 出力層\n",
        "  tf.keras.layers.Dense(\n",
        "    units=OUTPUT_RESULTS,                 # ユニットの数\n",
        "    activation='tanh'),                  # 活性化関数\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_hvgG8B1rFP",
        "colab_type": "code",
        "outputId": "6cf5f14e-11db-4615-fe8b-27bcb5778d4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 3)                 9         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 4         \n",
            "=================================================================\n",
            "Total params: 25\n",
            "Trainable params: 25\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ar9vyuqRiMv",
        "colab_type": "text"
      },
      "source": [
        "## ■（4）“手法” の選択とモデルの定義： 活性化関数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfGHPJhDRqpx",
        "colab_type": "text"
      },
      "source": [
        "### 活性化関数のグラフ（後編）\n",
        "前掲した（前編）の続きです。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65eY3wAHSnu6",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "1bb7d080-08db-4093-c88e-bec0d770f2ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "#@title 線形関数\n",
        "# This code will be hidden when the notebook is loaded.\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "def linear(x):\n",
        "  return x\n",
        "\n",
        "x = np.arange(-6.0, 6.0, 0.001)\n",
        "plt.plot(x, sigmoid(x), label = \"Sigmoid\")\n",
        "plt.plot(x, linear(x), label = \"Linear\")\n",
        "plt.xlim(-6, 6)\n",
        "plt.ylim(-1.2, 1.2)\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNyPwAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGStJujqS2P-",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "66dfec5c-e97d-425f-c414-b5b082d3ee78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "#@title ReLU関数\n",
        "# This code will be hidden when the notebook is loaded.\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "def relu(x):\n",
        "  return np.maximum(0, x)\n",
        "\n",
        "x = np.arange(-6.0, 6.0, 0.001)\n",
        "plt.plot(x, sigmoid(x), label = \"Sigmoid\")\n",
        "plt.plot(x, relu(x), label = \"ReLU\")\n",
        "plt.xlim(-6, 6)\n",
        "plt.ylim(-1.2, 1.2)\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5LzThaRjiQO",
        "colab_type": "text"
      },
      "source": [
        "### リスト4-3　活性化関数の指定例"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTcPVVXfjrk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ライブラリ「TensorFlow」のtensorflowパッケージを「tf」という別名でインポート\n",
        "import tensorflow as tf\n",
        "# ライブラリ「NumPy」のnumpyパッケージを「np」という別名でインポート\n",
        "import numpy as np\n",
        "\n",
        "# 定数（モデル定義時に必要となる数値）\n",
        "INPUT_FEATURES = 2      # 入力（特徴）の数： 2\n",
        "LAYER1_NEURONS = 3      # ニューロンの数： 3\n",
        "LAYER2_NEURONS = 3      # ニューロンの数： 3\n",
        "OUTPUT_RESULTS = 1      # 出力結果の数： 1\n",
        "ACTIVATION = 'sigmoid'  # 活性化関数（ここを書き換える）： シグモイド関数\n",
        "\n",
        "# 積層型のモデルの定義\n",
        "model = tf.keras.models.Sequential([\n",
        "  # 隠れ層：1つ目のレイヤー\n",
        "  tf.keras.layers.Dense(\n",
        "    input_shape=(INPUT_FEATURES,),       # 入力の形状（＝入力層）\n",
        "    units=LAYER1_NEURONS,                # ユニットの数\n",
        "    activation=ACTIVATION),              # 活性化関数\n",
        "  # 隠れ層：2つ目のレイヤー\n",
        "  tf.keras.layers.Dense(\n",
        "    units=LAYER2_NEURONS,                # ユニットの数\n",
        "    activation=ACTIVATION),              # 活性化関数\n",
        "  # 出力層\n",
        "  tf.keras.layers.Dense(\n",
        "    units=OUTPUT_RESULTS,                # ユニットの数\n",
        "    activation='tanh'),                  # 活性化関数\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv8-7jmHRke1",
        "colab_type": "text"
      },
      "source": [
        "## ■（4）“手法” の選択とモデルの定義： 正則化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_edc57slBW6",
        "colab_type": "text"
      },
      "source": [
        "### リスト4-4　正則化の指定例"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28aZTzo_lFGU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ライブラリ「TensorFlow」のtensorflowパッケージを「tf」という別名でインポート\n",
        "import tensorflow as tf\n",
        "# ライブラリ「NumPy」のnumpyパッケージを「np」という別名でインポート\n",
        "import numpy as np\n",
        "\n",
        "# 定数（モデル定義時に必要となるもの）\n",
        "INPUT_FEATURES = 2      # 入力（特徴）の数： 2\n",
        "LAYER1_NEURONS = 3      # ニューロンの数： 3\n",
        "LAYER2_NEURONS = 3      # ニューロンの数： 3\n",
        "OUTPUT_RESULTS = 1      # 出力結果の数： 1\n",
        "ACTIVATION = 'tanh'     # 活性化関数（ここを書き換える）： シグモイド関数\n",
        "REGULARIZATION = tf.keras.regularizers.l2(0.03)  # 正則化： L2、 正則化率： 0.03\n",
        "\n",
        "# 積層型のモデルの定義\n",
        "model = tf.keras.models.Sequential([\n",
        "  # 隠れ層：1つ目のレイヤー\n",
        "  tf.keras.layers.Dense(\n",
        "    input_shape=(INPUT_FEATURES,),        # 入力の形状（＝入力層）\n",
        "    units=LAYER1_NEURONS,                 # ユニットの数\n",
        "    activation=ACTIVATION,                # 活性化関数\n",
        "    kernel_regularizer= REGULARIZATION),  # 正則化\n",
        "                  \n",
        "  # 隠れ層：2つ目のレイヤー\n",
        "  tf.keras.layers.Dense(\n",
        "    units=LAYER2_NEURONS,                 # ユニットの数\n",
        "    activation=ACTIVATION,                # 活性化関数\n",
        "    kernel_regularizer= REGULARIZATION),  # 正則化\n",
        "\n",
        "  # 出力層\n",
        "  tf.keras.layers.Dense(\n",
        "    units=OUTPUT_RESULTS,                 # ユニットの数\n",
        "    activation='tanh',                    # 活性化関数\n",
        "    kernel_regularizer= REGULARIZATION)   # 正則化    \n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKuMufbLdpGV",
        "colab_type": "text"
      },
      "source": [
        "# 第3回　ディープラーニング最速入門 ― 仕組み理解×初実装（後編）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiaaAwr4jDNG",
        "colab_type": "text"
      },
      "source": [
        "## ■（5）“学習方法” の設計とモデルの生成： 損失関数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Yctz_lisMwV",
        "colab_type": "text"
      },
      "source": [
        "### リスト5-1　損失関数の定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnPuPqW9sRT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 定数（学習方法設計時に必要となる数値）\n",
        "LOSS = 'mean_squared_error'  # 損失関数：平均二乗誤差"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCbCa5p3snZ0",
        "colab_type": "text"
      },
      "source": [
        "## ■（5）“学習方法” の設計とモデルの生成： 最適化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFXEfgjXskEg",
        "colab_type": "text"
      },
      "source": [
        "### リスト5-2　最適化の定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NOoaJ1Isgqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# （必要に応じて）TensorFlow v2の最新バージョンにアップグレードする必要がある\n",
        "#!pip install --upgrade tensorflow\n",
        "# ライブラリ「TensorFlow」のtensorflowパッケージを「tf」という別名でインポート\n",
        "import tensorflow as tf\n",
        "\n",
        "# 定数（学習方法設計時に必要となるもの）\n",
        "OPTIMIZER = tf.keras.optimizers.SGD  # 最適化：確率的勾配降下法"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkEWzzu1tjaX",
        "colab_type": "text"
      },
      "source": [
        "## ■（5）“学習方法” の設計とモデルの生成： 学習率"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6Hr38pKttxO",
        "colab_type": "text"
      },
      "source": [
        "### リスト5-3　学習率の定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ss5mZa3ZtwSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 定数（学習方法設計時に必要となるもの）\n",
        "LEARNING_RATE = 0.03     # 学習率： 0.03"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5EZb3CQvkjf",
        "colab_type": "text"
      },
      "source": [
        "### リスト5-4　【前回の復習】モデルの定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPXUXDepwmdf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ライブラリ「TensorFlow」のtensorflowパッケージを「tf」という別名でインポート\n",
        "import tensorflow as tf\n",
        "\n",
        "# 定数（モデル定義時に必要となる数値）\n",
        "INPUT_FEATURES = 2      # 入力（特徴）の数： 2\n",
        "LAYER1_NEURONS = 3      # ニューロンの数： 3\n",
        "LAYER2_NEURONS = 3      # ニューロンの数： 3\n",
        "OUTPUT_RESULTS = 1      # 出力結果の数： 1\n",
        "ACTIVATION = 'tanh'     # 活性化関数（ここを書き換える）： tanh関数\n",
        "\n",
        "# 積層型のモデルの定義\n",
        "model = tf.keras.models.Sequential([\n",
        "\n",
        "  # 隠れ層：1つ目のレイヤー\n",
        "  tf.keras.layers.Dense(\n",
        "    input_shape=(INPUT_FEATURES,),       # 入力の形状（＝入力層）\n",
        "    units=LAYER1_NEURONS,                # ユニットの数\n",
        "    activation=ACTIVATION),              # 活性化関数\n",
        "\n",
        "  # 隠れ層：2つ目のレイヤー\n",
        "  tf.keras.layers.Dense(\n",
        "    units=LAYER2_NEURONS,                # ユニットの数\n",
        "    activation=ACTIVATION),              # 活性化関数\n",
        "\n",
        "  # 出力層\n",
        "  tf.keras.layers.Dense(\n",
        "    units=OUTPUT_RESULTS,                # ユニットの数\n",
        "    activation='tanh'),                  # 活性化関数\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzLt-2FKdEjc",
        "colab_type": "code",
        "outputId": "1f7d93b8-ea25-4ac3-8982-191eef93f998",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 3)                 9         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 4         \n",
            "=================================================================\n",
            "Total params: 25\n",
            "Trainable params: 25\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Trk7kOFowxiQ",
        "colab_type": "text"
      },
      "source": [
        "### リスト5-5　モデルの生成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5exRP34Hxez8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.keras.backend as K\n",
        "\n",
        "def tanh_accuracy(y_true, y_pred):           # y_trueは正解、y_predは予測（出力）\n",
        "  threshold = K.cast(0.0, y_pred.dtype)              # -1か1かを分ける閾値を作成\n",
        "  y_pred = K.cast(y_pred >= threshold, y_pred.dtype) # 閾値未満で0、以上で1に変換\n",
        "  # 2倍して-1.0することで、0／1を-1.0／1.0にスケール変換して正解率を計算\n",
        "  return K.mean(K.equal(y_true, K.round(y_pred) * 2 - 1.0), axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMaORFyxw31H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 定数（学習方法設計時に必要となるもの）\n",
        "LOSS = 'mean_squared_error'          # 損失関数： 平均二乗誤差\n",
        "OPTIMIZER = tf.keras.optimizers.SGD  # 最適化： 確率的勾配降下法\n",
        "LEARNING_RATE = 0.03                  # 学習率： 0.03\n",
        "\n",
        "# モデルを生成する\n",
        "model.compile(optimizer=OPTIMIZER(lr=LEARNING_RATE),\n",
        "              loss=LOSS,\n",
        "              metrics=[tanh_accuracy])  # 精度（正解率）"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eW-44PN-eCR",
        "colab_type": "text"
      },
      "source": [
        "## ■⑥学習： トレーニング"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8Vx0jZc--Zu",
        "colab_type": "text"
      },
      "source": [
        "### リスト6-1　【前回の復習】データの取得と分割"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ekAZt6M_BVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# （必要に応じて）座標点データを生成するライブラリをインストールする必要がある\n",
        "#!pip install playground-data\n",
        "\n",
        "# playground-dataライブラリのplygdataパッケージを「pg」という別名でインポート\n",
        "import plygdata as pg\n",
        "\n",
        "# 問題種別で「分類（Classification）」を選択し、\n",
        "# データ種別で「2つのガウシアンデータ（TwoGaussData）」を選択する場合の、\n",
        "# 設定値を定数として定義\n",
        "PROBLEM_DATA_TYPE = pg.DatasetType.ClassifyTwoGaussData\n",
        "\n",
        "# 各種設定を定数として定義\n",
        "TRAINING_DATA_RATIO = 0.5  # データの何％を訓練【Training】用に？ (残りは精度検証【Validation】用) ： 50％\n",
        "DATA_NOISE = 0.0           # ノイズ： 0％\n",
        "\n",
        "# 定義済みの定数を引数に指定して、データを生成する\n",
        "data_list = pg.generate_data(PROBLEM_DATA_TYPE, DATA_NOISE)\n",
        "\n",
        "# データを「訓練用」と「精度検証用」を指定の比率で分割し、さらにそれぞれを「データ（X）」と「教師ラベル（y）」に分ける\n",
        "X_train, y_train, X_valid, y_valid = pg.split_data(data_list, training_size=TRAINING_DATA_RATIO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibT9BFNthhXM",
        "colab_type": "code",
        "outputId": "0b25e640-65a5-4534-c9e7-3b258e36b859",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "# それぞれ5件ずつ出力\n",
        "print('X_train:'); print(X_train[:5])\n",
        "print('y_train:'); print(y_train[:5])\n",
        "print('X_valid:'); print(X_valid[:5])\n",
        "print('y_valid:'); print(y_valid[:5])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train:\n",
            "[[-3.14235882 -2.06319695]\n",
            " [-2.21140191 -1.68500123]\n",
            " [-2.27494093 -0.58023122]\n",
            " [ 1.74282335  1.56192155]\n",
            " [-3.07785159 -1.72988131]]\n",
            "y_train:\n",
            "[[-1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [ 1.]\n",
            " [-1.]]\n",
            "X_valid:\n",
            "[[ 1.47480725  3.59821988]\n",
            " [-2.14583251 -1.93423211]\n",
            " [ 1.29681706  2.24283417]\n",
            " [ 1.78524761  2.16130717]\n",
            " [-1.37062409 -1.96180036]]\n",
            "y_valid:\n",
            "[[ 1.]\n",
            " [-1.]\n",
            " [ 1.]\n",
            " [ 1.]\n",
            " [-1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_WjT4j5AvRt",
        "colab_type": "text"
      },
      "source": [
        "### リスト6-2　学習"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b72uD9v8AxeP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 定数（学習方法設計時に必要となるもの）\n",
        "BATCH_SIZE = 1   # バッチサイズ： 1（選択肢は「1」～「30」）\n",
        "EPOCHS = 100     # エポック数： 100\n",
        "\n",
        "# 学習する（※次の「リスト6-3　ミニバッチ学習」で実行するので、ここではまだ実行しないこと）\n",
        "#hist = model.fit(x=X_train,                          # 訓練用データ\n",
        "#                 y=y_train,                          # 訓練用ラベル\n",
        "#                 validation_data=(X_valid, y_valid), # 精度検証用\n",
        "#                 batch_size=BATCH_SIZE,              # バッチサイズ\n",
        "#                 epochs=EPOCHS,                      # エポック数\n",
        "#                 verbose=1)                          # 実行状況表示"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MacZaXSUZiTh",
        "colab_type": "text"
      },
      "source": [
        "## ■⑥学習： バッチサイズ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lTC91yBZouR",
        "colab_type": "text"
      },
      "source": [
        "###リスト6-3　ミニバッチ学習"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfKc72v-Z6FW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "816e9017-bbfe-4caf-f0af-be06dda70208"
      },
      "source": [
        "# 定数（学習方法設計時に必要となるもの）\n",
        "BATCH_SIZE = 15  # バッチサイズ： 15（選択肢は「1」～「30」）\n",
        "EPOCHS = 100     # エポック数： 100\n",
        "\n",
        "# 学習する\n",
        "hist = model.fit(x=X_train,                          # 訓練用データ\n",
        "                 y=y_train,                          # 訓練用ラベル\n",
        "                 validation_data=(X_valid, y_valid), # 精度検証用\n",
        "                 batch_size=BATCH_SIZE,              # バッチサイズ\n",
        "                 epochs=EPOCHS,                      # エポック数\n",
        "                 verbose=1)                          # 実行状況表示"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 250 samples, validate on 250 samples\n",
            "Epoch 1/100\n",
            "250/250 [==============================] - 1s 3ms/sample - loss: 0.5956 - tanh_accuracy: 0.8000 - val_loss: 0.1414 - val_tanh_accuracy: 1.0000\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 0s 253us/sample - loss: 0.0897 - tanh_accuracy: 1.0000 - val_loss: 0.0584 - val_tanh_accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 0s 256us/sample - loss: 0.0447 - tanh_accuracy: 1.0000 - val_loss: 0.0356 - val_tanh_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 0s 251us/sample - loss: 0.0293 - tanh_accuracy: 1.0000 - val_loss: 0.0253 - val_tanh_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 0s 257us/sample - loss: 0.0216 - tanh_accuracy: 1.0000 - val_loss: 0.0195 - val_tanh_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 0s 252us/sample - loss: 0.0170 - tanh_accuracy: 1.0000 - val_loss: 0.0158 - val_tanh_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 0s 292us/sample - loss: 0.0140 - tanh_accuracy: 1.0000 - val_loss: 0.0132 - val_tanh_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 0s 255us/sample - loss: 0.0118 - tanh_accuracy: 1.0000 - val_loss: 0.0113 - val_tanh_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 0s 249us/sample - loss: 0.0102 - tanh_accuracy: 1.0000 - val_loss: 0.0099 - val_tanh_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 0s 255us/sample - loss: 0.0090 - tanh_accuracy: 1.0000 - val_loss: 0.0088 - val_tanh_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 0s 263us/sample - loss: 0.0080 - tanh_accuracy: 1.0000 - val_loss: 0.0079 - val_tanh_accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 0s 285us/sample - loss: 0.0072 - tanh_accuracy: 1.0000 - val_loss: 0.0072 - val_tanh_accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 0s 249us/sample - loss: 0.0066 - tanh_accuracy: 1.0000 - val_loss: 0.0066 - val_tanh_accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 0s 264us/sample - loss: 0.0060 - tanh_accuracy: 1.0000 - val_loss: 0.0060 - val_tanh_accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 0s 270us/sample - loss: 0.0056 - tanh_accuracy: 1.0000 - val_loss: 0.0056 - val_tanh_accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 0s 246us/sample - loss: 0.0052 - tanh_accuracy: 1.0000 - val_loss: 0.0052 - val_tanh_accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 0s 258us/sample - loss: 0.0048 - tanh_accuracy: 1.0000 - val_loss: 0.0049 - val_tanh_accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 0s 290us/sample - loss: 0.0045 - tanh_accuracy: 1.0000 - val_loss: 0.0046 - val_tanh_accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 0s 254us/sample - loss: 0.0042 - tanh_accuracy: 1.0000 - val_loss: 0.0043 - val_tanh_accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 0s 248us/sample - loss: 0.0040 - tanh_accuracy: 1.0000 - val_loss: 0.0041 - val_tanh_accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 0s 256us/sample - loss: 0.0038 - tanh_accuracy: 1.0000 - val_loss: 0.0038 - val_tanh_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 0s 252us/sample - loss: 0.0036 - tanh_accuracy: 1.0000 - val_loss: 0.0037 - val_tanh_accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 0s 276us/sample - loss: 0.0034 - tanh_accuracy: 1.0000 - val_loss: 0.0035 - val_tanh_accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 0s 292us/sample - loss: 0.0032 - tanh_accuracy: 1.0000 - val_loss: 0.0033 - val_tanh_accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 0s 257us/sample - loss: 0.0031 - tanh_accuracy: 1.0000 - val_loss: 0.0032 - val_tanh_accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 0s 245us/sample - loss: 0.0030 - tanh_accuracy: 1.0000 - val_loss: 0.0030 - val_tanh_accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 0s 251us/sample - loss: 0.0028 - tanh_accuracy: 1.0000 - val_loss: 0.0029 - val_tanh_accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 0s 247us/sample - loss: 0.0027 - tanh_accuracy: 1.0000 - val_loss: 0.0028 - val_tanh_accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 0s 251us/sample - loss: 0.0026 - tanh_accuracy: 1.0000 - val_loss: 0.0027 - val_tanh_accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 0s 255us/sample - loss: 0.0025 - tanh_accuracy: 1.0000 - val_loss: 0.0026 - val_tanh_accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 0s 254us/sample - loss: 0.0024 - tanh_accuracy: 1.0000 - val_loss: 0.0025 - val_tanh_accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 0s 254us/sample - loss: 0.0023 - tanh_accuracy: 1.0000 - val_loss: 0.0024 - val_tanh_accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 0s 262us/sample - loss: 0.0023 - tanh_accuracy: 1.0000 - val_loss: 0.0023 - val_tanh_accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 0s 248us/sample - loss: 0.0022 - tanh_accuracy: 1.0000 - val_loss: 0.0023 - val_tanh_accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 0s 283us/sample - loss: 0.0021 - tanh_accuracy: 1.0000 - val_loss: 0.0022 - val_tanh_accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 0s 323us/sample - loss: 0.0021 - tanh_accuracy: 1.0000 - val_loss: 0.0021 - val_tanh_accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 0s 275us/sample - loss: 0.0020 - tanh_accuracy: 1.0000 - val_loss: 0.0021 - val_tanh_accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 0s 255us/sample - loss: 0.0019 - tanh_accuracy: 1.0000 - val_loss: 0.0020 - val_tanh_accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 0s 260us/sample - loss: 0.0019 - tanh_accuracy: 1.0000 - val_loss: 0.0019 - val_tanh_accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 0s 261us/sample - loss: 0.0018 - tanh_accuracy: 1.0000 - val_loss: 0.0019 - val_tanh_accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 0s 261us/sample - loss: 0.0018 - tanh_accuracy: 1.0000 - val_loss: 0.0018 - val_tanh_accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 0s 268us/sample - loss: 0.0017 - tanh_accuracy: 1.0000 - val_loss: 0.0018 - val_tanh_accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 0s 261us/sample - loss: 0.0017 - tanh_accuracy: 1.0000 - val_loss: 0.0017 - val_tanh_accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 0s 285us/sample - loss: 0.0016 - tanh_accuracy: 1.0000 - val_loss: 0.0017 - val_tanh_accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 0s 244us/sample - loss: 0.0016 - tanh_accuracy: 1.0000 - val_loss: 0.0017 - val_tanh_accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 0s 238us/sample - loss: 0.0016 - tanh_accuracy: 1.0000 - val_loss: 0.0016 - val_tanh_accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 0s 256us/sample - loss: 0.0015 - tanh_accuracy: 1.0000 - val_loss: 0.0016 - val_tanh_accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 0s 305us/sample - loss: 0.0015 - tanh_accuracy: 1.0000 - val_loss: 0.0016 - val_tanh_accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 0s 256us/sample - loss: 0.0015 - tanh_accuracy: 1.0000 - val_loss: 0.0015 - val_tanh_accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 0s 252us/sample - loss: 0.0014 - tanh_accuracy: 1.0000 - val_loss: 0.0015 - val_tanh_accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 0s 247us/sample - loss: 0.0014 - tanh_accuracy: 1.0000 - val_loss: 0.0015 - val_tanh_accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 0s 237us/sample - loss: 0.0014 - tanh_accuracy: 1.0000 - val_loss: 0.0014 - val_tanh_accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 0s 239us/sample - loss: 0.0013 - tanh_accuracy: 1.0000 - val_loss: 0.0014 - val_tanh_accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 0s 259us/sample - loss: 0.0013 - tanh_accuracy: 1.0000 - val_loss: 0.0014 - val_tanh_accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 0s 245us/sample - loss: 0.0013 - tanh_accuracy: 1.0000 - val_loss: 0.0013 - val_tanh_accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 0s 245us/sample - loss: 0.0013 - tanh_accuracy: 1.0000 - val_loss: 0.0013 - val_tanh_accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 0s 246us/sample - loss: 0.0012 - tanh_accuracy: 1.0000 - val_loss: 0.0013 - val_tanh_accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 0s 246us/sample - loss: 0.0012 - tanh_accuracy: 1.0000 - val_loss: 0.0013 - val_tanh_accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 0s 264us/sample - loss: 0.0012 - tanh_accuracy: 1.0000 - val_loss: 0.0012 - val_tanh_accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 0s 292us/sample - loss: 0.0012 - tanh_accuracy: 1.0000 - val_loss: 0.0012 - val_tanh_accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 0s 245us/sample - loss: 0.0011 - tanh_accuracy: 1.0000 - val_loss: 0.0012 - val_tanh_accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 0s 259us/sample - loss: 0.0011 - tanh_accuracy: 1.0000 - val_loss: 0.0012 - val_tanh_accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 0s 256us/sample - loss: 0.0011 - tanh_accuracy: 1.0000 - val_loss: 0.0012 - val_tanh_accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 0s 251us/sample - loss: 0.0011 - tanh_accuracy: 1.0000 - val_loss: 0.0011 - val_tanh_accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 0s 252us/sample - loss: 0.0011 - tanh_accuracy: 1.0000 - val_loss: 0.0011 - val_tanh_accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 0s 301us/sample - loss: 0.0010 - tanh_accuracy: 1.0000 - val_loss: 0.0011 - val_tanh_accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 0s 258us/sample - loss: 0.0010 - tanh_accuracy: 1.0000 - val_loss: 0.0011 - val_tanh_accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 0s 242us/sample - loss: 0.0010 - tanh_accuracy: 1.0000 - val_loss: 0.0011 - val_tanh_accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 0s 265us/sample - loss: 9.9797e-04 - tanh_accuracy: 1.0000 - val_loss: 0.0010 - val_tanh_accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 0s 272us/sample - loss: 9.8227e-04 - tanh_accuracy: 1.0000 - val_loss: 0.0010 - val_tanh_accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 0s 252us/sample - loss: 9.6705e-04 - tanh_accuracy: 1.0000 - val_loss: 0.0010 - val_tanh_accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 0s 259us/sample - loss: 9.5220e-04 - tanh_accuracy: 1.0000 - val_loss: 9.9716e-04 - val_tanh_accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 0s 260us/sample - loss: 9.3783e-04 - tanh_accuracy: 1.0000 - val_loss: 9.8233e-04 - val_tanh_accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 0s 265us/sample - loss: 9.2387e-04 - tanh_accuracy: 1.0000 - val_loss: 9.6786e-04 - val_tanh_accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 0s 267us/sample - loss: 9.1027e-04 - tanh_accuracy: 1.0000 - val_loss: 9.5386e-04 - val_tanh_accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 0s 248us/sample - loss: 8.9710e-04 - tanh_accuracy: 1.0000 - val_loss: 9.4023e-04 - val_tanh_accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 0s 269us/sample - loss: 8.8427e-04 - tanh_accuracy: 1.0000 - val_loss: 9.2699e-04 - val_tanh_accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 0s 252us/sample - loss: 8.7182e-04 - tanh_accuracy: 1.0000 - val_loss: 9.1411e-04 - val_tanh_accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 0s 257us/sample - loss: 8.5969e-04 - tanh_accuracy: 1.0000 - val_loss: 9.0154e-04 - val_tanh_accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 0s 260us/sample - loss: 8.4787e-04 - tanh_accuracy: 1.0000 - val_loss: 8.8932e-04 - val_tanh_accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 0s 277us/sample - loss: 8.3637e-04 - tanh_accuracy: 1.0000 - val_loss: 8.7742e-04 - val_tanh_accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 0s 274us/sample - loss: 8.2518e-04 - tanh_accuracy: 1.0000 - val_loss: 8.6582e-04 - val_tanh_accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 0s 245us/sample - loss: 8.1425e-04 - tanh_accuracy: 1.0000 - val_loss: 8.5447e-04 - val_tanh_accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 0s 237us/sample - loss: 8.0358e-04 - tanh_accuracy: 1.0000 - val_loss: 8.4345e-04 - val_tanh_accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 0s 247us/sample - loss: 7.9320e-04 - tanh_accuracy: 1.0000 - val_loss: 8.3269e-04 - val_tanh_accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 0s 263us/sample - loss: 7.8307e-04 - tanh_accuracy: 1.0000 - val_loss: 8.2218e-04 - val_tanh_accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 0s 255us/sample - loss: 7.7319e-04 - tanh_accuracy: 1.0000 - val_loss: 8.1195e-04 - val_tanh_accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 0s 295us/sample - loss: 7.6354e-04 - tanh_accuracy: 1.0000 - val_loss: 8.0193e-04 - val_tanh_accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 0s 263us/sample - loss: 7.5411e-04 - tanh_accuracy: 1.0000 - val_loss: 7.9217e-04 - val_tanh_accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 0s 258us/sample - loss: 7.4493e-04 - tanh_accuracy: 1.0000 - val_loss: 7.8263e-04 - val_tanh_accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 0s 262us/sample - loss: 7.3594e-04 - tanh_accuracy: 1.0000 - val_loss: 7.7333e-04 - val_tanh_accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 0s 271us/sample - loss: 7.2718e-04 - tanh_accuracy: 1.0000 - val_loss: 7.6418e-04 - val_tanh_accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 0s 279us/sample - loss: 7.1857e-04 - tanh_accuracy: 1.0000 - val_loss: 7.5529e-04 - val_tanh_accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 0s 270us/sample - loss: 7.1021e-04 - tanh_accuracy: 1.0000 - val_loss: 7.4657e-04 - val_tanh_accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 0s 261us/sample - loss: 7.0199e-04 - tanh_accuracy: 1.0000 - val_loss: 7.3806e-04 - val_tanh_accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 0s 250us/sample - loss: 6.9397e-04 - tanh_accuracy: 1.0000 - val_loss: 7.2974e-04 - val_tanh_accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 0s 278us/sample - loss: 6.8613e-04 - tanh_accuracy: 1.0000 - val_loss: 7.2158e-04 - val_tanh_accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 0s 261us/sample - loss: 6.7846e-04 - tanh_accuracy: 1.0000 - val_loss: 7.1362e-04 - val_tanh_accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 0s 254us/sample - loss: 6.7095e-04 - tanh_accuracy: 1.0000 - val_loss: 7.0581e-04 - val_tanh_accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 0s 232us/sample - loss: 6.6360e-04 - tanh_accuracy: 1.0000 - val_loss: 6.9815e-04 - val_tanh_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz1U1sOTaDiN",
        "colab_type": "text"
      },
      "source": [
        "## ■⑦評価： 損失のグラフ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl7Cau6jGqF6",
        "colab_type": "text"
      },
      "source": [
        "### リスト7-1　損失値の推移グラフ描画"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWlji88SdXpS",
        "colab_type": "code",
        "outputId": "d57e5ea8-9b0b-408d-848d-5b93ebb8cf58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 学習結果（損失）のグラフを描画\n",
        "train_loss = hist.history['loss']\n",
        "valid_loss = hist.history['val_loss']\n",
        "epochs = len(train_loss)\n",
        "plt.plot(range(epochs), train_loss, marker='.', label='loss (Training data)')\n",
        "plt.plot(range(epochs), valid_loss, marker='.', label='loss (validation data)')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEoGISMj9f8gV+vSrnpWbAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hxpyN4UHWu0",
        "colab_type": "text"
      },
      "source": [
        "### リスト7-2　コールバックの指定（早期終了とCSVログ出力）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2cNbgO1KORq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "63d8be5d-e314-4cc5-85fd-d573a0f1e9ce"
      },
      "source": [
        "# 早期終了\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "# CSVロガー\n",
        "csv_logger = tf.keras.callbacks.CSVLogger('training.log')\n",
        "\n",
        "# 学習する\n",
        "hist = model.fit(x=X_train,                          # 訓練用データ\n",
        "                 y=y_train,                          # 訓練用ラベル\n",
        "                 validation_data=(X_valid, y_valid), # 精度検証用\n",
        "                 batch_size=BATCH_SIZE,              # バッチサイズ\n",
        "                 epochs=EPOCHS,                      # エポック数\n",
        "                 verbose=1,                          # 実行状況表示\n",
        "                 callbacks=[es, csv_logger])         # コールバック"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 250 samples, validate on 250 samples\n",
            "Epoch 1/1000\n",
            "250/250 [==============================] - 0s 233us/sample - loss: 1.0017e-04 - tanh_accuracy: 1.0000 - val_loss: 9.4172e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 2/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 1.0000e-04 - tanh_accuracy: 1.0000 - val_loss: 9.4016e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 3/1000\n",
            "250/250 [==============================] - 0s 225us/sample - loss: 9.9837e-05 - tanh_accuracy: 1.0000 - val_loss: 9.3861e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 4/1000\n",
            "250/250 [==============================] - 0s 258us/sample - loss: 9.9673e-05 - tanh_accuracy: 1.0000 - val_loss: 9.3706e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 5/1000\n",
            "250/250 [==============================] - 0s 228us/sample - loss: 9.9510e-05 - tanh_accuracy: 1.0000 - val_loss: 9.3552e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 6/1000\n",
            "250/250 [==============================] - 0s 221us/sample - loss: 9.9347e-05 - tanh_accuracy: 1.0000 - val_loss: 9.3397e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 7/1000\n",
            "250/250 [==============================] - 0s 230us/sample - loss: 9.9185e-05 - tanh_accuracy: 1.0000 - val_loss: 9.3244e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 8/1000\n",
            "250/250 [==============================] - 0s 196us/sample - loss: 9.9023e-05 - tanh_accuracy: 1.0000 - val_loss: 9.3091e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 9/1000\n",
            "250/250 [==============================] - 0s 225us/sample - loss: 9.8862e-05 - tanh_accuracy: 1.0000 - val_loss: 9.2939e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 10/1000\n",
            "250/250 [==============================] - 0s 246us/sample - loss: 9.8701e-05 - tanh_accuracy: 1.0000 - val_loss: 9.2787e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 11/1000\n",
            "250/250 [==============================] - 0s 237us/sample - loss: 9.8541e-05 - tanh_accuracy: 1.0000 - val_loss: 9.2635e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 12/1000\n",
            "250/250 [==============================] - 0s 228us/sample - loss: 9.8382e-05 - tanh_accuracy: 1.0000 - val_loss: 9.2485e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 13/1000\n",
            "250/250 [==============================] - 0s 239us/sample - loss: 9.8223e-05 - tanh_accuracy: 1.0000 - val_loss: 9.2334e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 14/1000\n",
            "250/250 [==============================] - 0s 232us/sample - loss: 9.8064e-05 - tanh_accuracy: 1.0000 - val_loss: 9.2185e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 15/1000\n",
            "250/250 [==============================] - 0s 222us/sample - loss: 9.7906e-05 - tanh_accuracy: 1.0000 - val_loss: 9.2035e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 16/1000\n",
            "250/250 [==============================] - 0s 246us/sample - loss: 9.7749e-05 - tanh_accuracy: 1.0000 - val_loss: 9.1886e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 17/1000\n",
            "250/250 [==============================] - 0s 245us/sample - loss: 9.7592e-05 - tanh_accuracy: 1.0000 - val_loss: 9.1738e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 18/1000\n",
            "250/250 [==============================] - 0s 223us/sample - loss: 9.7436e-05 - tanh_accuracy: 1.0000 - val_loss: 9.1590e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 19/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 9.7280e-05 - tanh_accuracy: 1.0000 - val_loss: 9.1442e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 20/1000\n",
            "250/250 [==============================] - 0s 210us/sample - loss: 9.7124e-05 - tanh_accuracy: 1.0000 - val_loss: 9.1295e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 21/1000\n",
            "250/250 [==============================] - 0s 210us/sample - loss: 9.6969e-05 - tanh_accuracy: 1.0000 - val_loss: 9.1149e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 22/1000\n",
            "250/250 [==============================] - 0s 213us/sample - loss: 9.6815e-05 - tanh_accuracy: 1.0000 - val_loss: 9.1003e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 23/1000\n",
            "250/250 [==============================] - 0s 211us/sample - loss: 9.6661e-05 - tanh_accuracy: 1.0000 - val_loss: 9.0857e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 24/1000\n",
            "250/250 [==============================] - 0s 211us/sample - loss: 9.6507e-05 - tanh_accuracy: 1.0000 - val_loss: 9.0711e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 25/1000\n",
            "250/250 [==============================] - 0s 218us/sample - loss: 9.6354e-05 - tanh_accuracy: 1.0000 - val_loss: 9.0567e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 26/1000\n",
            "250/250 [==============================] - 0s 213us/sample - loss: 9.6201e-05 - tanh_accuracy: 1.0000 - val_loss: 9.0422e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 27/1000\n",
            "250/250 [==============================] - 0s 217us/sample - loss: 9.6049e-05 - tanh_accuracy: 1.0000 - val_loss: 9.0278e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 28/1000\n",
            "250/250 [==============================] - 0s 221us/sample - loss: 9.5897e-05 - tanh_accuracy: 1.0000 - val_loss: 9.0133e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 29/1000\n",
            "250/250 [==============================] - 0s 209us/sample - loss: 9.5745e-05 - tanh_accuracy: 1.0000 - val_loss: 8.9990e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 30/1000\n",
            "250/250 [==============================] - 0s 200us/sample - loss: 9.5594e-05 - tanh_accuracy: 1.0000 - val_loss: 8.9847e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 31/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 9.5444e-05 - tanh_accuracy: 1.0000 - val_loss: 8.9705e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 32/1000\n",
            "250/250 [==============================] - 0s 207us/sample - loss: 9.5293e-05 - tanh_accuracy: 1.0000 - val_loss: 8.9563e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 33/1000\n",
            "250/250 [==============================] - 0s 221us/sample - loss: 9.5144e-05 - tanh_accuracy: 1.0000 - val_loss: 8.9421e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 34/1000\n",
            "250/250 [==============================] - 0s 208us/sample - loss: 9.4995e-05 - tanh_accuracy: 1.0000 - val_loss: 8.9280e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 35/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 9.4845e-05 - tanh_accuracy: 1.0000 - val_loss: 8.9139e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 36/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 9.4697e-05 - tanh_accuracy: 1.0000 - val_loss: 8.8999e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 37/1000\n",
            "250/250 [==============================] - 0s 235us/sample - loss: 9.4549e-05 - tanh_accuracy: 1.0000 - val_loss: 8.8858e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 38/1000\n",
            "250/250 [==============================] - 0s 220us/sample - loss: 9.4401e-05 - tanh_accuracy: 1.0000 - val_loss: 8.8719e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 39/1000\n",
            "250/250 [==============================] - 0s 201us/sample - loss: 9.4254e-05 - tanh_accuracy: 1.0000 - val_loss: 8.8580e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 40/1000\n",
            "250/250 [==============================] - 0s 205us/sample - loss: 9.4108e-05 - tanh_accuracy: 1.0000 - val_loss: 8.8442e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 41/1000\n",
            "250/250 [==============================] - 0s 220us/sample - loss: 9.3962e-05 - tanh_accuracy: 1.0000 - val_loss: 8.8303e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 42/1000\n",
            "250/250 [==============================] - 0s 202us/sample - loss: 9.3816e-05 - tanh_accuracy: 1.0000 - val_loss: 8.8166e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 43/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 9.3671e-05 - tanh_accuracy: 1.0000 - val_loss: 8.8028e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 44/1000\n",
            "250/250 [==============================] - 0s 211us/sample - loss: 9.3525e-05 - tanh_accuracy: 1.0000 - val_loss: 8.7891e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 45/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 9.3381e-05 - tanh_accuracy: 1.0000 - val_loss: 8.7755e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 46/1000\n",
            "250/250 [==============================] - 0s 213us/sample - loss: 9.3237e-05 - tanh_accuracy: 1.0000 - val_loss: 8.7619e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 47/1000\n",
            "250/250 [==============================] - 0s 212us/sample - loss: 9.3094e-05 - tanh_accuracy: 1.0000 - val_loss: 8.7483e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 48/1000\n",
            "250/250 [==============================] - 0s 225us/sample - loss: 9.2951e-05 - tanh_accuracy: 1.0000 - val_loss: 8.7348e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 49/1000\n",
            "250/250 [==============================] - 0s 231us/sample - loss: 9.2808e-05 - tanh_accuracy: 1.0000 - val_loss: 8.7213e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 50/1000\n",
            "250/250 [==============================] - 0s 239us/sample - loss: 9.2666e-05 - tanh_accuracy: 1.0000 - val_loss: 8.7078e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 51/1000\n",
            "250/250 [==============================] - 0s 221us/sample - loss: 9.2523e-05 - tanh_accuracy: 1.0000 - val_loss: 8.6944e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 52/1000\n",
            "250/250 [==============================] - 0s 213us/sample - loss: 9.2382e-05 - tanh_accuracy: 1.0000 - val_loss: 8.6810e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 53/1000\n",
            "250/250 [==============================] - 0s 219us/sample - loss: 9.2241e-05 - tanh_accuracy: 1.0000 - val_loss: 8.6675e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 54/1000\n",
            "250/250 [==============================] - 0s 211us/sample - loss: 9.2098e-05 - tanh_accuracy: 1.0000 - val_loss: 8.6542e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 55/1000\n",
            "250/250 [==============================] - 0s 212us/sample - loss: 9.1958e-05 - tanh_accuracy: 1.0000 - val_loss: 8.6409e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 56/1000\n",
            "250/250 [==============================] - 0s 213us/sample - loss: 9.1818e-05 - tanh_accuracy: 1.0000 - val_loss: 8.6278e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 57/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 9.1680e-05 - tanh_accuracy: 1.0000 - val_loss: 8.6146e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 58/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 9.1540e-05 - tanh_accuracy: 1.0000 - val_loss: 8.6013e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 59/1000\n",
            "250/250 [==============================] - 0s 233us/sample - loss: 9.1399e-05 - tanh_accuracy: 1.0000 - val_loss: 8.5882e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 60/1000\n",
            "250/250 [==============================] - 0s 234us/sample - loss: 9.1261e-05 - tanh_accuracy: 1.0000 - val_loss: 8.5751e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 61/1000\n",
            "250/250 [==============================] - 0s 225us/sample - loss: 9.1124e-05 - tanh_accuracy: 1.0000 - val_loss: 8.5621e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 62/1000\n",
            "250/250 [==============================] - 0s 210us/sample - loss: 9.0987e-05 - tanh_accuracy: 1.0000 - val_loss: 8.5492e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 63/1000\n",
            "250/250 [==============================] - 0s 204us/sample - loss: 9.0850e-05 - tanh_accuracy: 1.0000 - val_loss: 8.5362e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 64/1000\n",
            "250/250 [==============================] - 0s 205us/sample - loss: 9.0714e-05 - tanh_accuracy: 1.0000 - val_loss: 8.5234e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 65/1000\n",
            "250/250 [==============================] - 0s 212us/sample - loss: 9.0578e-05 - tanh_accuracy: 1.0000 - val_loss: 8.5105e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 66/1000\n",
            "250/250 [==============================] - 0s 208us/sample - loss: 9.0443e-05 - tanh_accuracy: 1.0000 - val_loss: 8.4977e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 67/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 9.0308e-05 - tanh_accuracy: 1.0000 - val_loss: 8.4849e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 68/1000\n",
            "250/250 [==============================] - 0s 226us/sample - loss: 9.0172e-05 - tanh_accuracy: 1.0000 - val_loss: 8.4722e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 69/1000\n",
            "250/250 [==============================] - 0s 230us/sample - loss: 9.0038e-05 - tanh_accuracy: 1.0000 - val_loss: 8.4594e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 70/1000\n",
            "250/250 [==============================] - 0s 231us/sample - loss: 8.9903e-05 - tanh_accuracy: 1.0000 - val_loss: 8.4467e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 71/1000\n",
            "250/250 [==============================] - 0s 225us/sample - loss: 8.9770e-05 - tanh_accuracy: 1.0000 - val_loss: 8.4341e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 72/1000\n",
            "250/250 [==============================] - 0s 205us/sample - loss: 8.9637e-05 - tanh_accuracy: 1.0000 - val_loss: 8.4215e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 73/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 8.9504e-05 - tanh_accuracy: 1.0000 - val_loss: 8.4089e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 74/1000\n",
            "250/250 [==============================] - 0s 222us/sample - loss: 8.9371e-05 - tanh_accuracy: 1.0000 - val_loss: 8.3963e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 75/1000\n",
            "250/250 [==============================] - 0s 203us/sample - loss: 8.9237e-05 - tanh_accuracy: 1.0000 - val_loss: 8.3837e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 76/1000\n",
            "250/250 [==============================] - 0s 210us/sample - loss: 8.9105e-05 - tanh_accuracy: 1.0000 - val_loss: 8.3713e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 77/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 8.8974e-05 - tanh_accuracy: 1.0000 - val_loss: 8.3589e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 78/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 8.8843e-05 - tanh_accuracy: 1.0000 - val_loss: 8.3464e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 79/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 8.8712e-05 - tanh_accuracy: 1.0000 - val_loss: 8.3341e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 80/1000\n",
            "250/250 [==============================] - 0s 266us/sample - loss: 8.8581e-05 - tanh_accuracy: 1.0000 - val_loss: 8.3218e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 81/1000\n",
            "250/250 [==============================] - 0s 240us/sample - loss: 8.8451e-05 - tanh_accuracy: 1.0000 - val_loss: 8.3095e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 82/1000\n",
            "250/250 [==============================] - 0s 237us/sample - loss: 8.8322e-05 - tanh_accuracy: 1.0000 - val_loss: 8.2973e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 83/1000\n",
            "250/250 [==============================] - 0s 213us/sample - loss: 8.8193e-05 - tanh_accuracy: 1.0000 - val_loss: 8.2851e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 84/1000\n",
            "250/250 [==============================] - 0s 219us/sample - loss: 8.8064e-05 - tanh_accuracy: 1.0000 - val_loss: 8.2729e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 85/1000\n",
            "250/250 [==============================] - 0s 210us/sample - loss: 8.7936e-05 - tanh_accuracy: 1.0000 - val_loss: 8.2607e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 86/1000\n",
            "250/250 [==============================] - 0s 214us/sample - loss: 8.7807e-05 - tanh_accuracy: 1.0000 - val_loss: 8.2486e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 87/1000\n",
            "250/250 [==============================] - 0s 217us/sample - loss: 8.7680e-05 - tanh_accuracy: 1.0000 - val_loss: 8.2365e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 88/1000\n",
            "250/250 [==============================] - 0s 227us/sample - loss: 8.7553e-05 - tanh_accuracy: 1.0000 - val_loss: 8.2245e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 89/1000\n",
            "250/250 [==============================] - 0s 212us/sample - loss: 8.7426e-05 - tanh_accuracy: 1.0000 - val_loss: 8.2125e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 90/1000\n",
            "250/250 [==============================] - 0s 211us/sample - loss: 8.7299e-05 - tanh_accuracy: 1.0000 - val_loss: 8.2006e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 91/1000\n",
            "250/250 [==============================] - 0s 213us/sample - loss: 8.7173e-05 - tanh_accuracy: 1.0000 - val_loss: 8.1886e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 92/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 8.7047e-05 - tanh_accuracy: 1.0000 - val_loss: 8.1767e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 93/1000\n",
            "250/250 [==============================] - 0s 224us/sample - loss: 8.6921e-05 - tanh_accuracy: 1.0000 - val_loss: 8.1648e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 94/1000\n",
            "250/250 [==============================] - 0s 233us/sample - loss: 8.6796e-05 - tanh_accuracy: 1.0000 - val_loss: 8.1530e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 95/1000\n",
            "250/250 [==============================] - 0s 205us/sample - loss: 8.6671e-05 - tanh_accuracy: 1.0000 - val_loss: 8.1412e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 96/1000\n",
            "250/250 [==============================] - 0s 206us/sample - loss: 8.6547e-05 - tanh_accuracy: 1.0000 - val_loss: 8.1294e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 97/1000\n",
            "250/250 [==============================] - 0s 213us/sample - loss: 8.6423e-05 - tanh_accuracy: 1.0000 - val_loss: 8.1176e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 98/1000\n",
            "250/250 [==============================] - 0s 209us/sample - loss: 8.6299e-05 - tanh_accuracy: 1.0000 - val_loss: 8.1059e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 99/1000\n",
            "250/250 [==============================] - 0s 229us/sample - loss: 8.6175e-05 - tanh_accuracy: 1.0000 - val_loss: 8.0943e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 100/1000\n",
            "250/250 [==============================] - 0s 222us/sample - loss: 8.6052e-05 - tanh_accuracy: 1.0000 - val_loss: 8.0826e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 101/1000\n",
            "250/250 [==============================] - 0s 219us/sample - loss: 8.5929e-05 - tanh_accuracy: 1.0000 - val_loss: 8.0709e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 102/1000\n",
            "250/250 [==============================] - 0s 208us/sample - loss: 8.5806e-05 - tanh_accuracy: 1.0000 - val_loss: 8.0594e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 103/1000\n",
            "250/250 [==============================] - 0s 232us/sample - loss: 8.5684e-05 - tanh_accuracy: 1.0000 - val_loss: 8.0477e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 104/1000\n",
            "250/250 [==============================] - 0s 211us/sample - loss: 8.5560e-05 - tanh_accuracy: 1.0000 - val_loss: 8.0362e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 105/1000\n",
            "250/250 [==============================] - 0s 221us/sample - loss: 8.5439e-05 - tanh_accuracy: 1.0000 - val_loss: 8.0247e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 106/1000\n",
            "250/250 [==============================] - 0s 242us/sample - loss: 8.5318e-05 - tanh_accuracy: 1.0000 - val_loss: 8.0132e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 107/1000\n",
            "250/250 [==============================] - 0s 228us/sample - loss: 8.5197e-05 - tanh_accuracy: 1.0000 - val_loss: 8.0018e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 108/1000\n",
            "250/250 [==============================] - 0s 222us/sample - loss: 8.5076e-05 - tanh_accuracy: 1.0000 - val_loss: 7.9904e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 109/1000\n",
            "250/250 [==============================] - 0s 221us/sample - loss: 8.4956e-05 - tanh_accuracy: 1.0000 - val_loss: 7.9791e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 110/1000\n",
            "250/250 [==============================] - 0s 214us/sample - loss: 8.4836e-05 - tanh_accuracy: 1.0000 - val_loss: 7.9678e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 111/1000\n",
            "250/250 [==============================] - 0s 220us/sample - loss: 8.4717e-05 - tanh_accuracy: 1.0000 - val_loss: 7.9565e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 112/1000\n",
            "250/250 [==============================] - 0s 248us/sample - loss: 8.4598e-05 - tanh_accuracy: 1.0000 - val_loss: 7.9452e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 113/1000\n",
            "250/250 [==============================] - 0s 213us/sample - loss: 8.4480e-05 - tanh_accuracy: 1.0000 - val_loss: 7.9340e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 114/1000\n",
            "250/250 [==============================] - 0s 218us/sample - loss: 8.4361e-05 - tanh_accuracy: 1.0000 - val_loss: 7.9228e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 115/1000\n",
            "250/250 [==============================] - 0s 211us/sample - loss: 8.4243e-05 - tanh_accuracy: 1.0000 - val_loss: 7.9116e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 116/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 8.4125e-05 - tanh_accuracy: 1.0000 - val_loss: 7.9005e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 117/1000\n",
            "250/250 [==============================] - 0s 211us/sample - loss: 8.4007e-05 - tanh_accuracy: 1.0000 - val_loss: 7.8894e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 118/1000\n",
            "250/250 [==============================] - 0s 213us/sample - loss: 8.3891e-05 - tanh_accuracy: 1.0000 - val_loss: 7.8783e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 119/1000\n",
            "250/250 [==============================] - 0s 223us/sample - loss: 8.3773e-05 - tanh_accuracy: 1.0000 - val_loss: 7.8671e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 120/1000\n",
            "250/250 [==============================] - 0s 212us/sample - loss: 8.3654e-05 - tanh_accuracy: 1.0000 - val_loss: 7.8561e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 121/1000\n",
            "250/250 [==============================] - 0s 220us/sample - loss: 8.3538e-05 - tanh_accuracy: 1.0000 - val_loss: 7.8451e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 122/1000\n",
            "250/250 [==============================] - 0s 213us/sample - loss: 8.3422e-05 - tanh_accuracy: 1.0000 - val_loss: 7.8341e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 123/1000\n",
            "250/250 [==============================] - 0s 282us/sample - loss: 8.3306e-05 - tanh_accuracy: 1.0000 - val_loss: 7.8231e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 124/1000\n",
            "250/250 [==============================] - 0s 231us/sample - loss: 8.3191e-05 - tanh_accuracy: 1.0000 - val_loss: 7.8123e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 125/1000\n",
            "250/250 [==============================] - 0s 217us/sample - loss: 8.3076e-05 - tanh_accuracy: 1.0000 - val_loss: 7.8014e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 126/1000\n",
            "250/250 [==============================] - 0s 219us/sample - loss: 8.2961e-05 - tanh_accuracy: 1.0000 - val_loss: 7.7906e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 127/1000\n",
            "250/250 [==============================] - 0s 214us/sample - loss: 8.2847e-05 - tanh_accuracy: 1.0000 - val_loss: 7.7798e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 128/1000\n",
            "250/250 [==============================] - 0s 202us/sample - loss: 8.2733e-05 - tanh_accuracy: 1.0000 - val_loss: 7.7690e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 129/1000\n",
            "250/250 [==============================] - 0s 222us/sample - loss: 8.2620e-05 - tanh_accuracy: 1.0000 - val_loss: 7.7583e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 130/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 8.2506e-05 - tanh_accuracy: 1.0000 - val_loss: 7.7476e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 131/1000\n",
            "250/250 [==============================] - 0s 220us/sample - loss: 8.2393e-05 - tanh_accuracy: 1.0000 - val_loss: 7.7369e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 132/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 8.2281e-05 - tanh_accuracy: 1.0000 - val_loss: 7.7263e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 133/1000\n",
            "250/250 [==============================] - 0s 217us/sample - loss: 8.2168e-05 - tanh_accuracy: 1.0000 - val_loss: 7.7156e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 134/1000\n",
            "250/250 [==============================] - 0s 211us/sample - loss: 8.2056e-05 - tanh_accuracy: 1.0000 - val_loss: 7.7049e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 135/1000\n",
            "250/250 [==============================] - 0s 231us/sample - loss: 8.1943e-05 - tanh_accuracy: 1.0000 - val_loss: 7.6944e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 136/1000\n",
            "250/250 [==============================] - 0s 210us/sample - loss: 8.1832e-05 - tanh_accuracy: 1.0000 - val_loss: 7.6838e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 137/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 8.1720e-05 - tanh_accuracy: 1.0000 - val_loss: 7.6733e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 138/1000\n",
            "250/250 [==============================] - 0s 203us/sample - loss: 8.1609e-05 - tanh_accuracy: 1.0000 - val_loss: 7.6628e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 139/1000\n",
            "250/250 [==============================] - 0s 238us/sample - loss: 8.1499e-05 - tanh_accuracy: 1.0000 - val_loss: 7.6523e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 140/1000\n",
            "250/250 [==============================] - 0s 263us/sample - loss: 8.1389e-05 - tanh_accuracy: 1.0000 - val_loss: 7.6419e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 141/1000\n",
            "250/250 [==============================] - 0s 226us/sample - loss: 8.1278e-05 - tanh_accuracy: 1.0000 - val_loss: 7.6315e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 142/1000\n",
            "250/250 [==============================] - 0s 206us/sample - loss: 8.1168e-05 - tanh_accuracy: 1.0000 - val_loss: 7.6211e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 143/1000\n",
            "250/250 [==============================] - 0s 218us/sample - loss: 8.1059e-05 - tanh_accuracy: 1.0000 - val_loss: 7.6107e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 144/1000\n",
            "250/250 [==============================] - 0s 223us/sample - loss: 8.0949e-05 - tanh_accuracy: 1.0000 - val_loss: 7.6004e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 145/1000\n",
            "250/250 [==============================] - 0s 209us/sample - loss: 8.0841e-05 - tanh_accuracy: 1.0000 - val_loss: 7.5901e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 146/1000\n",
            "250/250 [==============================] - 0s 212us/sample - loss: 8.0732e-05 - tanh_accuracy: 1.0000 - val_loss: 7.5798e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 147/1000\n",
            "250/250 [==============================] - 0s 230us/sample - loss: 8.0623e-05 - tanh_accuracy: 1.0000 - val_loss: 7.5695e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 148/1000\n",
            "250/250 [==============================] - 0s 224us/sample - loss: 8.0515e-05 - tanh_accuracy: 1.0000 - val_loss: 7.5593e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 149/1000\n",
            "250/250 [==============================] - 0s 223us/sample - loss: 8.0407e-05 - tanh_accuracy: 1.0000 - val_loss: 7.5491e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 150/1000\n",
            "250/250 [==============================] - 0s 246us/sample - loss: 8.0299e-05 - tanh_accuracy: 1.0000 - val_loss: 7.5389e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 151/1000\n",
            "250/250 [==============================] - 0s 218us/sample - loss: 8.0192e-05 - tanh_accuracy: 1.0000 - val_loss: 7.5288e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 152/1000\n",
            "250/250 [==============================] - 0s 233us/sample - loss: 8.0084e-05 - tanh_accuracy: 1.0000 - val_loss: 7.5185e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 153/1000\n",
            "250/250 [==============================] - 0s 223us/sample - loss: 7.9975e-05 - tanh_accuracy: 1.0000 - val_loss: 7.5084e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 154/1000\n",
            "250/250 [==============================] - 0s 240us/sample - loss: 7.9869e-05 - tanh_accuracy: 1.0000 - val_loss: 7.4983e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 155/1000\n",
            "250/250 [==============================] - 0s 240us/sample - loss: 7.9763e-05 - tanh_accuracy: 1.0000 - val_loss: 7.4883e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 156/1000\n",
            "250/250 [==============================] - 0s 238us/sample - loss: 7.9657e-05 - tanh_accuracy: 1.0000 - val_loss: 7.4783e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 157/1000\n",
            "250/250 [==============================] - 0s 237us/sample - loss: 7.9551e-05 - tanh_accuracy: 1.0000 - val_loss: 7.4683e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 158/1000\n",
            "250/250 [==============================] - 0s 250us/sample - loss: 7.9446e-05 - tanh_accuracy: 1.0000 - val_loss: 7.4583e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 159/1000\n",
            "250/250 [==============================] - 0s 236us/sample - loss: 7.9340e-05 - tanh_accuracy: 1.0000 - val_loss: 7.4483e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 160/1000\n",
            "250/250 [==============================] - 0s 232us/sample - loss: 7.9235e-05 - tanh_accuracy: 1.0000 - val_loss: 7.4384e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 161/1000\n",
            "250/250 [==============================] - 0s 234us/sample - loss: 7.9130e-05 - tanh_accuracy: 1.0000 - val_loss: 7.4285e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 162/1000\n",
            "250/250 [==============================] - 0s 247us/sample - loss: 7.9026e-05 - tanh_accuracy: 1.0000 - val_loss: 7.4186e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 163/1000\n",
            "250/250 [==============================] - 0s 241us/sample - loss: 7.8921e-05 - tanh_accuracy: 1.0000 - val_loss: 7.4088e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 164/1000\n",
            "250/250 [==============================] - 0s 232us/sample - loss: 7.8818e-05 - tanh_accuracy: 1.0000 - val_loss: 7.3989e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 165/1000\n",
            "250/250 [==============================] - 0s 257us/sample - loss: 7.8714e-05 - tanh_accuracy: 1.0000 - val_loss: 7.3891e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 166/1000\n",
            "250/250 [==============================] - 0s 240us/sample - loss: 7.8610e-05 - tanh_accuracy: 1.0000 - val_loss: 7.3793e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 167/1000\n",
            "250/250 [==============================] - 0s 241us/sample - loss: 7.8507e-05 - tanh_accuracy: 1.0000 - val_loss: 7.3695e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 168/1000\n",
            "250/250 [==============================] - 0s 281us/sample - loss: 7.8404e-05 - tanh_accuracy: 1.0000 - val_loss: 7.3598e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 169/1000\n",
            "250/250 [==============================] - 0s 254us/sample - loss: 7.8301e-05 - tanh_accuracy: 1.0000 - val_loss: 7.3501e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 170/1000\n",
            "250/250 [==============================] - 0s 243us/sample - loss: 7.8199e-05 - tanh_accuracy: 1.0000 - val_loss: 7.3405e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 171/1000\n",
            "250/250 [==============================] - 0s 248us/sample - loss: 7.8097e-05 - tanh_accuracy: 1.0000 - val_loss: 7.3308e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 172/1000\n",
            "250/250 [==============================] - 0s 236us/sample - loss: 7.7995e-05 - tanh_accuracy: 1.0000 - val_loss: 7.3212e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 173/1000\n",
            "250/250 [==============================] - 0s 229us/sample - loss: 7.7894e-05 - tanh_accuracy: 1.0000 - val_loss: 7.3116e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 174/1000\n",
            "250/250 [==============================] - 0s 236us/sample - loss: 7.7792e-05 - tanh_accuracy: 1.0000 - val_loss: 7.3020e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 175/1000\n",
            "250/250 [==============================] - 0s 244us/sample - loss: 7.7691e-05 - tanh_accuracy: 1.0000 - val_loss: 7.2924e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 176/1000\n",
            "250/250 [==============================] - 0s 248us/sample - loss: 7.7590e-05 - tanh_accuracy: 1.0000 - val_loss: 7.2829e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 177/1000\n",
            "250/250 [==============================] - 0s 240us/sample - loss: 7.7490e-05 - tanh_accuracy: 1.0000 - val_loss: 7.2734e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 178/1000\n",
            "250/250 [==============================] - 0s 224us/sample - loss: 7.7389e-05 - tanh_accuracy: 1.0000 - val_loss: 7.2639e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 179/1000\n",
            "250/250 [==============================] - 0s 237us/sample - loss: 7.7289e-05 - tanh_accuracy: 1.0000 - val_loss: 7.2545e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 180/1000\n",
            "250/250 [==============================] - 0s 244us/sample - loss: 7.7190e-05 - tanh_accuracy: 1.0000 - val_loss: 7.2450e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 181/1000\n",
            "250/250 [==============================] - 0s 232us/sample - loss: 7.7090e-05 - tanh_accuracy: 1.0000 - val_loss: 7.2356e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 182/1000\n",
            "250/250 [==============================] - 0s 227us/sample - loss: 7.6991e-05 - tanh_accuracy: 1.0000 - val_loss: 7.2263e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 183/1000\n",
            "250/250 [==============================] - 0s 226us/sample - loss: 7.6892e-05 - tanh_accuracy: 1.0000 - val_loss: 7.2170e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 184/1000\n",
            "250/250 [==============================] - 0s 224us/sample - loss: 7.6794e-05 - tanh_accuracy: 1.0000 - val_loss: 7.2076e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 185/1000\n",
            "250/250 [==============================] - 0s 227us/sample - loss: 7.6695e-05 - tanh_accuracy: 1.0000 - val_loss: 7.1983e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 186/1000\n",
            "250/250 [==============================] - 0s 240us/sample - loss: 7.6597e-05 - tanh_accuracy: 1.0000 - val_loss: 7.1891e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 187/1000\n",
            "250/250 [==============================] - 0s 230us/sample - loss: 7.6499e-05 - tanh_accuracy: 1.0000 - val_loss: 7.1798e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 188/1000\n",
            "250/250 [==============================] - 0s 251us/sample - loss: 7.6401e-05 - tanh_accuracy: 1.0000 - val_loss: 7.1706e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 189/1000\n",
            "250/250 [==============================] - 0s 242us/sample - loss: 7.6304e-05 - tanh_accuracy: 1.0000 - val_loss: 7.1612e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 190/1000\n",
            "250/250 [==============================] - 0s 236us/sample - loss: 7.6205e-05 - tanh_accuracy: 1.0000 - val_loss: 7.1520e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 191/1000\n",
            "250/250 [==============================] - 0s 243us/sample - loss: 7.6108e-05 - tanh_accuracy: 1.0000 - val_loss: 7.1429e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 192/1000\n",
            "250/250 [==============================] - 0s 267us/sample - loss: 7.6011e-05 - tanh_accuracy: 1.0000 - val_loss: 7.1337e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 193/1000\n",
            "250/250 [==============================] - 0s 242us/sample - loss: 7.5914e-05 - tanh_accuracy: 1.0000 - val_loss: 7.1245e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 194/1000\n",
            "250/250 [==============================] - 0s 244us/sample - loss: 7.5816e-05 - tanh_accuracy: 1.0000 - val_loss: 7.1154e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 195/1000\n",
            "250/250 [==============================] - 0s 313us/sample - loss: 7.5720e-05 - tanh_accuracy: 1.0000 - val_loss: 7.1063e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 196/1000\n",
            "250/250 [==============================] - 0s 254us/sample - loss: 7.5625e-05 - tanh_accuracy: 1.0000 - val_loss: 7.0972e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 197/1000\n",
            "250/250 [==============================] - 0s 252us/sample - loss: 7.5529e-05 - tanh_accuracy: 1.0000 - val_loss: 7.0882e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 198/1000\n",
            "250/250 [==============================] - 0s 278us/sample - loss: 7.5434e-05 - tanh_accuracy: 1.0000 - val_loss: 7.0792e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 199/1000\n",
            "250/250 [==============================] - 0s 228us/sample - loss: 7.5339e-05 - tanh_accuracy: 1.0000 - val_loss: 7.0703e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 200/1000\n",
            "250/250 [==============================] - 0s 238us/sample - loss: 7.5244e-05 - tanh_accuracy: 1.0000 - val_loss: 7.0613e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 201/1000\n",
            "250/250 [==============================] - 0s 243us/sample - loss: 7.5150e-05 - tanh_accuracy: 1.0000 - val_loss: 7.0523e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 202/1000\n",
            "250/250 [==============================] - 0s 228us/sample - loss: 7.5055e-05 - tanh_accuracy: 1.0000 - val_loss: 7.0434e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 203/1000\n",
            "250/250 [==============================] - 0s 231us/sample - loss: 7.4961e-05 - tanh_accuracy: 1.0000 - val_loss: 7.0345e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 204/1000\n",
            "250/250 [==============================] - 0s 212us/sample - loss: 7.4867e-05 - tanh_accuracy: 1.0000 - val_loss: 7.0256e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 205/1000\n",
            "250/250 [==============================] - 0s 220us/sample - loss: 7.4773e-05 - tanh_accuracy: 1.0000 - val_loss: 7.0167e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 206/1000\n",
            "250/250 [==============================] - 0s 249us/sample - loss: 7.4679e-05 - tanh_accuracy: 1.0000 - val_loss: 7.0079e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 207/1000\n",
            "250/250 [==============================] - 0s 238us/sample - loss: 7.4586e-05 - tanh_accuracy: 1.0000 - val_loss: 6.9991e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 208/1000\n",
            "250/250 [==============================] - 0s 238us/sample - loss: 7.4493e-05 - tanh_accuracy: 1.0000 - val_loss: 6.9903e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 209/1000\n",
            "250/250 [==============================] - 0s 217us/sample - loss: 7.4400e-05 - tanh_accuracy: 1.0000 - val_loss: 6.9815e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 210/1000\n",
            "250/250 [==============================] - 0s 239us/sample - loss: 7.4307e-05 - tanh_accuracy: 1.0000 - val_loss: 6.9727e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 211/1000\n",
            "250/250 [==============================] - 0s 269us/sample - loss: 7.4214e-05 - tanh_accuracy: 1.0000 - val_loss: 6.9640e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 212/1000\n",
            "250/250 [==============================] - 0s 259us/sample - loss: 7.4122e-05 - tanh_accuracy: 1.0000 - val_loss: 6.9552e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 213/1000\n",
            "250/250 [==============================] - 0s 274us/sample - loss: 7.4029e-05 - tanh_accuracy: 1.0000 - val_loss: 6.9465e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 214/1000\n",
            "250/250 [==============================] - 0s 298us/sample - loss: 7.3938e-05 - tanh_accuracy: 1.0000 - val_loss: 6.9378e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 215/1000\n",
            "250/250 [==============================] - 0s 264us/sample - loss: 7.3845e-05 - tanh_accuracy: 1.0000 - val_loss: 6.9291e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 216/1000\n",
            "250/250 [==============================] - 0s 246us/sample - loss: 7.3753e-05 - tanh_accuracy: 1.0000 - val_loss: 6.9204e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 217/1000\n",
            "250/250 [==============================] - 0s 288us/sample - loss: 7.3661e-05 - tanh_accuracy: 1.0000 - val_loss: 6.9118e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 218/1000\n",
            "250/250 [==============================] - 0s 257us/sample - loss: 7.3570e-05 - tanh_accuracy: 1.0000 - val_loss: 6.9032e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 219/1000\n",
            "250/250 [==============================] - 0s 263us/sample - loss: 7.3480e-05 - tanh_accuracy: 1.0000 - val_loss: 6.8947e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 220/1000\n",
            "250/250 [==============================] - 0s 241us/sample - loss: 7.3389e-05 - tanh_accuracy: 1.0000 - val_loss: 6.8861e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 221/1000\n",
            "250/250 [==============================] - 0s 246us/sample - loss: 7.3299e-05 - tanh_accuracy: 1.0000 - val_loss: 6.8776e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 222/1000\n",
            "250/250 [==============================] - 0s 253us/sample - loss: 7.3210e-05 - tanh_accuracy: 1.0000 - val_loss: 6.8692e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 223/1000\n",
            "250/250 [==============================] - 0s 279us/sample - loss: 7.3120e-05 - tanh_accuracy: 1.0000 - val_loss: 6.8605e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 224/1000\n",
            "250/250 [==============================] - 0s 235us/sample - loss: 7.3028e-05 - tanh_accuracy: 1.0000 - val_loss: 6.8521e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 225/1000\n",
            "250/250 [==============================] - 0s 262us/sample - loss: 7.2939e-05 - tanh_accuracy: 1.0000 - val_loss: 6.8436e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 226/1000\n",
            "250/250 [==============================] - 0s 287us/sample - loss: 7.2850e-05 - tanh_accuracy: 1.0000 - val_loss: 6.8352e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 227/1000\n",
            "250/250 [==============================] - 0s 273us/sample - loss: 7.2761e-05 - tanh_accuracy: 1.0000 - val_loss: 6.8268e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 228/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 7.2672e-05 - tanh_accuracy: 1.0000 - val_loss: 6.8184e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 229/1000\n",
            "250/250 [==============================] - 0s 228us/sample - loss: 7.2584e-05 - tanh_accuracy: 1.0000 - val_loss: 6.8101e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 230/1000\n",
            "250/250 [==============================] - 0s 247us/sample - loss: 7.2496e-05 - tanh_accuracy: 1.0000 - val_loss: 6.8017e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 231/1000\n",
            "250/250 [==============================] - 0s 242us/sample - loss: 7.2408e-05 - tanh_accuracy: 1.0000 - val_loss: 6.7934e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 232/1000\n",
            "250/250 [==============================] - 0s 225us/sample - loss: 7.2320e-05 - tanh_accuracy: 1.0000 - val_loss: 6.7850e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 233/1000\n",
            "250/250 [==============================] - 0s 241us/sample - loss: 7.2231e-05 - tanh_accuracy: 1.0000 - val_loss: 6.7767e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 234/1000\n",
            "250/250 [==============================] - 0s 236us/sample - loss: 7.2143e-05 - tanh_accuracy: 1.0000 - val_loss: 6.7683e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 235/1000\n",
            "250/250 [==============================] - 0s 243us/sample - loss: 7.2054e-05 - tanh_accuracy: 1.0000 - val_loss: 6.7601e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 236/1000\n",
            "250/250 [==============================] - 0s 231us/sample - loss: 7.1967e-05 - tanh_accuracy: 1.0000 - val_loss: 6.7519e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 237/1000\n",
            "250/250 [==============================] - 0s 233us/sample - loss: 7.1880e-05 - tanh_accuracy: 1.0000 - val_loss: 6.7437e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 238/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 7.1793e-05 - tanh_accuracy: 1.0000 - val_loss: 6.7355e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 239/1000\n",
            "250/250 [==============================] - 0s 229us/sample - loss: 7.1707e-05 - tanh_accuracy: 1.0000 - val_loss: 6.7273e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 240/1000\n",
            "250/250 [==============================] - 0s 249us/sample - loss: 7.1621e-05 - tanh_accuracy: 1.0000 - val_loss: 6.7192e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 241/1000\n",
            "250/250 [==============================] - 0s 256us/sample - loss: 7.1535e-05 - tanh_accuracy: 1.0000 - val_loss: 6.7110e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 242/1000\n",
            "250/250 [==============================] - 0s 240us/sample - loss: 7.1449e-05 - tanh_accuracy: 1.0000 - val_loss: 6.7029e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 243/1000\n",
            "250/250 [==============================] - 0s 217us/sample - loss: 7.1363e-05 - tanh_accuracy: 1.0000 - val_loss: 6.6948e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 244/1000\n",
            "250/250 [==============================] - 0s 239us/sample - loss: 7.1278e-05 - tanh_accuracy: 1.0000 - val_loss: 6.6867e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 245/1000\n",
            "250/250 [==============================] - 0s 238us/sample - loss: 7.1192e-05 - tanh_accuracy: 1.0000 - val_loss: 6.6787e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 246/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 7.1107e-05 - tanh_accuracy: 1.0000 - val_loss: 6.6707e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 247/1000\n",
            "250/250 [==============================] - 0s 212us/sample - loss: 7.1023e-05 - tanh_accuracy: 1.0000 - val_loss: 6.6627e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 248/1000\n",
            "250/250 [==============================] - 0s 204us/sample - loss: 7.0938e-05 - tanh_accuracy: 1.0000 - val_loss: 6.6547e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 249/1000\n",
            "250/250 [==============================] - 0s 250us/sample - loss: 7.0854e-05 - tanh_accuracy: 1.0000 - val_loss: 6.6467e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 250/1000\n",
            "250/250 [==============================] - 0s 217us/sample - loss: 7.0770e-05 - tanh_accuracy: 1.0000 - val_loss: 6.6388e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 251/1000\n",
            "250/250 [==============================] - 0s 206us/sample - loss: 7.0686e-05 - tanh_accuracy: 1.0000 - val_loss: 6.6308e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 252/1000\n",
            "250/250 [==============================] - 0s 214us/sample - loss: 7.0601e-05 - tanh_accuracy: 1.0000 - val_loss: 6.6227e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 253/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 7.0516e-05 - tanh_accuracy: 1.0000 - val_loss: 6.6148e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 254/1000\n",
            "250/250 [==============================] - 0s 224us/sample - loss: 7.0432e-05 - tanh_accuracy: 1.0000 - val_loss: 6.6069e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 255/1000\n",
            "250/250 [==============================] - 0s 213us/sample - loss: 7.0349e-05 - tanh_accuracy: 1.0000 - val_loss: 6.5991e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 256/1000\n",
            "250/250 [==============================] - 0s 203us/sample - loss: 7.0266e-05 - tanh_accuracy: 1.0000 - val_loss: 6.5913e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 257/1000\n",
            "250/250 [==============================] - 0s 205us/sample - loss: 7.0183e-05 - tanh_accuracy: 1.0000 - val_loss: 6.5834e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 258/1000\n",
            "250/250 [==============================] - 0s 206us/sample - loss: 7.0101e-05 - tanh_accuracy: 1.0000 - val_loss: 6.5756e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 259/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 7.0018e-05 - tanh_accuracy: 1.0000 - val_loss: 6.5678e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 260/1000\n",
            "250/250 [==============================] - 0s 222us/sample - loss: 6.9936e-05 - tanh_accuracy: 1.0000 - val_loss: 6.5601e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 261/1000\n",
            "250/250 [==============================] - 0s 219us/sample - loss: 6.9854e-05 - tanh_accuracy: 1.0000 - val_loss: 6.5523e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 262/1000\n",
            "250/250 [==============================] - 0s 226us/sample - loss: 6.9772e-05 - tanh_accuracy: 1.0000 - val_loss: 6.5446e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 263/1000\n",
            "250/250 [==============================] - 0s 257us/sample - loss: 6.9691e-05 - tanh_accuracy: 1.0000 - val_loss: 6.5369e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 264/1000\n",
            "250/250 [==============================] - 0s 223us/sample - loss: 6.9609e-05 - tanh_accuracy: 1.0000 - val_loss: 6.5292e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 265/1000\n",
            "250/250 [==============================] - 0s 217us/sample - loss: 6.9528e-05 - tanh_accuracy: 1.0000 - val_loss: 6.5215e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 266/1000\n",
            "250/250 [==============================] - 0s 225us/sample - loss: 6.9447e-05 - tanh_accuracy: 1.0000 - val_loss: 6.5138e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 267/1000\n",
            "250/250 [==============================] - 0s 242us/sample - loss: 6.9366e-05 - tanh_accuracy: 1.0000 - val_loss: 6.5062e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 268/1000\n",
            "250/250 [==============================] - 0s 224us/sample - loss: 6.9285e-05 - tanh_accuracy: 1.0000 - val_loss: 6.4985e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 269/1000\n",
            "250/250 [==============================] - 0s 202us/sample - loss: 6.9204e-05 - tanh_accuracy: 1.0000 - val_loss: 6.4909e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 270/1000\n",
            "250/250 [==============================] - 0s 218us/sample - loss: 6.9124e-05 - tanh_accuracy: 1.0000 - val_loss: 6.4833e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 271/1000\n",
            "250/250 [==============================] - 0s 222us/sample - loss: 6.9043e-05 - tanh_accuracy: 1.0000 - val_loss: 6.4756e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 272/1000\n",
            "250/250 [==============================] - 0s 204us/sample - loss: 6.8962e-05 - tanh_accuracy: 1.0000 - val_loss: 6.4680e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 273/1000\n",
            "250/250 [==============================] - 0s 209us/sample - loss: 6.8881e-05 - tanh_accuracy: 1.0000 - val_loss: 6.4605e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 274/1000\n",
            "250/250 [==============================] - 0s 237us/sample - loss: 6.8802e-05 - tanh_accuracy: 1.0000 - val_loss: 6.4529e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 275/1000\n",
            "250/250 [==============================] - 0s 208us/sample - loss: 6.8722e-05 - tanh_accuracy: 1.0000 - val_loss: 6.4454e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 276/1000\n",
            "250/250 [==============================] - 0s 208us/sample - loss: 6.8643e-05 - tanh_accuracy: 1.0000 - val_loss: 6.4379e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 277/1000\n",
            "250/250 [==============================] - 0s 211us/sample - loss: 6.8563e-05 - tanh_accuracy: 1.0000 - val_loss: 6.4304e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 278/1000\n",
            "250/250 [==============================] - 0s 235us/sample - loss: 6.8484e-05 - tanh_accuracy: 1.0000 - val_loss: 6.4229e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 279/1000\n",
            "250/250 [==============================] - 0s 244us/sample - loss: 6.8406e-05 - tanh_accuracy: 1.0000 - val_loss: 6.4155e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 280/1000\n",
            "250/250 [==============================] - 0s 217us/sample - loss: 6.8327e-05 - tanh_accuracy: 1.0000 - val_loss: 6.4081e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 281/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 6.8249e-05 - tanh_accuracy: 1.0000 - val_loss: 6.4007e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 282/1000\n",
            "250/250 [==============================] - 0s 214us/sample - loss: 6.8170e-05 - tanh_accuracy: 1.0000 - val_loss: 6.3933e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 283/1000\n",
            "250/250 [==============================] - 0s 201us/sample - loss: 6.8092e-05 - tanh_accuracy: 1.0000 - val_loss: 6.3859e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 284/1000\n",
            "250/250 [==============================] - 0s 222us/sample - loss: 6.8014e-05 - tanh_accuracy: 1.0000 - val_loss: 6.3785e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 285/1000\n",
            "250/250 [==============================] - 0s 209us/sample - loss: 6.7936e-05 - tanh_accuracy: 1.0000 - val_loss: 6.3712e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 286/1000\n",
            "250/250 [==============================] - 0s 210us/sample - loss: 6.7859e-05 - tanh_accuracy: 1.0000 - val_loss: 6.3638e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 287/1000\n",
            "250/250 [==============================] - 0s 211us/sample - loss: 6.7781e-05 - tanh_accuracy: 1.0000 - val_loss: 6.3565e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 288/1000\n",
            "250/250 [==============================] - 0s 231us/sample - loss: 6.7704e-05 - tanh_accuracy: 1.0000 - val_loss: 6.3492e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 289/1000\n",
            "250/250 [==============================] - 0s 219us/sample - loss: 6.7627e-05 - tanh_accuracy: 1.0000 - val_loss: 6.3419e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 290/1000\n",
            "250/250 [==============================] - 0s 203us/sample - loss: 6.7550e-05 - tanh_accuracy: 1.0000 - val_loss: 6.3347e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 291/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 6.7473e-05 - tanh_accuracy: 1.0000 - val_loss: 6.3274e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 292/1000\n",
            "250/250 [==============================] - 0s 211us/sample - loss: 6.7397e-05 - tanh_accuracy: 1.0000 - val_loss: 6.3201e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 293/1000\n",
            "250/250 [==============================] - 0s 214us/sample - loss: 6.7320e-05 - tanh_accuracy: 1.0000 - val_loss: 6.3130e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 294/1000\n",
            "250/250 [==============================] - 0s 290us/sample - loss: 6.7244e-05 - tanh_accuracy: 1.0000 - val_loss: 6.3057e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 295/1000\n",
            "250/250 [==============================] - 0s 246us/sample - loss: 6.7168e-05 - tanh_accuracy: 1.0000 - val_loss: 6.2986e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 296/1000\n",
            "250/250 [==============================] - 0s 233us/sample - loss: 6.7092e-05 - tanh_accuracy: 1.0000 - val_loss: 6.2914e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 297/1000\n",
            "250/250 [==============================] - 0s 276us/sample - loss: 6.7016e-05 - tanh_accuracy: 1.0000 - val_loss: 6.2842e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 298/1000\n",
            "250/250 [==============================] - 0s 220us/sample - loss: 6.6941e-05 - tanh_accuracy: 1.0000 - val_loss: 6.2770e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 299/1000\n",
            "250/250 [==============================] - 0s 220us/sample - loss: 6.6864e-05 - tanh_accuracy: 1.0000 - val_loss: 6.2699e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 300/1000\n",
            "250/250 [==============================] - 0s 221us/sample - loss: 6.6788e-05 - tanh_accuracy: 1.0000 - val_loss: 6.2628e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 301/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 6.6713e-05 - tanh_accuracy: 1.0000 - val_loss: 6.2557e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 302/1000\n",
            "250/250 [==============================] - 0s 212us/sample - loss: 6.6638e-05 - tanh_accuracy: 1.0000 - val_loss: 6.2486e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 303/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 6.6563e-05 - tanh_accuracy: 1.0000 - val_loss: 6.2415e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 304/1000\n",
            "250/250 [==============================] - 0s 221us/sample - loss: 6.6489e-05 - tanh_accuracy: 1.0000 - val_loss: 6.2344e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 305/1000\n",
            "250/250 [==============================] - 0s 210us/sample - loss: 6.6414e-05 - tanh_accuracy: 1.0000 - val_loss: 6.2274e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 306/1000\n",
            "250/250 [==============================] - 0s 231us/sample - loss: 6.6340e-05 - tanh_accuracy: 1.0000 - val_loss: 6.2204e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 307/1000\n",
            "250/250 [==============================] - 0s 226us/sample - loss: 6.6266e-05 - tanh_accuracy: 1.0000 - val_loss: 6.2134e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 308/1000\n",
            "250/250 [==============================] - 0s 218us/sample - loss: 6.6191e-05 - tanh_accuracy: 1.0000 - val_loss: 6.2064e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 309/1000\n",
            "250/250 [==============================] - 0s 222us/sample - loss: 6.6118e-05 - tanh_accuracy: 1.0000 - val_loss: 6.1994e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 310/1000\n",
            "250/250 [==============================] - 0s 212us/sample - loss: 6.6044e-05 - tanh_accuracy: 1.0000 - val_loss: 6.1925e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 311/1000\n",
            "250/250 [==============================] - 0s 226us/sample - loss: 6.5971e-05 - tanh_accuracy: 1.0000 - val_loss: 6.1855e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 312/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 6.5896e-05 - tanh_accuracy: 1.0000 - val_loss: 6.1786e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 313/1000\n",
            "250/250 [==============================] - 0s 197us/sample - loss: 6.5823e-05 - tanh_accuracy: 1.0000 - val_loss: 6.1716e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 314/1000\n",
            "250/250 [==============================] - 0s 203us/sample - loss: 6.5750e-05 - tanh_accuracy: 1.0000 - val_loss: 6.1648e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 315/1000\n",
            "250/250 [==============================] - 0s 213us/sample - loss: 6.5677e-05 - tanh_accuracy: 1.0000 - val_loss: 6.1579e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 316/1000\n",
            "250/250 [==============================] - 0s 238us/sample - loss: 6.5604e-05 - tanh_accuracy: 1.0000 - val_loss: 6.1510e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 317/1000\n",
            "250/250 [==============================] - 0s 212us/sample - loss: 6.5532e-05 - tanh_accuracy: 1.0000 - val_loss: 6.1441e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 318/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 6.5460e-05 - tanh_accuracy: 1.0000 - val_loss: 6.1373e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 319/1000\n",
            "250/250 [==============================] - 0s 226us/sample - loss: 6.5387e-05 - tanh_accuracy: 1.0000 - val_loss: 6.1305e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 320/1000\n",
            "250/250 [==============================] - 0s 220us/sample - loss: 6.5315e-05 - tanh_accuracy: 1.0000 - val_loss: 6.1237e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 321/1000\n",
            "250/250 [==============================] - 0s 217us/sample - loss: 6.5243e-05 - tanh_accuracy: 1.0000 - val_loss: 6.1169e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 322/1000\n",
            "250/250 [==============================] - 0s 212us/sample - loss: 6.5172e-05 - tanh_accuracy: 1.0000 - val_loss: 6.1101e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 323/1000\n",
            "250/250 [==============================] - 0s 210us/sample - loss: 6.5100e-05 - tanh_accuracy: 1.0000 - val_loss: 6.1033e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 324/1000\n",
            "250/250 [==============================] - 0s 219us/sample - loss: 6.5028e-05 - tanh_accuracy: 1.0000 - val_loss: 6.0965e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 325/1000\n",
            "250/250 [==============================] - 0s 237us/sample - loss: 6.4957e-05 - tanh_accuracy: 1.0000 - val_loss: 6.0898e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 326/1000\n",
            "250/250 [==============================] - 0s 212us/sample - loss: 6.4885e-05 - tanh_accuracy: 1.0000 - val_loss: 6.0830e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 327/1000\n",
            "250/250 [==============================] - 0s 202us/sample - loss: 6.4814e-05 - tanh_accuracy: 1.0000 - val_loss: 6.0762e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 328/1000\n",
            "250/250 [==============================] - 0s 207us/sample - loss: 6.4742e-05 - tanh_accuracy: 1.0000 - val_loss: 6.0695e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 329/1000\n",
            "250/250 [==============================] - 0s 214us/sample - loss: 6.4670e-05 - tanh_accuracy: 1.0000 - val_loss: 6.0628e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 330/1000\n",
            "250/250 [==============================] - 0s 212us/sample - loss: 6.4599e-05 - tanh_accuracy: 1.0000 - val_loss: 6.0561e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 331/1000\n",
            "250/250 [==============================] - 0s 218us/sample - loss: 6.4529e-05 - tanh_accuracy: 1.0000 - val_loss: 6.0495e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 332/1000\n",
            "250/250 [==============================] - 0s 206us/sample - loss: 6.4459e-05 - tanh_accuracy: 1.0000 - val_loss: 6.0428e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 333/1000\n",
            "250/250 [==============================] - 0s 200us/sample - loss: 6.4389e-05 - tanh_accuracy: 1.0000 - val_loss: 6.0362e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 334/1000\n",
            "250/250 [==============================] - 0s 220us/sample - loss: 6.4319e-05 - tanh_accuracy: 1.0000 - val_loss: 6.0296e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 335/1000\n",
            "250/250 [==============================] - 0s 244us/sample - loss: 6.4249e-05 - tanh_accuracy: 1.0000 - val_loss: 6.0229e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 336/1000\n",
            "250/250 [==============================] - 0s 227us/sample - loss: 6.4178e-05 - tanh_accuracy: 1.0000 - val_loss: 6.0164e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 337/1000\n",
            "250/250 [==============================] - 0s 213us/sample - loss: 6.4109e-05 - tanh_accuracy: 1.0000 - val_loss: 6.0098e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 338/1000\n",
            "250/250 [==============================] - 0s 214us/sample - loss: 6.4039e-05 - tanh_accuracy: 1.0000 - val_loss: 6.0032e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 339/1000\n",
            "250/250 [==============================] - 0s 214us/sample - loss: 6.3970e-05 - tanh_accuracy: 1.0000 - val_loss: 5.9967e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 340/1000\n",
            "250/250 [==============================] - 0s 213us/sample - loss: 6.3901e-05 - tanh_accuracy: 1.0000 - val_loss: 5.9901e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 341/1000\n",
            "250/250 [==============================] - 0s 213us/sample - loss: 6.3832e-05 - tanh_accuracy: 1.0000 - val_loss: 5.9836e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 342/1000\n",
            "250/250 [==============================] - 0s 205us/sample - loss: 6.3763e-05 - tanh_accuracy: 1.0000 - val_loss: 5.9771e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 343/1000\n",
            "250/250 [==============================] - 0s 208us/sample - loss: 6.3694e-05 - tanh_accuracy: 1.0000 - val_loss: 5.9706e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 344/1000\n",
            "250/250 [==============================] - 0s 218us/sample - loss: 6.3626e-05 - tanh_accuracy: 1.0000 - val_loss: 5.9642e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 345/1000\n",
            "250/250 [==============================] - 0s 219us/sample - loss: 6.3557e-05 - tanh_accuracy: 1.0000 - val_loss: 5.9577e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 346/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 6.3489e-05 - tanh_accuracy: 1.0000 - val_loss: 5.9513e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 347/1000\n",
            "250/250 [==============================] - 0s 231us/sample - loss: 6.3421e-05 - tanh_accuracy: 1.0000 - val_loss: 5.9448e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 348/1000\n",
            "250/250 [==============================] - 0s 211us/sample - loss: 6.3353e-05 - tanh_accuracy: 1.0000 - val_loss: 5.9384e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 349/1000\n",
            "250/250 [==============================] - 0s 227us/sample - loss: 6.3285e-05 - tanh_accuracy: 1.0000 - val_loss: 5.9320e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 350/1000\n",
            "250/250 [==============================] - 0s 210us/sample - loss: 6.3218e-05 - tanh_accuracy: 1.0000 - val_loss: 5.9257e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 351/1000\n",
            "250/250 [==============================] - 0s 224us/sample - loss: 6.3151e-05 - tanh_accuracy: 1.0000 - val_loss: 5.9193e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 352/1000\n",
            "250/250 [==============================] - 0s 223us/sample - loss: 6.3083e-05 - tanh_accuracy: 1.0000 - val_loss: 5.9129e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 353/1000\n",
            "250/250 [==============================] - 0s 208us/sample - loss: 6.3016e-05 - tanh_accuracy: 1.0000 - val_loss: 5.9066e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 354/1000\n",
            "250/250 [==============================] - 0s 221us/sample - loss: 6.2949e-05 - tanh_accuracy: 1.0000 - val_loss: 5.9002e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 355/1000\n",
            "250/250 [==============================] - 0s 226us/sample - loss: 6.2881e-05 - tanh_accuracy: 1.0000 - val_loss: 5.8938e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 356/1000\n",
            "250/250 [==============================] - 0s 212us/sample - loss: 6.2813e-05 - tanh_accuracy: 1.0000 - val_loss: 5.8875e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 357/1000\n",
            "250/250 [==============================] - 0s 220us/sample - loss: 6.2747e-05 - tanh_accuracy: 1.0000 - val_loss: 5.8812e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 358/1000\n",
            "250/250 [==============================] - 0s 239us/sample - loss: 6.2680e-05 - tanh_accuracy: 1.0000 - val_loss: 5.8749e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 359/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 6.2614e-05 - tanh_accuracy: 1.0000 - val_loss: 5.8686e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 360/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 6.2548e-05 - tanh_accuracy: 1.0000 - val_loss: 5.8624e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 361/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 6.2482e-05 - tanh_accuracy: 1.0000 - val_loss: 5.8562e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 362/1000\n",
            "250/250 [==============================] - 0s 219us/sample - loss: 6.2415e-05 - tanh_accuracy: 1.0000 - val_loss: 5.8499e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 363/1000\n",
            "250/250 [==============================] - 0s 228us/sample - loss: 6.2350e-05 - tanh_accuracy: 1.0000 - val_loss: 5.8437e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 364/1000\n",
            "250/250 [==============================] - 0s 221us/sample - loss: 6.2284e-05 - tanh_accuracy: 1.0000 - val_loss: 5.8375e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 365/1000\n",
            "250/250 [==============================] - 0s 240us/sample - loss: 6.2218e-05 - tanh_accuracy: 1.0000 - val_loss: 5.8312e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 366/1000\n",
            "250/250 [==============================] - 0s 231us/sample - loss: 6.2152e-05 - tanh_accuracy: 1.0000 - val_loss: 5.8251e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 367/1000\n",
            "250/250 [==============================] - 0s 221us/sample - loss: 6.2087e-05 - tanh_accuracy: 1.0000 - val_loss: 5.8189e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 368/1000\n",
            "250/250 [==============================] - 0s 222us/sample - loss: 6.2022e-05 - tanh_accuracy: 1.0000 - val_loss: 5.8128e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 369/1000\n",
            "250/250 [==============================] - 0s 217us/sample - loss: 6.1957e-05 - tanh_accuracy: 1.0000 - val_loss: 5.8066e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 370/1000\n",
            "250/250 [==============================] - 0s 219us/sample - loss: 6.1892e-05 - tanh_accuracy: 1.0000 - val_loss: 5.8004e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 371/1000\n",
            "250/250 [==============================] - 0s 207us/sample - loss: 6.1827e-05 - tanh_accuracy: 1.0000 - val_loss: 5.7943e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 372/1000\n",
            "250/250 [==============================] - 0s 205us/sample - loss: 6.1762e-05 - tanh_accuracy: 1.0000 - val_loss: 5.7882e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 373/1000\n",
            "250/250 [==============================] - 0s 217us/sample - loss: 6.1698e-05 - tanh_accuracy: 1.0000 - val_loss: 5.7821e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 374/1000\n",
            "250/250 [==============================] - 0s 217us/sample - loss: 6.1633e-05 - tanh_accuracy: 1.0000 - val_loss: 5.7760e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 375/1000\n",
            "250/250 [==============================] - 0s 218us/sample - loss: 6.1569e-05 - tanh_accuracy: 1.0000 - val_loss: 5.7700e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 376/1000\n",
            "250/250 [==============================] - 0s 223us/sample - loss: 6.1505e-05 - tanh_accuracy: 1.0000 - val_loss: 5.7639e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 377/1000\n",
            "250/250 [==============================] - 0s 212us/sample - loss: 6.1440e-05 - tanh_accuracy: 1.0000 - val_loss: 5.7579e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 378/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 6.1377e-05 - tanh_accuracy: 1.0000 - val_loss: 5.7519e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 379/1000\n",
            "250/250 [==============================] - 0s 242us/sample - loss: 6.1313e-05 - tanh_accuracy: 1.0000 - val_loss: 5.7458e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 380/1000\n",
            "250/250 [==============================] - 0s 212us/sample - loss: 6.1250e-05 - tanh_accuracy: 1.0000 - val_loss: 5.7398e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 381/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 6.1185e-05 - tanh_accuracy: 1.0000 - val_loss: 5.7338e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 382/1000\n",
            "250/250 [==============================] - 0s 246us/sample - loss: 6.1122e-05 - tanh_accuracy: 1.0000 - val_loss: 5.7278e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 383/1000\n",
            "250/250 [==============================] - 0s 214us/sample - loss: 6.1059e-05 - tanh_accuracy: 1.0000 - val_loss: 5.7219e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 384/1000\n",
            "250/250 [==============================] - 0s 218us/sample - loss: 6.0996e-05 - tanh_accuracy: 1.0000 - val_loss: 5.7159e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 385/1000\n",
            "250/250 [==============================] - 0s 242us/sample - loss: 6.0933e-05 - tanh_accuracy: 1.0000 - val_loss: 5.7099e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 386/1000\n",
            "250/250 [==============================] - 0s 234us/sample - loss: 6.0870e-05 - tanh_accuracy: 1.0000 - val_loss: 5.7040e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 387/1000\n",
            "250/250 [==============================] - 0s 245us/sample - loss: 6.0808e-05 - tanh_accuracy: 1.0000 - val_loss: 5.6981e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 388/1000\n",
            "250/250 [==============================] - 0s 210us/sample - loss: 6.0745e-05 - tanh_accuracy: 1.0000 - val_loss: 5.6922e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 389/1000\n",
            "250/250 [==============================] - 0s 209us/sample - loss: 6.0683e-05 - tanh_accuracy: 1.0000 - val_loss: 5.6863e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 390/1000\n",
            "250/250 [==============================] - 0s 221us/sample - loss: 6.0621e-05 - tanh_accuracy: 1.0000 - val_loss: 5.6805e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 391/1000\n",
            "250/250 [==============================] - 0s 200us/sample - loss: 6.0558e-05 - tanh_accuracy: 1.0000 - val_loss: 5.6745e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 392/1000\n",
            "250/250 [==============================] - 0s 237us/sample - loss: 6.0495e-05 - tanh_accuracy: 1.0000 - val_loss: 5.6686e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 393/1000\n",
            "250/250 [==============================] - 0s 243us/sample - loss: 6.0433e-05 - tanh_accuracy: 1.0000 - val_loss: 5.6628e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 394/1000\n",
            "250/250 [==============================] - 0s 232us/sample - loss: 6.0371e-05 - tanh_accuracy: 1.0000 - val_loss: 5.6569e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 395/1000\n",
            "250/250 [==============================] - 0s 231us/sample - loss: 6.0310e-05 - tanh_accuracy: 1.0000 - val_loss: 5.6511e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 396/1000\n",
            "250/250 [==============================] - 0s 224us/sample - loss: 6.0248e-05 - tanh_accuracy: 1.0000 - val_loss: 5.6453e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 397/1000\n",
            "250/250 [==============================] - 0s 207us/sample - loss: 6.0187e-05 - tanh_accuracy: 1.0000 - val_loss: 5.6395e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 398/1000\n",
            "250/250 [==============================] - 0s 212us/sample - loss: 6.0125e-05 - tanh_accuracy: 1.0000 - val_loss: 5.6337e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 399/1000\n",
            "250/250 [==============================] - 0s 222us/sample - loss: 6.0064e-05 - tanh_accuracy: 1.0000 - val_loss: 5.6280e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 400/1000\n",
            "250/250 [==============================] - 0s 219us/sample - loss: 6.0003e-05 - tanh_accuracy: 1.0000 - val_loss: 5.6222e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 401/1000\n",
            "250/250 [==============================] - 0s 236us/sample - loss: 5.9942e-05 - tanh_accuracy: 1.0000 - val_loss: 5.6164e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 402/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 5.9881e-05 - tanh_accuracy: 1.0000 - val_loss: 5.6107e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 403/1000\n",
            "250/250 [==============================] - 0s 262us/sample - loss: 5.9820e-05 - tanh_accuracy: 1.0000 - val_loss: 5.6049e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 404/1000\n",
            "250/250 [==============================] - 0s 209us/sample - loss: 5.9759e-05 - tanh_accuracy: 1.0000 - val_loss: 5.5992e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 405/1000\n",
            "250/250 [==============================] - 0s 211us/sample - loss: 5.9699e-05 - tanh_accuracy: 1.0000 - val_loss: 5.5935e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 406/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 5.9638e-05 - tanh_accuracy: 1.0000 - val_loss: 5.5878e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 407/1000\n",
            "250/250 [==============================] - 0s 218us/sample - loss: 5.9578e-05 - tanh_accuracy: 1.0000 - val_loss: 5.5821e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 408/1000\n",
            "250/250 [==============================] - 0s 234us/sample - loss: 5.9518e-05 - tanh_accuracy: 1.0000 - val_loss: 5.5764e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 409/1000\n",
            "250/250 [==============================] - 0s 219us/sample - loss: 5.9458e-05 - tanh_accuracy: 1.0000 - val_loss: 5.5707e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 410/1000\n",
            "250/250 [==============================] - 0s 225us/sample - loss: 5.9398e-05 - tanh_accuracy: 1.0000 - val_loss: 5.5650e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 411/1000\n",
            "250/250 [==============================] - 0s 212us/sample - loss: 5.9338e-05 - tanh_accuracy: 1.0000 - val_loss: 5.5594e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 412/1000\n",
            "250/250 [==============================] - 0s 237us/sample - loss: 5.9278e-05 - tanh_accuracy: 1.0000 - val_loss: 5.5537e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 413/1000\n",
            "250/250 [==============================] - 0s 219us/sample - loss: 5.9218e-05 - tanh_accuracy: 1.0000 - val_loss: 5.5481e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 414/1000\n",
            "250/250 [==============================] - 0s 206us/sample - loss: 5.9159e-05 - tanh_accuracy: 1.0000 - val_loss: 5.5425e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 415/1000\n",
            "250/250 [==============================] - 0s 235us/sample - loss: 5.9100e-05 - tanh_accuracy: 1.0000 - val_loss: 5.5369e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 416/1000\n",
            "250/250 [==============================] - 0s 227us/sample - loss: 5.9041e-05 - tanh_accuracy: 1.0000 - val_loss: 5.5313e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 417/1000\n",
            "250/250 [==============================] - 0s 228us/sample - loss: 5.8981e-05 - tanh_accuracy: 1.0000 - val_loss: 5.5257e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 418/1000\n",
            "250/250 [==============================] - 0s 214us/sample - loss: 5.8922e-05 - tanh_accuracy: 1.0000 - val_loss: 5.5201e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 419/1000\n",
            "250/250 [==============================] - 0s 217us/sample - loss: 5.8863e-05 - tanh_accuracy: 1.0000 - val_loss: 5.5146e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 420/1000\n",
            "250/250 [==============================] - 0s 211us/sample - loss: 5.8804e-05 - tanh_accuracy: 1.0000 - val_loss: 5.5090e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 421/1000\n",
            "250/250 [==============================] - 0s 218us/sample - loss: 5.8746e-05 - tanh_accuracy: 1.0000 - val_loss: 5.5035e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 422/1000\n",
            "250/250 [==============================] - 0s 232us/sample - loss: 5.8687e-05 - tanh_accuracy: 1.0000 - val_loss: 5.4980e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 423/1000\n",
            "250/250 [==============================] - 0s 221us/sample - loss: 5.8629e-05 - tanh_accuracy: 1.0000 - val_loss: 5.4925e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 424/1000\n",
            "250/250 [==============================] - 0s 250us/sample - loss: 5.8571e-05 - tanh_accuracy: 1.0000 - val_loss: 5.4870e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 425/1000\n",
            "250/250 [==============================] - 0s 233us/sample - loss: 5.8512e-05 - tanh_accuracy: 1.0000 - val_loss: 5.4815e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 426/1000\n",
            "250/250 [==============================] - 0s 205us/sample - loss: 5.8454e-05 - tanh_accuracy: 1.0000 - val_loss: 5.4760e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 427/1000\n",
            "250/250 [==============================] - 0s 212us/sample - loss: 5.8396e-05 - tanh_accuracy: 1.0000 - val_loss: 5.4705e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 428/1000\n",
            "250/250 [==============================] - 0s 207us/sample - loss: 5.8339e-05 - tanh_accuracy: 1.0000 - val_loss: 5.4651e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 429/1000\n",
            "250/250 [==============================] - 0s 243us/sample - loss: 5.8281e-05 - tanh_accuracy: 1.0000 - val_loss: 5.4596e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 430/1000\n",
            "250/250 [==============================] - 0s 226us/sample - loss: 5.8223e-05 - tanh_accuracy: 1.0000 - val_loss: 5.4542e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 431/1000\n",
            "250/250 [==============================] - 0s 224us/sample - loss: 5.8166e-05 - tanh_accuracy: 1.0000 - val_loss: 5.4487e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 432/1000\n",
            "250/250 [==============================] - 0s 199us/sample - loss: 5.8108e-05 - tanh_accuracy: 1.0000 - val_loss: 5.4433e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 433/1000\n",
            "250/250 [==============================] - 0s 209us/sample - loss: 5.8051e-05 - tanh_accuracy: 1.0000 - val_loss: 5.4379e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 434/1000\n",
            "250/250 [==============================] - 0s 226us/sample - loss: 5.7994e-05 - tanh_accuracy: 1.0000 - val_loss: 5.4325e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 435/1000\n",
            "250/250 [==============================] - 0s 206us/sample - loss: 5.7937e-05 - tanh_accuracy: 1.0000 - val_loss: 5.4271e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 436/1000\n",
            "250/250 [==============================] - 0s 214us/sample - loss: 5.7880e-05 - tanh_accuracy: 1.0000 - val_loss: 5.4218e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 437/1000\n",
            "250/250 [==============================] - 0s 207us/sample - loss: 5.7823e-05 - tanh_accuracy: 1.0000 - val_loss: 5.4164e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 438/1000\n",
            "250/250 [==============================] - 0s 227us/sample - loss: 5.7766e-05 - tanh_accuracy: 1.0000 - val_loss: 5.4110e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 439/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 5.7710e-05 - tanh_accuracy: 1.0000 - val_loss: 5.4057e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 440/1000\n",
            "250/250 [==============================] - 0s 214us/sample - loss: 5.7653e-05 - tanh_accuracy: 1.0000 - val_loss: 5.4003e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 441/1000\n",
            "250/250 [==============================] - 0s 225us/sample - loss: 5.7596e-05 - tanh_accuracy: 1.0000 - val_loss: 5.3949e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 442/1000\n",
            "250/250 [==============================] - 0s 203us/sample - loss: 5.7539e-05 - tanh_accuracy: 1.0000 - val_loss: 5.3896e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 443/1000\n",
            "250/250 [==============================] - 0s 202us/sample - loss: 5.7483e-05 - tanh_accuracy: 1.0000 - val_loss: 5.3843e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 444/1000\n",
            "250/250 [==============================] - 0s 211us/sample - loss: 5.7427e-05 - tanh_accuracy: 1.0000 - val_loss: 5.3790e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 445/1000\n",
            "250/250 [==============================] - 0s 210us/sample - loss: 5.7371e-05 - tanh_accuracy: 1.0000 - val_loss: 5.3738e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 446/1000\n",
            "250/250 [==============================] - 0s 211us/sample - loss: 5.7315e-05 - tanh_accuracy: 1.0000 - val_loss: 5.3685e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 447/1000\n",
            "250/250 [==============================] - 0s 201us/sample - loss: 5.7260e-05 - tanh_accuracy: 1.0000 - val_loss: 5.3632e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 448/1000\n",
            "250/250 [==============================] - 0s 219us/sample - loss: 5.7204e-05 - tanh_accuracy: 1.0000 - val_loss: 5.3579e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 449/1000\n",
            "250/250 [==============================] - 0s 204us/sample - loss: 5.7148e-05 - tanh_accuracy: 1.0000 - val_loss: 5.3527e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 450/1000\n",
            "250/250 [==============================] - 0s 231us/sample - loss: 5.7093e-05 - tanh_accuracy: 1.0000 - val_loss: 5.3474e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 451/1000\n",
            "250/250 [==============================] - 0s 221us/sample - loss: 5.7037e-05 - tanh_accuracy: 1.0000 - val_loss: 5.3422e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 452/1000\n",
            "250/250 [==============================] - 0s 224us/sample - loss: 5.6982e-05 - tanh_accuracy: 1.0000 - val_loss: 5.3370e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 453/1000\n",
            "250/250 [==============================] - 0s 220us/sample - loss: 5.6926e-05 - tanh_accuracy: 1.0000 - val_loss: 5.3318e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 454/1000\n",
            "250/250 [==============================] - 0s 220us/sample - loss: 5.6871e-05 - tanh_accuracy: 1.0000 - val_loss: 5.3265e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 455/1000\n",
            "250/250 [==============================] - 0s 213us/sample - loss: 5.6815e-05 - tanh_accuracy: 1.0000 - val_loss: 5.3213e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 456/1000\n",
            "250/250 [==============================] - 0s 213us/sample - loss: 5.6760e-05 - tanh_accuracy: 1.0000 - val_loss: 5.3161e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 457/1000\n",
            "250/250 [==============================] - 0s 245us/sample - loss: 5.6705e-05 - tanh_accuracy: 1.0000 - val_loss: 5.3109e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 458/1000\n",
            "250/250 [==============================] - 0s 224us/sample - loss: 5.6651e-05 - tanh_accuracy: 1.0000 - val_loss: 5.3058e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 459/1000\n",
            "250/250 [==============================] - 0s 250us/sample - loss: 5.6596e-05 - tanh_accuracy: 1.0000 - val_loss: 5.3006e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 460/1000\n",
            "250/250 [==============================] - 0s 205us/sample - loss: 5.6542e-05 - tanh_accuracy: 1.0000 - val_loss: 5.2955e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 461/1000\n",
            "250/250 [==============================] - 0s 203us/sample - loss: 5.6487e-05 - tanh_accuracy: 1.0000 - val_loss: 5.2904e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 462/1000\n",
            "250/250 [==============================] - 0s 222us/sample - loss: 5.6433e-05 - tanh_accuracy: 1.0000 - val_loss: 5.2852e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 463/1000\n",
            "250/250 [==============================] - 0s 217us/sample - loss: 5.6379e-05 - tanh_accuracy: 1.0000 - val_loss: 5.2801e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 464/1000\n",
            "250/250 [==============================] - 0s 207us/sample - loss: 5.6325e-05 - tanh_accuracy: 1.0000 - val_loss: 5.2750e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 465/1000\n",
            "250/250 [==============================] - 0s 206us/sample - loss: 5.6271e-05 - tanh_accuracy: 1.0000 - val_loss: 5.2699e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 466/1000\n",
            "250/250 [==============================] - 0s 213us/sample - loss: 5.6217e-05 - tanh_accuracy: 1.0000 - val_loss: 5.2648e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 467/1000\n",
            "250/250 [==============================] - 0s 226us/sample - loss: 5.6163e-05 - tanh_accuracy: 1.0000 - val_loss: 5.2597e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 468/1000\n",
            "250/250 [==============================] - 0s 237us/sample - loss: 5.6109e-05 - tanh_accuracy: 1.0000 - val_loss: 5.2546e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 469/1000\n",
            "250/250 [==============================] - 0s 234us/sample - loss: 5.6055e-05 - tanh_accuracy: 1.0000 - val_loss: 5.2496e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 470/1000\n",
            "250/250 [==============================] - 0s 219us/sample - loss: 5.6001e-05 - tanh_accuracy: 1.0000 - val_loss: 5.2445e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 471/1000\n",
            "250/250 [==============================] - 0s 235us/sample - loss: 5.5948e-05 - tanh_accuracy: 1.0000 - val_loss: 5.2395e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 472/1000\n",
            "250/250 [==============================] - 0s 241us/sample - loss: 5.5895e-05 - tanh_accuracy: 1.0000 - val_loss: 5.2344e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 473/1000\n",
            "250/250 [==============================] - 0s 217us/sample - loss: 5.5841e-05 - tanh_accuracy: 1.0000 - val_loss: 5.2294e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 474/1000\n",
            "250/250 [==============================] - 0s 214us/sample - loss: 5.5788e-05 - tanh_accuracy: 1.0000 - val_loss: 5.2244e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 475/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 5.5736e-05 - tanh_accuracy: 1.0000 - val_loss: 5.2195e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 476/1000\n",
            "250/250 [==============================] - 0s 233us/sample - loss: 5.5683e-05 - tanh_accuracy: 1.0000 - val_loss: 5.2145e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 477/1000\n",
            "250/250 [==============================] - 0s 230us/sample - loss: 5.5630e-05 - tanh_accuracy: 1.0000 - val_loss: 5.2095e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 478/1000\n",
            "250/250 [==============================] - 0s 279us/sample - loss: 5.5578e-05 - tanh_accuracy: 1.0000 - val_loss: 5.2045e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 479/1000\n",
            "250/250 [==============================] - 0s 249us/sample - loss: 5.5525e-05 - tanh_accuracy: 1.0000 - val_loss: 5.1996e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 480/1000\n",
            "250/250 [==============================] - 0s 213us/sample - loss: 5.5473e-05 - tanh_accuracy: 1.0000 - val_loss: 5.1946e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 481/1000\n",
            "250/250 [==============================] - 0s 222us/sample - loss: 5.5420e-05 - tanh_accuracy: 1.0000 - val_loss: 5.1897e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 482/1000\n",
            "250/250 [==============================] - 0s 238us/sample - loss: 5.5368e-05 - tanh_accuracy: 1.0000 - val_loss: 5.1848e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 483/1000\n",
            "250/250 [==============================] - 0s 228us/sample - loss: 5.5316e-05 - tanh_accuracy: 1.0000 - val_loss: 5.1798e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 484/1000\n",
            "250/250 [==============================] - 0s 214us/sample - loss: 5.5264e-05 - tanh_accuracy: 1.0000 - val_loss: 5.1749e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 485/1000\n",
            "250/250 [==============================] - 0s 221us/sample - loss: 5.5212e-05 - tanh_accuracy: 1.0000 - val_loss: 5.1700e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 486/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 5.5160e-05 - tanh_accuracy: 1.0000 - val_loss: 5.1651e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 487/1000\n",
            "250/250 [==============================] - 0s 224us/sample - loss: 5.5108e-05 - tanh_accuracy: 1.0000 - val_loss: 5.1602e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 488/1000\n",
            "250/250 [==============================] - 0s 228us/sample - loss: 5.5056e-05 - tanh_accuracy: 1.0000 - val_loss: 5.1553e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 489/1000\n",
            "250/250 [==============================] - 0s 218us/sample - loss: 5.5004e-05 - tanh_accuracy: 1.0000 - val_loss: 5.1504e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 490/1000\n",
            "250/250 [==============================] - 0s 213us/sample - loss: 5.4953e-05 - tanh_accuracy: 1.0000 - val_loss: 5.1456e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 491/1000\n",
            "250/250 [==============================] - 0s 227us/sample - loss: 5.4901e-05 - tanh_accuracy: 1.0000 - val_loss: 5.1407e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 492/1000\n",
            "250/250 [==============================] - 0s 202us/sample - loss: 5.4850e-05 - tanh_accuracy: 1.0000 - val_loss: 5.1358e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 493/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 5.4797e-05 - tanh_accuracy: 1.0000 - val_loss: 5.1309e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 494/1000\n",
            "250/250 [==============================] - 0s 219us/sample - loss: 5.4746e-05 - tanh_accuracy: 1.0000 - val_loss: 5.1261e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 495/1000\n",
            "250/250 [==============================] - 0s 209us/sample - loss: 5.4695e-05 - tanh_accuracy: 1.0000 - val_loss: 5.1213e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 496/1000\n",
            "250/250 [==============================] - 0s 220us/sample - loss: 5.4644e-05 - tanh_accuracy: 1.0000 - val_loss: 5.1165e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 497/1000\n",
            "250/250 [==============================] - 0s 227us/sample - loss: 5.4593e-05 - tanh_accuracy: 1.0000 - val_loss: 5.1117e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 498/1000\n",
            "250/250 [==============================] - 0s 240us/sample - loss: 5.4542e-05 - tanh_accuracy: 1.0000 - val_loss: 5.1069e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 499/1000\n",
            "250/250 [==============================] - 0s 206us/sample - loss: 5.4491e-05 - tanh_accuracy: 1.0000 - val_loss: 5.1021e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 500/1000\n",
            "250/250 [==============================] - 0s 212us/sample - loss: 5.4441e-05 - tanh_accuracy: 1.0000 - val_loss: 5.0973e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 501/1000\n",
            "250/250 [==============================] - 0s 228us/sample - loss: 5.4390e-05 - tanh_accuracy: 1.0000 - val_loss: 5.0926e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 502/1000\n",
            "250/250 [==============================] - 0s 207us/sample - loss: 5.4340e-05 - tanh_accuracy: 1.0000 - val_loss: 5.0878e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 503/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 5.4290e-05 - tanh_accuracy: 1.0000 - val_loss: 5.0830e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 504/1000\n",
            "250/250 [==============================] - 0s 218us/sample - loss: 5.4239e-05 - tanh_accuracy: 1.0000 - val_loss: 5.0783e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 505/1000\n",
            "250/250 [==============================] - 0s 217us/sample - loss: 5.4189e-05 - tanh_accuracy: 1.0000 - val_loss: 5.0736e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 506/1000\n",
            "250/250 [==============================] - 0s 212us/sample - loss: 5.4139e-05 - tanh_accuracy: 1.0000 - val_loss: 5.0688e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 507/1000\n",
            "250/250 [==============================] - 0s 219us/sample - loss: 5.4089e-05 - tanh_accuracy: 1.0000 - val_loss: 5.0641e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 508/1000\n",
            "250/250 [==============================] - 0s 209us/sample - loss: 5.4039e-05 - tanh_accuracy: 1.0000 - val_loss: 5.0594e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 509/1000\n",
            "250/250 [==============================] - 0s 210us/sample - loss: 5.3990e-05 - tanh_accuracy: 1.0000 - val_loss: 5.0548e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 510/1000\n",
            "250/250 [==============================] - 0s 220us/sample - loss: 5.3940e-05 - tanh_accuracy: 1.0000 - val_loss: 5.0501e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 511/1000\n",
            "250/250 [==============================] - 0s 236us/sample - loss: 5.3890e-05 - tanh_accuracy: 1.0000 - val_loss: 5.0454e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 512/1000\n",
            "250/250 [==============================] - 0s 240us/sample - loss: 5.3841e-05 - tanh_accuracy: 1.0000 - val_loss: 5.0407e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 513/1000\n",
            "250/250 [==============================] - 0s 225us/sample - loss: 5.3792e-05 - tanh_accuracy: 1.0000 - val_loss: 5.0361e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 514/1000\n",
            "250/250 [==============================] - 0s 217us/sample - loss: 5.3742e-05 - tanh_accuracy: 1.0000 - val_loss: 5.0314e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 515/1000\n",
            "250/250 [==============================] - 0s 220us/sample - loss: 5.3693e-05 - tanh_accuracy: 1.0000 - val_loss: 5.0268e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 516/1000\n",
            "250/250 [==============================] - 0s 210us/sample - loss: 5.3644e-05 - tanh_accuracy: 1.0000 - val_loss: 5.0221e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 517/1000\n",
            "250/250 [==============================] - 0s 209us/sample - loss: 5.3595e-05 - tanh_accuracy: 1.0000 - val_loss: 5.0175e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 518/1000\n",
            "250/250 [==============================] - 0s 236us/sample - loss: 5.3546e-05 - tanh_accuracy: 1.0000 - val_loss: 5.0129e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 519/1000\n",
            "250/250 [==============================] - 0s 255us/sample - loss: 5.3497e-05 - tanh_accuracy: 1.0000 - val_loss: 5.0083e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 520/1000\n",
            "250/250 [==============================] - 0s 250us/sample - loss: 5.3449e-05 - tanh_accuracy: 1.0000 - val_loss: 5.0037e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 521/1000\n",
            "250/250 [==============================] - 0s 289us/sample - loss: 5.3400e-05 - tanh_accuracy: 1.0000 - val_loss: 4.9991e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 522/1000\n",
            "250/250 [==============================] - 0s 229us/sample - loss: 5.3351e-05 - tanh_accuracy: 1.0000 - val_loss: 4.9945e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 523/1000\n",
            "250/250 [==============================] - 0s 299us/sample - loss: 5.3303e-05 - tanh_accuracy: 1.0000 - val_loss: 4.9899e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 524/1000\n",
            "250/250 [==============================] - 0s 243us/sample - loss: 5.3254e-05 - tanh_accuracy: 1.0000 - val_loss: 4.9854e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 525/1000\n",
            "250/250 [==============================] - 0s 262us/sample - loss: 5.3206e-05 - tanh_accuracy: 1.0000 - val_loss: 4.9808e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 526/1000\n",
            "250/250 [==============================] - 0s 221us/sample - loss: 5.3158e-05 - tanh_accuracy: 1.0000 - val_loss: 4.9762e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 527/1000\n",
            "250/250 [==============================] - 0s 232us/sample - loss: 5.3109e-05 - tanh_accuracy: 1.0000 - val_loss: 4.9717e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 528/1000\n",
            "250/250 [==============================] - 0s 209us/sample - loss: 5.3061e-05 - tanh_accuracy: 1.0000 - val_loss: 4.9671e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 529/1000\n",
            "250/250 [==============================] - 0s 229us/sample - loss: 5.3013e-05 - tanh_accuracy: 1.0000 - val_loss: 4.9626e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 530/1000\n",
            "250/250 [==============================] - 0s 225us/sample - loss: 5.2965e-05 - tanh_accuracy: 1.0000 - val_loss: 4.9581e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 531/1000\n",
            "250/250 [==============================] - 0s 236us/sample - loss: 5.2917e-05 - tanh_accuracy: 1.0000 - val_loss: 4.9536e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 532/1000\n",
            "250/250 [==============================] - 0s 238us/sample - loss: 5.2869e-05 - tanh_accuracy: 1.0000 - val_loss: 4.9490e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 533/1000\n",
            "250/250 [==============================] - 0s 223us/sample - loss: 5.2822e-05 - tanh_accuracy: 1.0000 - val_loss: 4.9446e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 534/1000\n",
            "250/250 [==============================] - 0s 225us/sample - loss: 5.2774e-05 - tanh_accuracy: 1.0000 - val_loss: 4.9400e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 535/1000\n",
            "250/250 [==============================] - 0s 222us/sample - loss: 5.2727e-05 - tanh_accuracy: 1.0000 - val_loss: 4.9355e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 536/1000\n",
            "250/250 [==============================] - 0s 211us/sample - loss: 5.2678e-05 - tanh_accuracy: 1.0000 - val_loss: 4.9310e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 537/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 5.2631e-05 - tanh_accuracy: 1.0000 - val_loss: 4.9265e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 538/1000\n",
            "250/250 [==============================] - 0s 272us/sample - loss: 5.2583e-05 - tanh_accuracy: 1.0000 - val_loss: 4.9221e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 539/1000\n",
            "250/250 [==============================] - 0s 242us/sample - loss: 5.2536e-05 - tanh_accuracy: 1.0000 - val_loss: 4.9176e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 540/1000\n",
            "250/250 [==============================] - 0s 222us/sample - loss: 5.2489e-05 - tanh_accuracy: 1.0000 - val_loss: 4.9132e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 541/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 5.2442e-05 - tanh_accuracy: 1.0000 - val_loss: 4.9087e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 542/1000\n",
            "250/250 [==============================] - 0s 231us/sample - loss: 5.2395e-05 - tanh_accuracy: 1.0000 - val_loss: 4.9043e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 543/1000\n",
            "250/250 [==============================] - 0s 239us/sample - loss: 5.2348e-05 - tanh_accuracy: 1.0000 - val_loss: 4.8999e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 544/1000\n",
            "250/250 [==============================] - 0s 237us/sample - loss: 5.2301e-05 - tanh_accuracy: 1.0000 - val_loss: 4.8955e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 545/1000\n",
            "250/250 [==============================] - 0s 228us/sample - loss: 5.2255e-05 - tanh_accuracy: 1.0000 - val_loss: 4.8911e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 546/1000\n",
            "250/250 [==============================] - 0s 240us/sample - loss: 5.2208e-05 - tanh_accuracy: 1.0000 - val_loss: 4.8867e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 547/1000\n",
            "250/250 [==============================] - 0s 217us/sample - loss: 5.2161e-05 - tanh_accuracy: 1.0000 - val_loss: 4.8823e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 548/1000\n",
            "250/250 [==============================] - 0s 226us/sample - loss: 5.2115e-05 - tanh_accuracy: 1.0000 - val_loss: 4.8779e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 549/1000\n",
            "250/250 [==============================] - 0s 236us/sample - loss: 5.2068e-05 - tanh_accuracy: 1.0000 - val_loss: 4.8735e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 550/1000\n",
            "250/250 [==============================] - 0s 222us/sample - loss: 5.2022e-05 - tanh_accuracy: 1.0000 - val_loss: 4.8691e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 551/1000\n",
            "250/250 [==============================] - 0s 224us/sample - loss: 5.1976e-05 - tanh_accuracy: 1.0000 - val_loss: 4.8648e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 552/1000\n",
            "250/250 [==============================] - 0s 214us/sample - loss: 5.1930e-05 - tanh_accuracy: 1.0000 - val_loss: 4.8604e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 553/1000\n",
            "250/250 [==============================] - 0s 229us/sample - loss: 5.1883e-05 - tanh_accuracy: 1.0000 - val_loss: 4.8561e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 554/1000\n",
            "250/250 [==============================] - 0s 231us/sample - loss: 5.1837e-05 - tanh_accuracy: 1.0000 - val_loss: 4.8517e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 555/1000\n",
            "250/250 [==============================] - 0s 223us/sample - loss: 5.1791e-05 - tanh_accuracy: 1.0000 - val_loss: 4.8474e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 556/1000\n",
            "250/250 [==============================] - 0s 229us/sample - loss: 5.1746e-05 - tanh_accuracy: 1.0000 - val_loss: 4.8431e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 557/1000\n",
            "250/250 [==============================] - 0s 239us/sample - loss: 5.1700e-05 - tanh_accuracy: 1.0000 - val_loss: 4.8387e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 558/1000\n",
            "250/250 [==============================] - 0s 221us/sample - loss: 5.1654e-05 - tanh_accuracy: 1.0000 - val_loss: 4.8344e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 559/1000\n",
            "250/250 [==============================] - 0s 238us/sample - loss: 5.1609e-05 - tanh_accuracy: 1.0000 - val_loss: 4.8301e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 560/1000\n",
            "250/250 [==============================] - 0s 232us/sample - loss: 5.1563e-05 - tanh_accuracy: 1.0000 - val_loss: 4.8258e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 561/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 5.1518e-05 - tanh_accuracy: 1.0000 - val_loss: 4.8215e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 562/1000\n",
            "250/250 [==============================] - 0s 208us/sample - loss: 5.1472e-05 - tanh_accuracy: 1.0000 - val_loss: 4.8172e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 563/1000\n",
            "250/250 [==============================] - 0s 221us/sample - loss: 5.1427e-05 - tanh_accuracy: 1.0000 - val_loss: 4.8130e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 564/1000\n",
            "250/250 [==============================] - 0s 210us/sample - loss: 5.1382e-05 - tanh_accuracy: 1.0000 - val_loss: 4.8087e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 565/1000\n",
            "250/250 [==============================] - 0s 236us/sample - loss: 5.1336e-05 - tanh_accuracy: 1.0000 - val_loss: 4.8044e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 566/1000\n",
            "250/250 [==============================] - 0s 231us/sample - loss: 5.1291e-05 - tanh_accuracy: 1.0000 - val_loss: 4.8002e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 567/1000\n",
            "250/250 [==============================] - 0s 222us/sample - loss: 5.1246e-05 - tanh_accuracy: 1.0000 - val_loss: 4.7959e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 568/1000\n",
            "250/250 [==============================] - 0s 221us/sample - loss: 5.1201e-05 - tanh_accuracy: 1.0000 - val_loss: 4.7917e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 569/1000\n",
            "250/250 [==============================] - 0s 237us/sample - loss: 5.1156e-05 - tanh_accuracy: 1.0000 - val_loss: 4.7874e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 570/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 5.1111e-05 - tanh_accuracy: 1.0000 - val_loss: 4.7832e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 571/1000\n",
            "250/250 [==============================] - 0s 222us/sample - loss: 5.1067e-05 - tanh_accuracy: 1.0000 - val_loss: 4.7790e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 572/1000\n",
            "250/250 [==============================] - 0s 239us/sample - loss: 5.1022e-05 - tanh_accuracy: 1.0000 - val_loss: 4.7748e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 573/1000\n",
            "250/250 [==============================] - 0s 236us/sample - loss: 5.0978e-05 - tanh_accuracy: 1.0000 - val_loss: 4.7706e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 574/1000\n",
            "250/250 [==============================] - 0s 219us/sample - loss: 5.0933e-05 - tanh_accuracy: 1.0000 - val_loss: 4.7664e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 575/1000\n",
            "250/250 [==============================] - 0s 232us/sample - loss: 5.0889e-05 - tanh_accuracy: 1.0000 - val_loss: 4.7622e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 576/1000\n",
            "250/250 [==============================] - 0s 240us/sample - loss: 5.0845e-05 - tanh_accuracy: 1.0000 - val_loss: 4.7581e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 577/1000\n",
            "250/250 [==============================] - 0s 229us/sample - loss: 5.0801e-05 - tanh_accuracy: 1.0000 - val_loss: 4.7539e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 578/1000\n",
            "250/250 [==============================] - 0s 228us/sample - loss: 5.0756e-05 - tanh_accuracy: 1.0000 - val_loss: 4.7497e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 579/1000\n",
            "250/250 [==============================] - 0s 221us/sample - loss: 5.0712e-05 - tanh_accuracy: 1.0000 - val_loss: 4.7456e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 580/1000\n",
            "250/250 [==============================] - 0s 231us/sample - loss: 5.0668e-05 - tanh_accuracy: 1.0000 - val_loss: 4.7414e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 581/1000\n",
            "250/250 [==============================] - 0s 220us/sample - loss: 5.0624e-05 - tanh_accuracy: 1.0000 - val_loss: 4.7373e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 582/1000\n",
            "250/250 [==============================] - 0s 217us/sample - loss: 5.0581e-05 - tanh_accuracy: 1.0000 - val_loss: 4.7331e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 583/1000\n",
            "250/250 [==============================] - 0s 208us/sample - loss: 5.0537e-05 - tanh_accuracy: 1.0000 - val_loss: 4.7290e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 584/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 5.0493e-05 - tanh_accuracy: 1.0000 - val_loss: 4.7249e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 585/1000\n",
            "250/250 [==============================] - 0s 221us/sample - loss: 5.0450e-05 - tanh_accuracy: 1.0000 - val_loss: 4.7208e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 586/1000\n",
            "250/250 [==============================] - 0s 236us/sample - loss: 5.0406e-05 - tanh_accuracy: 1.0000 - val_loss: 4.7167e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 587/1000\n",
            "250/250 [==============================] - 0s 221us/sample - loss: 5.0363e-05 - tanh_accuracy: 1.0000 - val_loss: 4.7125e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 588/1000\n",
            "250/250 [==============================] - 0s 220us/sample - loss: 5.0318e-05 - tanh_accuracy: 1.0000 - val_loss: 4.7084e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 589/1000\n",
            "250/250 [==============================] - 0s 223us/sample - loss: 5.0275e-05 - tanh_accuracy: 1.0000 - val_loss: 4.7044e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 590/1000\n",
            "250/250 [==============================] - 0s 227us/sample - loss: 5.0232e-05 - tanh_accuracy: 1.0000 - val_loss: 4.7003e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 591/1000\n",
            "250/250 [==============================] - 0s 233us/sample - loss: 5.0189e-05 - tanh_accuracy: 1.0000 - val_loss: 4.6962e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 592/1000\n",
            "250/250 [==============================] - 0s 228us/sample - loss: 5.0145e-05 - tanh_accuracy: 1.0000 - val_loss: 4.6921e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 593/1000\n",
            "250/250 [==============================] - 0s 245us/sample - loss: 5.0103e-05 - tanh_accuracy: 1.0000 - val_loss: 4.6881e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 594/1000\n",
            "250/250 [==============================] - 0s 243us/sample - loss: 5.0060e-05 - tanh_accuracy: 1.0000 - val_loss: 4.6839e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 595/1000\n",
            "250/250 [==============================] - 0s 273us/sample - loss: 5.0015e-05 - tanh_accuracy: 1.0000 - val_loss: 4.6799e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 596/1000\n",
            "250/250 [==============================] - 0s 250us/sample - loss: 4.9973e-05 - tanh_accuracy: 1.0000 - val_loss: 4.6759e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 597/1000\n",
            "250/250 [==============================] - 0s 230us/sample - loss: 4.9930e-05 - tanh_accuracy: 1.0000 - val_loss: 4.6718e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 598/1000\n",
            "250/250 [==============================] - 0s 209us/sample - loss: 4.9887e-05 - tanh_accuracy: 1.0000 - val_loss: 4.6677e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 599/1000\n",
            "250/250 [==============================] - 0s 229us/sample - loss: 4.9844e-05 - tanh_accuracy: 1.0000 - val_loss: 4.6637e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 600/1000\n",
            "250/250 [==============================] - 0s 232us/sample - loss: 4.9801e-05 - tanh_accuracy: 1.0000 - val_loss: 4.6597e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 601/1000\n",
            "250/250 [==============================] - 0s 232us/sample - loss: 4.9759e-05 - tanh_accuracy: 1.0000 - val_loss: 4.6557e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 602/1000\n",
            "250/250 [==============================] - 0s 203us/sample - loss: 4.9716e-05 - tanh_accuracy: 1.0000 - val_loss: 4.6517e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 603/1000\n",
            "250/250 [==============================] - 0s 201us/sample - loss: 4.9673e-05 - tanh_accuracy: 1.0000 - val_loss: 4.6477e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 604/1000\n",
            "250/250 [==============================] - 0s 247us/sample - loss: 4.9631e-05 - tanh_accuracy: 1.0000 - val_loss: 4.6437e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 605/1000\n",
            "250/250 [==============================] - 0s 232us/sample - loss: 4.9589e-05 - tanh_accuracy: 1.0000 - val_loss: 4.6397e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 606/1000\n",
            "250/250 [==============================] - 0s 232us/sample - loss: 4.9547e-05 - tanh_accuracy: 1.0000 - val_loss: 4.6357e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 607/1000\n",
            "250/250 [==============================] - 0s 204us/sample - loss: 4.9505e-05 - tanh_accuracy: 1.0000 - val_loss: 4.6317e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 608/1000\n",
            "250/250 [==============================] - 0s 198us/sample - loss: 4.9463e-05 - tanh_accuracy: 1.0000 - val_loss: 4.6278e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 609/1000\n",
            "250/250 [==============================] - 0s 203us/sample - loss: 4.9421e-05 - tanh_accuracy: 1.0000 - val_loss: 4.6238e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 610/1000\n",
            "250/250 [==============================] - 0s 218us/sample - loss: 4.9379e-05 - tanh_accuracy: 1.0000 - val_loss: 4.6199e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 611/1000\n",
            "250/250 [==============================] - 0s 267us/sample - loss: 4.9337e-05 - tanh_accuracy: 1.0000 - val_loss: 4.6160e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 612/1000\n",
            "250/250 [==============================] - 0s 208us/sample - loss: 4.9296e-05 - tanh_accuracy: 1.0000 - val_loss: 4.6120e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 613/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 4.9254e-05 - tanh_accuracy: 1.0000 - val_loss: 4.6081e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 614/1000\n",
            "250/250 [==============================] - 0s 222us/sample - loss: 4.9213e-05 - tanh_accuracy: 1.0000 - val_loss: 4.6042e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 615/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 4.9171e-05 - tanh_accuracy: 1.0000 - val_loss: 4.6003e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 616/1000\n",
            "250/250 [==============================] - 0s 211us/sample - loss: 4.9130e-05 - tanh_accuracy: 1.0000 - val_loss: 4.5964e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 617/1000\n",
            "250/250 [==============================] - 0s 211us/sample - loss: 4.9088e-05 - tanh_accuracy: 1.0000 - val_loss: 4.5925e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 618/1000\n",
            "250/250 [==============================] - 0s 222us/sample - loss: 4.9047e-05 - tanh_accuracy: 1.0000 - val_loss: 4.5886e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 619/1000\n",
            "250/250 [==============================] - 0s 209us/sample - loss: 4.9006e-05 - tanh_accuracy: 1.0000 - val_loss: 4.5847e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 620/1000\n",
            "250/250 [==============================] - 0s 240us/sample - loss: 4.8965e-05 - tanh_accuracy: 1.0000 - val_loss: 4.5808e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 621/1000\n",
            "250/250 [==============================] - 0s 210us/sample - loss: 4.8923e-05 - tanh_accuracy: 1.0000 - val_loss: 4.5769e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 622/1000\n",
            "250/250 [==============================] - 0s 217us/sample - loss: 4.8882e-05 - tanh_accuracy: 1.0000 - val_loss: 4.5730e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 623/1000\n",
            "250/250 [==============================] - 0s 205us/sample - loss: 4.8841e-05 - tanh_accuracy: 1.0000 - val_loss: 4.5691e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 624/1000\n",
            "250/250 [==============================] - 0s 212us/sample - loss: 4.8800e-05 - tanh_accuracy: 1.0000 - val_loss: 4.5653e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 625/1000\n",
            "250/250 [==============================] - 0s 211us/sample - loss: 4.8759e-05 - tanh_accuracy: 1.0000 - val_loss: 4.5614e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 626/1000\n",
            "250/250 [==============================] - 0s 206us/sample - loss: 4.8719e-05 - tanh_accuracy: 1.0000 - val_loss: 4.5576e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 627/1000\n",
            "250/250 [==============================] - 0s 227us/sample - loss: 4.8678e-05 - tanh_accuracy: 1.0000 - val_loss: 4.5537e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 628/1000\n",
            "250/250 [==============================] - 0s 237us/sample - loss: 4.8637e-05 - tanh_accuracy: 1.0000 - val_loss: 4.5499e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 629/1000\n",
            "250/250 [==============================] - 0s 213us/sample - loss: 4.8596e-05 - tanh_accuracy: 1.0000 - val_loss: 4.5461e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 630/1000\n",
            "250/250 [==============================] - 0s 210us/sample - loss: 4.8556e-05 - tanh_accuracy: 1.0000 - val_loss: 4.5422e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 631/1000\n",
            "250/250 [==============================] - 0s 206us/sample - loss: 4.8515e-05 - tanh_accuracy: 1.0000 - val_loss: 4.5384e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 632/1000\n",
            "250/250 [==============================] - 0s 219us/sample - loss: 4.8475e-05 - tanh_accuracy: 1.0000 - val_loss: 4.5346e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 633/1000\n",
            "250/250 [==============================] - 0s 220us/sample - loss: 4.8434e-05 - tanh_accuracy: 1.0000 - val_loss: 4.5307e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 634/1000\n",
            "250/250 [==============================] - 0s 213us/sample - loss: 4.8393e-05 - tanh_accuracy: 1.0000 - val_loss: 4.5269e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 635/1000\n",
            "250/250 [==============================] - 0s 211us/sample - loss: 4.8353e-05 - tanh_accuracy: 1.0000 - val_loss: 4.5231e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 636/1000\n",
            "250/250 [==============================] - 0s 209us/sample - loss: 4.8313e-05 - tanh_accuracy: 1.0000 - val_loss: 4.5194e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 637/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 4.8273e-05 - tanh_accuracy: 1.0000 - val_loss: 4.5156e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 638/1000\n",
            "250/250 [==============================] - 0s 210us/sample - loss: 4.8233e-05 - tanh_accuracy: 1.0000 - val_loss: 4.5118e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 639/1000\n",
            "250/250 [==============================] - 0s 223us/sample - loss: 4.8193e-05 - tanh_accuracy: 1.0000 - val_loss: 4.5080e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 640/1000\n",
            "250/250 [==============================] - 0s 223us/sample - loss: 4.8153e-05 - tanh_accuracy: 1.0000 - val_loss: 4.5043e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 641/1000\n",
            "250/250 [==============================] - 0s 207us/sample - loss: 4.8113e-05 - tanh_accuracy: 1.0000 - val_loss: 4.5005e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 642/1000\n",
            "250/250 [==============================] - 0s 208us/sample - loss: 4.8074e-05 - tanh_accuracy: 1.0000 - val_loss: 4.4968e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 643/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 4.8034e-05 - tanh_accuracy: 1.0000 - val_loss: 4.4930e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 644/1000\n",
            "250/250 [==============================] - 0s 229us/sample - loss: 4.7994e-05 - tanh_accuracy: 1.0000 - val_loss: 4.4893e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 645/1000\n",
            "250/250 [==============================] - 0s 205us/sample - loss: 4.7955e-05 - tanh_accuracy: 1.0000 - val_loss: 4.4856e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 646/1000\n",
            "250/250 [==============================] - 0s 217us/sample - loss: 4.7915e-05 - tanh_accuracy: 1.0000 - val_loss: 4.4819e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 647/1000\n",
            "250/250 [==============================] - 0s 218us/sample - loss: 4.7876e-05 - tanh_accuracy: 1.0000 - val_loss: 4.4781e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 648/1000\n",
            "250/250 [==============================] - 0s 210us/sample - loss: 4.7836e-05 - tanh_accuracy: 1.0000 - val_loss: 4.4744e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 649/1000\n",
            "250/250 [==============================] - 0s 214us/sample - loss: 4.7797e-05 - tanh_accuracy: 1.0000 - val_loss: 4.4707e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 650/1000\n",
            "250/250 [==============================] - 0s 230us/sample - loss: 4.7758e-05 - tanh_accuracy: 1.0000 - val_loss: 4.4670e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 651/1000\n",
            "250/250 [==============================] - 0s 268us/sample - loss: 4.7719e-05 - tanh_accuracy: 1.0000 - val_loss: 4.4634e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 652/1000\n",
            "250/250 [==============================] - 0s 227us/sample - loss: 4.7680e-05 - tanh_accuracy: 1.0000 - val_loss: 4.4597e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 653/1000\n",
            "250/250 [==============================] - 0s 217us/sample - loss: 4.7641e-05 - tanh_accuracy: 1.0000 - val_loss: 4.4560e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 654/1000\n",
            "250/250 [==============================] - 0s 229us/sample - loss: 4.7602e-05 - tanh_accuracy: 1.0000 - val_loss: 4.4523e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 655/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 4.7563e-05 - tanh_accuracy: 1.0000 - val_loss: 4.4487e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 656/1000\n",
            "250/250 [==============================] - 0s 214us/sample - loss: 4.7524e-05 - tanh_accuracy: 1.0000 - val_loss: 4.4450e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 657/1000\n",
            "250/250 [==============================] - 0s 229us/sample - loss: 4.7486e-05 - tanh_accuracy: 1.0000 - val_loss: 4.4414e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 658/1000\n",
            "250/250 [==============================] - 0s 220us/sample - loss: 4.7447e-05 - tanh_accuracy: 1.0000 - val_loss: 4.4377e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 659/1000\n",
            "250/250 [==============================] - 0s 229us/sample - loss: 4.7408e-05 - tanh_accuracy: 1.0000 - val_loss: 4.4341e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 660/1000\n",
            "250/250 [==============================] - 0s 287us/sample - loss: 4.7370e-05 - tanh_accuracy: 1.0000 - val_loss: 4.4304e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 661/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 4.7331e-05 - tanh_accuracy: 1.0000 - val_loss: 4.4268e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 662/1000\n",
            "250/250 [==============================] - 0s 211us/sample - loss: 4.7293e-05 - tanh_accuracy: 1.0000 - val_loss: 4.4232e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 663/1000\n",
            "250/250 [==============================] - 0s 211us/sample - loss: 4.7255e-05 - tanh_accuracy: 1.0000 - val_loss: 4.4196e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 664/1000\n",
            "250/250 [==============================] - 0s 211us/sample - loss: 4.7217e-05 - tanh_accuracy: 1.0000 - val_loss: 4.4159e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 665/1000\n",
            "250/250 [==============================] - 0s 226us/sample - loss: 4.7178e-05 - tanh_accuracy: 1.0000 - val_loss: 4.4123e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 666/1000\n",
            "250/250 [==============================] - 0s 219us/sample - loss: 4.7140e-05 - tanh_accuracy: 1.0000 - val_loss: 4.4087e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 667/1000\n",
            "250/250 [==============================] - 0s 200us/sample - loss: 4.7102e-05 - tanh_accuracy: 1.0000 - val_loss: 4.4051e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 668/1000\n",
            "250/250 [==============================] - 0s 204us/sample - loss: 4.7064e-05 - tanh_accuracy: 1.0000 - val_loss: 4.4015e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 669/1000\n",
            "250/250 [==============================] - 0s 218us/sample - loss: 4.7026e-05 - tanh_accuracy: 1.0000 - val_loss: 4.3980e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 670/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 4.6988e-05 - tanh_accuracy: 1.0000 - val_loss: 4.3944e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 671/1000\n",
            "250/250 [==============================] - 0s 220us/sample - loss: 4.6950e-05 - tanh_accuracy: 1.0000 - val_loss: 4.3908e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 672/1000\n",
            "250/250 [==============================] - 0s 238us/sample - loss: 4.6912e-05 - tanh_accuracy: 1.0000 - val_loss: 4.3872e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 673/1000\n",
            "250/250 [==============================] - 0s 227us/sample - loss: 4.6874e-05 - tanh_accuracy: 1.0000 - val_loss: 4.3837e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 674/1000\n",
            "250/250 [==============================] - 0s 212us/sample - loss: 4.6836e-05 - tanh_accuracy: 1.0000 - val_loss: 4.3801e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 675/1000\n",
            "250/250 [==============================] - 0s 222us/sample - loss: 4.6798e-05 - tanh_accuracy: 1.0000 - val_loss: 4.3765e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 676/1000\n",
            "250/250 [==============================] - 0s 222us/sample - loss: 4.6761e-05 - tanh_accuracy: 1.0000 - val_loss: 4.3730e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 677/1000\n",
            "250/250 [==============================] - 0s 233us/sample - loss: 4.6723e-05 - tanh_accuracy: 1.0000 - val_loss: 4.3694e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 678/1000\n",
            "250/250 [==============================] - 0s 232us/sample - loss: 4.6686e-05 - tanh_accuracy: 1.0000 - val_loss: 4.3659e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 679/1000\n",
            "250/250 [==============================] - 0s 218us/sample - loss: 4.6648e-05 - tanh_accuracy: 1.0000 - val_loss: 4.3624e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 680/1000\n",
            "250/250 [==============================] - 0s 238us/sample - loss: 4.6611e-05 - tanh_accuracy: 1.0000 - val_loss: 4.3589e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 681/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 4.6574e-05 - tanh_accuracy: 1.0000 - val_loss: 4.3553e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 682/1000\n",
            "250/250 [==============================] - 0s 222us/sample - loss: 4.6536e-05 - tanh_accuracy: 1.0000 - val_loss: 4.3518e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 683/1000\n",
            "250/250 [==============================] - 0s 221us/sample - loss: 4.6499e-05 - tanh_accuracy: 1.0000 - val_loss: 4.3483e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 684/1000\n",
            "250/250 [==============================] - 0s 238us/sample - loss: 4.6462e-05 - tanh_accuracy: 1.0000 - val_loss: 4.3448e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 685/1000\n",
            "250/250 [==============================] - 0s 242us/sample - loss: 4.6425e-05 - tanh_accuracy: 1.0000 - val_loss: 4.3413e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 686/1000\n",
            "250/250 [==============================] - 0s 232us/sample - loss: 4.6388e-05 - tanh_accuracy: 1.0000 - val_loss: 4.3379e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 687/1000\n",
            "250/250 [==============================] - 0s 241us/sample - loss: 4.6351e-05 - tanh_accuracy: 1.0000 - val_loss: 4.3344e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 688/1000\n",
            "250/250 [==============================] - 0s 223us/sample - loss: 4.6314e-05 - tanh_accuracy: 1.0000 - val_loss: 4.3309e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 689/1000\n",
            "250/250 [==============================] - 0s 223us/sample - loss: 4.6277e-05 - tanh_accuracy: 1.0000 - val_loss: 4.3274e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 690/1000\n",
            "250/250 [==============================] - 0s 219us/sample - loss: 4.6241e-05 - tanh_accuracy: 1.0000 - val_loss: 4.3239e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 691/1000\n",
            "250/250 [==============================] - 0s 230us/sample - loss: 4.6204e-05 - tanh_accuracy: 1.0000 - val_loss: 4.3205e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 692/1000\n",
            "250/250 [==============================] - 0s 217us/sample - loss: 4.6167e-05 - tanh_accuracy: 1.0000 - val_loss: 4.3170e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 693/1000\n",
            "250/250 [==============================] - 0s 218us/sample - loss: 4.6130e-05 - tanh_accuracy: 1.0000 - val_loss: 4.3136e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 694/1000\n",
            "250/250 [==============================] - 0s 228us/sample - loss: 4.6094e-05 - tanh_accuracy: 1.0000 - val_loss: 4.3101e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 695/1000\n",
            "250/250 [==============================] - 0s 235us/sample - loss: 4.6057e-05 - tanh_accuracy: 1.0000 - val_loss: 4.3067e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 696/1000\n",
            "250/250 [==============================] - 0s 242us/sample - loss: 4.6021e-05 - tanh_accuracy: 1.0000 - val_loss: 4.3032e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 697/1000\n",
            "250/250 [==============================] - 0s 226us/sample - loss: 4.5985e-05 - tanh_accuracy: 1.0000 - val_loss: 4.2998e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 698/1000\n",
            "250/250 [==============================] - 0s 214us/sample - loss: 4.5948e-05 - tanh_accuracy: 1.0000 - val_loss: 4.2964e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 699/1000\n",
            "250/250 [==============================] - 0s 218us/sample - loss: 4.5912e-05 - tanh_accuracy: 1.0000 - val_loss: 4.2930e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 700/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 4.5876e-05 - tanh_accuracy: 1.0000 - val_loss: 4.2896e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 701/1000\n",
            "250/250 [==============================] - 0s 218us/sample - loss: 4.5840e-05 - tanh_accuracy: 1.0000 - val_loss: 4.2861e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 702/1000\n",
            "250/250 [==============================] - 0s 229us/sample - loss: 4.5804e-05 - tanh_accuracy: 1.0000 - val_loss: 4.2827e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 703/1000\n",
            "250/250 [==============================] - 0s 223us/sample - loss: 4.5767e-05 - tanh_accuracy: 1.0000 - val_loss: 4.2793e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 704/1000\n",
            "250/250 [==============================] - 0s 230us/sample - loss: 4.5731e-05 - tanh_accuracy: 1.0000 - val_loss: 4.2759e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 705/1000\n",
            "250/250 [==============================] - 0s 223us/sample - loss: 4.5695e-05 - tanh_accuracy: 1.0000 - val_loss: 4.2725e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 706/1000\n",
            "250/250 [==============================] - 0s 226us/sample - loss: 4.5659e-05 - tanh_accuracy: 1.0000 - val_loss: 4.2692e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 707/1000\n",
            "250/250 [==============================] - 0s 225us/sample - loss: 4.5624e-05 - tanh_accuracy: 1.0000 - val_loss: 4.2658e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 708/1000\n",
            "250/250 [==============================] - 0s 220us/sample - loss: 4.5588e-05 - tanh_accuracy: 1.0000 - val_loss: 4.2624e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 709/1000\n",
            "250/250 [==============================] - 0s 230us/sample - loss: 4.5552e-05 - tanh_accuracy: 1.0000 - val_loss: 4.2590e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 710/1000\n",
            "250/250 [==============================] - 0s 231us/sample - loss: 4.5516e-05 - tanh_accuracy: 1.0000 - val_loss: 4.2557e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 711/1000\n",
            "250/250 [==============================] - 0s 235us/sample - loss: 4.5481e-05 - tanh_accuracy: 1.0000 - val_loss: 4.2523e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 712/1000\n",
            "250/250 [==============================] - 0s 234us/sample - loss: 4.5445e-05 - tanh_accuracy: 1.0000 - val_loss: 4.2490e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 713/1000\n",
            "250/250 [==============================] - 0s 235us/sample - loss: 4.5410e-05 - tanh_accuracy: 1.0000 - val_loss: 4.2456e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 714/1000\n",
            "250/250 [==============================] - 0s 236us/sample - loss: 4.5374e-05 - tanh_accuracy: 1.0000 - val_loss: 4.2422e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 715/1000\n",
            "250/250 [==============================] - 0s 217us/sample - loss: 4.5339e-05 - tanh_accuracy: 1.0000 - val_loss: 4.2389e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 716/1000\n",
            "250/250 [==============================] - 0s 211us/sample - loss: 4.5303e-05 - tanh_accuracy: 1.0000 - val_loss: 4.2355e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 717/1000\n",
            "250/250 [==============================] - 0s 227us/sample - loss: 4.5268e-05 - tanh_accuracy: 1.0000 - val_loss: 4.2322e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 718/1000\n",
            "250/250 [==============================] - 0s 239us/sample - loss: 4.5232e-05 - tanh_accuracy: 1.0000 - val_loss: 4.2289e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 719/1000\n",
            "250/250 [==============================] - 0s 229us/sample - loss: 4.5197e-05 - tanh_accuracy: 1.0000 - val_loss: 4.2255e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 720/1000\n",
            "250/250 [==============================] - 0s 246us/sample - loss: 4.5162e-05 - tanh_accuracy: 1.0000 - val_loss: 4.2222e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 721/1000\n",
            "250/250 [==============================] - 0s 228us/sample - loss: 4.5126e-05 - tanh_accuracy: 1.0000 - val_loss: 4.2189e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 722/1000\n",
            "250/250 [==============================] - 0s 221us/sample - loss: 4.5092e-05 - tanh_accuracy: 1.0000 - val_loss: 4.2156e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 723/1000\n",
            "250/250 [==============================] - 0s 233us/sample - loss: 4.5057e-05 - tanh_accuracy: 1.0000 - val_loss: 4.2123e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 724/1000\n",
            "250/250 [==============================] - 0s 223us/sample - loss: 4.5022e-05 - tanh_accuracy: 1.0000 - val_loss: 4.2090e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 725/1000\n",
            "250/250 [==============================] - 0s 234us/sample - loss: 4.4987e-05 - tanh_accuracy: 1.0000 - val_loss: 4.2058e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 726/1000\n",
            "250/250 [==============================] - 0s 217us/sample - loss: 4.4952e-05 - tanh_accuracy: 1.0000 - val_loss: 4.2025e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 727/1000\n",
            "250/250 [==============================] - 0s 227us/sample - loss: 4.4917e-05 - tanh_accuracy: 1.0000 - val_loss: 4.1992e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 728/1000\n",
            "250/250 [==============================] - 0s 257us/sample - loss: 4.4883e-05 - tanh_accuracy: 1.0000 - val_loss: 4.1959e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 729/1000\n",
            "250/250 [==============================] - 0s 233us/sample - loss: 4.4848e-05 - tanh_accuracy: 1.0000 - val_loss: 4.1926e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 730/1000\n",
            "250/250 [==============================] - 0s 230us/sample - loss: 4.4813e-05 - tanh_accuracy: 1.0000 - val_loss: 4.1893e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 731/1000\n",
            "250/250 [==============================] - 0s 228us/sample - loss: 4.4778e-05 - tanh_accuracy: 1.0000 - val_loss: 4.1861e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 732/1000\n",
            "250/250 [==============================] - 0s 227us/sample - loss: 4.4743e-05 - tanh_accuracy: 1.0000 - val_loss: 4.1828e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 733/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 4.4709e-05 - tanh_accuracy: 1.0000 - val_loss: 4.1796e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 734/1000\n",
            "250/250 [==============================] - 0s 226us/sample - loss: 4.4674e-05 - tanh_accuracy: 1.0000 - val_loss: 4.1763e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 735/1000\n",
            "250/250 [==============================] - 0s 252us/sample - loss: 4.4640e-05 - tanh_accuracy: 1.0000 - val_loss: 4.1731e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 736/1000\n",
            "250/250 [==============================] - 0s 227us/sample - loss: 4.4605e-05 - tanh_accuracy: 1.0000 - val_loss: 4.1698e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 737/1000\n",
            "250/250 [==============================] - 0s 223us/sample - loss: 4.4571e-05 - tanh_accuracy: 1.0000 - val_loss: 4.1666e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 738/1000\n",
            "250/250 [==============================] - 0s 228us/sample - loss: 4.4537e-05 - tanh_accuracy: 1.0000 - val_loss: 4.1634e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 739/1000\n",
            "250/250 [==============================] - 0s 206us/sample - loss: 4.4503e-05 - tanh_accuracy: 1.0000 - val_loss: 4.1601e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 740/1000\n",
            "250/250 [==============================] - 0s 226us/sample - loss: 4.4468e-05 - tanh_accuracy: 1.0000 - val_loss: 4.1569e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 741/1000\n",
            "250/250 [==============================] - 0s 225us/sample - loss: 4.4434e-05 - tanh_accuracy: 1.0000 - val_loss: 4.1537e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 742/1000\n",
            "250/250 [==============================] - 0s 209us/sample - loss: 4.4400e-05 - tanh_accuracy: 1.0000 - val_loss: 4.1505e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 743/1000\n",
            "250/250 [==============================] - 0s 224us/sample - loss: 4.4366e-05 - tanh_accuracy: 1.0000 - val_loss: 4.1473e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 744/1000\n",
            "250/250 [==============================] - 0s 219us/sample - loss: 4.4332e-05 - tanh_accuracy: 1.0000 - val_loss: 4.1441e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 745/1000\n",
            "250/250 [==============================] - 0s 226us/sample - loss: 4.4299e-05 - tanh_accuracy: 1.0000 - val_loss: 4.1409e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 746/1000\n",
            "250/250 [==============================] - 0s 228us/sample - loss: 4.4265e-05 - tanh_accuracy: 1.0000 - val_loss: 4.1377e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 747/1000\n",
            "250/250 [==============================] - 0s 234us/sample - loss: 4.4231e-05 - tanh_accuracy: 1.0000 - val_loss: 4.1346e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 748/1000\n",
            "250/250 [==============================] - 0s 240us/sample - loss: 4.4198e-05 - tanh_accuracy: 1.0000 - val_loss: 4.1314e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 749/1000\n",
            "250/250 [==============================] - 0s 231us/sample - loss: 4.4164e-05 - tanh_accuracy: 1.0000 - val_loss: 4.1282e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 750/1000\n",
            "250/250 [==============================] - 0s 218us/sample - loss: 4.4130e-05 - tanh_accuracy: 1.0000 - val_loss: 4.1250e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 751/1000\n",
            "250/250 [==============================] - 0s 212us/sample - loss: 4.4097e-05 - tanh_accuracy: 1.0000 - val_loss: 4.1219e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 752/1000\n",
            "250/250 [==============================] - 0s 222us/sample - loss: 4.4063e-05 - tanh_accuracy: 1.0000 - val_loss: 4.1187e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 753/1000\n",
            "250/250 [==============================] - 0s 212us/sample - loss: 4.4030e-05 - tanh_accuracy: 1.0000 - val_loss: 4.1155e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 754/1000\n",
            "250/250 [==============================] - 0s 207us/sample - loss: 4.3996e-05 - tanh_accuracy: 1.0000 - val_loss: 4.1124e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 755/1000\n",
            "250/250 [==============================] - 0s 214us/sample - loss: 4.3963e-05 - tanh_accuracy: 1.0000 - val_loss: 4.1093e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 756/1000\n",
            "250/250 [==============================] - 0s 231us/sample - loss: 4.3930e-05 - tanh_accuracy: 1.0000 - val_loss: 4.1061e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 757/1000\n",
            "250/250 [==============================] - 0s 218us/sample - loss: 4.3897e-05 - tanh_accuracy: 1.0000 - val_loss: 4.1030e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 758/1000\n",
            "250/250 [==============================] - 0s 209us/sample - loss: 4.3863e-05 - tanh_accuracy: 1.0000 - val_loss: 4.0999e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 759/1000\n",
            "250/250 [==============================] - 0s 220us/sample - loss: 4.3830e-05 - tanh_accuracy: 1.0000 - val_loss: 4.0968e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 760/1000\n",
            "250/250 [==============================] - 0s 222us/sample - loss: 4.3797e-05 - tanh_accuracy: 1.0000 - val_loss: 4.0936e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 761/1000\n",
            "250/250 [==============================] - 0s 239us/sample - loss: 4.3764e-05 - tanh_accuracy: 1.0000 - val_loss: 4.0905e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 762/1000\n",
            "250/250 [==============================] - 0s 222us/sample - loss: 4.3731e-05 - tanh_accuracy: 1.0000 - val_loss: 4.0874e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 763/1000\n",
            "250/250 [==============================] - 0s 242us/sample - loss: 4.3698e-05 - tanh_accuracy: 1.0000 - val_loss: 4.0843e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 764/1000\n",
            "250/250 [==============================] - 0s 242us/sample - loss: 4.3665e-05 - tanh_accuracy: 1.0000 - val_loss: 4.0811e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 765/1000\n",
            "250/250 [==============================] - 0s 238us/sample - loss: 4.3632e-05 - tanh_accuracy: 1.0000 - val_loss: 4.0780e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 766/1000\n",
            "250/250 [==============================] - 0s 230us/sample - loss: 4.3599e-05 - tanh_accuracy: 1.0000 - val_loss: 4.0750e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 767/1000\n",
            "250/250 [==============================] - 0s 263us/sample - loss: 4.3566e-05 - tanh_accuracy: 1.0000 - val_loss: 4.0719e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 768/1000\n",
            "250/250 [==============================] - 0s 239us/sample - loss: 4.3533e-05 - tanh_accuracy: 1.0000 - val_loss: 4.0688e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 769/1000\n",
            "250/250 [==============================] - 0s 261us/sample - loss: 4.3501e-05 - tanh_accuracy: 1.0000 - val_loss: 4.0657e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 770/1000\n",
            "250/250 [==============================] - 0s 243us/sample - loss: 4.3468e-05 - tanh_accuracy: 1.0000 - val_loss: 4.0627e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 771/1000\n",
            "250/250 [==============================] - 0s 220us/sample - loss: 4.3436e-05 - tanh_accuracy: 1.0000 - val_loss: 4.0596e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 772/1000\n",
            "250/250 [==============================] - 0s 228us/sample - loss: 4.3403e-05 - tanh_accuracy: 1.0000 - val_loss: 4.0565e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 773/1000\n",
            "250/250 [==============================] - 0s 229us/sample - loss: 4.3371e-05 - tanh_accuracy: 1.0000 - val_loss: 4.0535e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 774/1000\n",
            "250/250 [==============================] - 0s 230us/sample - loss: 4.3338e-05 - tanh_accuracy: 1.0000 - val_loss: 4.0504e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 775/1000\n",
            "250/250 [==============================] - 0s 214us/sample - loss: 4.3306e-05 - tanh_accuracy: 1.0000 - val_loss: 4.0473e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 776/1000\n",
            "250/250 [==============================] - 0s 219us/sample - loss: 4.3274e-05 - tanh_accuracy: 1.0000 - val_loss: 4.0443e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 777/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 4.3241e-05 - tanh_accuracy: 1.0000 - val_loss: 4.0412e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 778/1000\n",
            "250/250 [==============================] - 0s 232us/sample - loss: 4.3209e-05 - tanh_accuracy: 1.0000 - val_loss: 4.0382e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 779/1000\n",
            "250/250 [==============================] - 0s 271us/sample - loss: 4.3177e-05 - tanh_accuracy: 1.0000 - val_loss: 4.0352e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 780/1000\n",
            "250/250 [==============================] - 0s 276us/sample - loss: 4.3145e-05 - tanh_accuracy: 1.0000 - val_loss: 4.0322e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 781/1000\n",
            "250/250 [==============================] - 0s 238us/sample - loss: 4.3113e-05 - tanh_accuracy: 1.0000 - val_loss: 4.0291e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 782/1000\n",
            "250/250 [==============================] - 0s 236us/sample - loss: 4.3081e-05 - tanh_accuracy: 1.0000 - val_loss: 4.0261e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 783/1000\n",
            "250/250 [==============================] - 0s 233us/sample - loss: 4.3049e-05 - tanh_accuracy: 1.0000 - val_loss: 4.0231e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 784/1000\n",
            "250/250 [==============================] - 0s 225us/sample - loss: 4.3016e-05 - tanh_accuracy: 1.0000 - val_loss: 4.0200e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 785/1000\n",
            "250/250 [==============================] - 0s 219us/sample - loss: 4.2984e-05 - tanh_accuracy: 1.0000 - val_loss: 4.0170e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 786/1000\n",
            "250/250 [==============================] - 0s 214us/sample - loss: 4.2952e-05 - tanh_accuracy: 1.0000 - val_loss: 4.0140e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 787/1000\n",
            "250/250 [==============================] - 0s 235us/sample - loss: 4.2921e-05 - tanh_accuracy: 1.0000 - val_loss: 4.0110e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 788/1000\n",
            "250/250 [==============================] - 0s 208us/sample - loss: 4.2889e-05 - tanh_accuracy: 1.0000 - val_loss: 4.0080e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 789/1000\n",
            "250/250 [==============================] - 0s 210us/sample - loss: 4.2857e-05 - tanh_accuracy: 1.0000 - val_loss: 4.0050e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 790/1000\n",
            "250/250 [==============================] - 0s 202us/sample - loss: 4.2825e-05 - tanh_accuracy: 1.0000 - val_loss: 4.0020e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 791/1000\n",
            "250/250 [==============================] - 0s 238us/sample - loss: 4.2793e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9990e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 792/1000\n",
            "250/250 [==============================] - 0s 218us/sample - loss: 4.2761e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9960e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 793/1000\n",
            "250/250 [==============================] - 0s 201us/sample - loss: 4.2729e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9930e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 794/1000\n",
            "250/250 [==============================] - 0s 223us/sample - loss: 4.2698e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9900e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 795/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 4.2666e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9871e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 796/1000\n",
            "250/250 [==============================] - 0s 241us/sample - loss: 4.2635e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9841e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 797/1000\n",
            "250/250 [==============================] - 0s 234us/sample - loss: 4.2603e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9812e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 798/1000\n",
            "250/250 [==============================] - 0s 208us/sample - loss: 4.2572e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9782e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 799/1000\n",
            "250/250 [==============================] - 0s 217us/sample - loss: 4.2541e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9753e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 800/1000\n",
            "250/250 [==============================] - 0s 230us/sample - loss: 4.2509e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9723e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 801/1000\n",
            "250/250 [==============================] - 0s 234us/sample - loss: 4.2478e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9694e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 802/1000\n",
            "250/250 [==============================] - 0s 230us/sample - loss: 4.2447e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9664e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 803/1000\n",
            "250/250 [==============================] - 0s 230us/sample - loss: 4.2416e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9635e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 804/1000\n",
            "250/250 [==============================] - 0s 243us/sample - loss: 4.2385e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9606e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 805/1000\n",
            "250/250 [==============================] - 0s 227us/sample - loss: 4.2354e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9576e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 806/1000\n",
            "250/250 [==============================] - 0s 224us/sample - loss: 4.2323e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9547e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 807/1000\n",
            "250/250 [==============================] - 0s 212us/sample - loss: 4.2292e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9518e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 808/1000\n",
            "250/250 [==============================] - 0s 208us/sample - loss: 4.2261e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9489e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 809/1000\n",
            "250/250 [==============================] - 0s 233us/sample - loss: 4.2230e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9460e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 810/1000\n",
            "250/250 [==============================] - 0s 236us/sample - loss: 4.2199e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9431e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 811/1000\n",
            "250/250 [==============================] - 0s 212us/sample - loss: 4.2168e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9402e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 812/1000\n",
            "250/250 [==============================] - 0s 230us/sample - loss: 4.2138e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9373e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 813/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 4.2107e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9344e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 814/1000\n",
            "250/250 [==============================] - 0s 235us/sample - loss: 4.2076e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9315e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 815/1000\n",
            "250/250 [==============================] - 0s 240us/sample - loss: 4.2046e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9286e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 816/1000\n",
            "250/250 [==============================] - 0s 230us/sample - loss: 4.2015e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9257e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 817/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 4.1984e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9228e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 818/1000\n",
            "250/250 [==============================] - 0s 273us/sample - loss: 4.1953e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9199e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 819/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 4.1923e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9171e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 820/1000\n",
            "250/250 [==============================] - 0s 246us/sample - loss: 4.1892e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9142e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 821/1000\n",
            "250/250 [==============================] - 0s 234us/sample - loss: 4.1862e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9113e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 822/1000\n",
            "250/250 [==============================] - 0s 221us/sample - loss: 4.1832e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9085e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 823/1000\n",
            "250/250 [==============================] - 0s 220us/sample - loss: 4.1802e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9056e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 824/1000\n",
            "250/250 [==============================] - 0s 217us/sample - loss: 4.1771e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9028e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 825/1000\n",
            "250/250 [==============================] - 0s 209us/sample - loss: 4.1741e-05 - tanh_accuracy: 1.0000 - val_loss: 3.9000e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 826/1000\n",
            "250/250 [==============================] - 0s 233us/sample - loss: 4.1711e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8971e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 827/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 4.1681e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8943e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 828/1000\n",
            "250/250 [==============================] - 0s 217us/sample - loss: 4.1651e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8914e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 829/1000\n",
            "250/250 [==============================] - 0s 242us/sample - loss: 4.1621e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8886e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 830/1000\n",
            "250/250 [==============================] - 0s 248us/sample - loss: 4.1591e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8858e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 831/1000\n",
            "250/250 [==============================] - 0s 225us/sample - loss: 4.1561e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8830e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 832/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 4.1531e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8801e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 833/1000\n",
            "250/250 [==============================] - 0s 261us/sample - loss: 4.1501e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8773e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 834/1000\n",
            "250/250 [==============================] - 0s 228us/sample - loss: 4.1471e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8745e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 835/1000\n",
            "250/250 [==============================] - 0s 228us/sample - loss: 4.1442e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8717e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 836/1000\n",
            "250/250 [==============================] - 0s 218us/sample - loss: 4.1412e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8689e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 837/1000\n",
            "250/250 [==============================] - 0s 236us/sample - loss: 4.1382e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8661e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 838/1000\n",
            "250/250 [==============================] - 0s 229us/sample - loss: 4.1353e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8633e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 839/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 4.1323e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8605e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 840/1000\n",
            "250/250 [==============================] - 0s 214us/sample - loss: 4.1294e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8578e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 841/1000\n",
            "250/250 [==============================] - 0s 226us/sample - loss: 4.1264e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8550e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 842/1000\n",
            "250/250 [==============================] - 0s 266us/sample - loss: 4.1235e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8522e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 843/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 4.1205e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8494e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 844/1000\n",
            "250/250 [==============================] - 0s 229us/sample - loss: 4.1175e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8466e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 845/1000\n",
            "250/250 [==============================] - 0s 230us/sample - loss: 4.1146e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8438e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 846/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 4.1116e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8411e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 847/1000\n",
            "250/250 [==============================] - 0s 222us/sample - loss: 4.1087e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8383e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 848/1000\n",
            "250/250 [==============================] - 0s 280us/sample - loss: 4.1058e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8355e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 849/1000\n",
            "250/250 [==============================] - 0s 255us/sample - loss: 4.1029e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8328e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 850/1000\n",
            "250/250 [==============================] - 0s 282us/sample - loss: 4.0999e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8300e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 851/1000\n",
            "250/250 [==============================] - 0s 230us/sample - loss: 4.0970e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8273e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 852/1000\n",
            "250/250 [==============================] - 0s 274us/sample - loss: 4.0941e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8246e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 853/1000\n",
            "250/250 [==============================] - 0s 270us/sample - loss: 4.0912e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8218e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 854/1000\n",
            "250/250 [==============================] - 0s 251us/sample - loss: 4.0883e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8191e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 855/1000\n",
            "250/250 [==============================] - 0s 245us/sample - loss: 4.0854e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8163e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 856/1000\n",
            "250/250 [==============================] - 0s 243us/sample - loss: 4.0825e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8136e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 857/1000\n",
            "250/250 [==============================] - 0s 224us/sample - loss: 4.0796e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8109e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 858/1000\n",
            "250/250 [==============================] - 0s 218us/sample - loss: 4.0767e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8082e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 859/1000\n",
            "250/250 [==============================] - 0s 250us/sample - loss: 4.0738e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8055e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 860/1000\n",
            "250/250 [==============================] - 0s 221us/sample - loss: 4.0710e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8028e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 861/1000\n",
            "250/250 [==============================] - 0s 230us/sample - loss: 4.0681e-05 - tanh_accuracy: 1.0000 - val_loss: 3.8001e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 862/1000\n",
            "250/250 [==============================] - 0s 213us/sample - loss: 4.0652e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7974e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 863/1000\n",
            "250/250 [==============================] - 0s 212us/sample - loss: 4.0624e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7947e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 864/1000\n",
            "250/250 [==============================] - 0s 240us/sample - loss: 4.0595e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7920e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 865/1000\n",
            "250/250 [==============================] - 0s 234us/sample - loss: 4.0566e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7893e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 866/1000\n",
            "250/250 [==============================] - 0s 217us/sample - loss: 4.0538e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7866e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 867/1000\n",
            "250/250 [==============================] - 0s 221us/sample - loss: 4.0509e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7839e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 868/1000\n",
            "250/250 [==============================] - 0s 245us/sample - loss: 4.0481e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7812e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 869/1000\n",
            "250/250 [==============================] - 0s 241us/sample - loss: 4.0452e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7785e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 870/1000\n",
            "250/250 [==============================] - 0s 228us/sample - loss: 4.0424e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7759e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 871/1000\n",
            "250/250 [==============================] - 0s 233us/sample - loss: 4.0396e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7732e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 872/1000\n",
            "250/250 [==============================] - 0s 232us/sample - loss: 4.0367e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7705e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 873/1000\n",
            "250/250 [==============================] - 0s 235us/sample - loss: 4.0339e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7679e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 874/1000\n",
            "250/250 [==============================] - 0s 226us/sample - loss: 4.0311e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7652e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 875/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 4.0283e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7625e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 876/1000\n",
            "250/250 [==============================] - 0s 241us/sample - loss: 4.0254e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7599e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 877/1000\n",
            "250/250 [==============================] - 0s 214us/sample - loss: 4.0226e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7572e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 878/1000\n",
            "250/250 [==============================] - 0s 221us/sample - loss: 4.0198e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7546e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 879/1000\n",
            "250/250 [==============================] - 0s 219us/sample - loss: 4.0170e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7519e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 880/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 4.0142e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7493e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 881/1000\n",
            "250/250 [==============================] - 0s 233us/sample - loss: 4.0114e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7467e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 882/1000\n",
            "250/250 [==============================] - 0s 230us/sample - loss: 4.0086e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7441e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 883/1000\n",
            "250/250 [==============================] - 0s 248us/sample - loss: 4.0059e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7414e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 884/1000\n",
            "250/250 [==============================] - 0s 254us/sample - loss: 4.0031e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7388e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 885/1000\n",
            "250/250 [==============================] - 0s 232us/sample - loss: 4.0003e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7362e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 886/1000\n",
            "250/250 [==============================] - 0s 222us/sample - loss: 3.9975e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7336e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 887/1000\n",
            "250/250 [==============================] - 0s 228us/sample - loss: 3.9948e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7310e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 888/1000\n",
            "250/250 [==============================] - 0s 228us/sample - loss: 3.9920e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7284e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 889/1000\n",
            "250/250 [==============================] - 0s 221us/sample - loss: 3.9893e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7258e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 890/1000\n",
            "250/250 [==============================] - 0s 223us/sample - loss: 3.9865e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7232e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 891/1000\n",
            "250/250 [==============================] - 0s 233us/sample - loss: 3.9838e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7206e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 892/1000\n",
            "250/250 [==============================] - 0s 225us/sample - loss: 3.9810e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7180e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 893/1000\n",
            "250/250 [==============================] - 0s 222us/sample - loss: 3.9782e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7154e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 894/1000\n",
            "250/250 [==============================] - 0s 221us/sample - loss: 3.9755e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7128e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 895/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 3.9728e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7103e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 896/1000\n",
            "250/250 [==============================] - 0s 223us/sample - loss: 3.9700e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7077e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 897/1000\n",
            "250/250 [==============================] - 0s 223us/sample - loss: 3.9673e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7051e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 898/1000\n",
            "250/250 [==============================] - 0s 256us/sample - loss: 3.9645e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7025e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 899/1000\n",
            "250/250 [==============================] - 0s 250us/sample - loss: 3.9618e-05 - tanh_accuracy: 1.0000 - val_loss: 3.7000e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 900/1000\n",
            "250/250 [==============================] - 0s 254us/sample - loss: 3.9591e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6974e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 901/1000\n",
            "250/250 [==============================] - 0s 283us/sample - loss: 3.9564e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6948e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 902/1000\n",
            "250/250 [==============================] - 0s 251us/sample - loss: 3.9537e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6922e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 903/1000\n",
            "250/250 [==============================] - 0s 222us/sample - loss: 3.9509e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6896e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 904/1000\n",
            "250/250 [==============================] - 0s 222us/sample - loss: 3.9482e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6871e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 905/1000\n",
            "250/250 [==============================] - 0s 213us/sample - loss: 3.9455e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6845e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 906/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 3.9428e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6820e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 907/1000\n",
            "250/250 [==============================] - 0s 213us/sample - loss: 3.9401e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6795e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 908/1000\n",
            "250/250 [==============================] - 0s 225us/sample - loss: 3.9374e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6769e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 909/1000\n",
            "250/250 [==============================] - 0s 224us/sample - loss: 3.9347e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6744e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 910/1000\n",
            "250/250 [==============================] - 0s 225us/sample - loss: 3.9320e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6719e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 911/1000\n",
            "250/250 [==============================] - 0s 213us/sample - loss: 3.9293e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6693e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 912/1000\n",
            "250/250 [==============================] - 0s 210us/sample - loss: 3.9266e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6668e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 913/1000\n",
            "250/250 [==============================] - 0s 218us/sample - loss: 3.9240e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6643e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 914/1000\n",
            "250/250 [==============================] - 0s 220us/sample - loss: 3.9213e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6618e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 915/1000\n",
            "250/250 [==============================] - 0s 214us/sample - loss: 3.9186e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6593e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 916/1000\n",
            "250/250 [==============================] - 0s 227us/sample - loss: 3.9160e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6568e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 917/1000\n",
            "250/250 [==============================] - 0s 229us/sample - loss: 3.9133e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6543e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 918/1000\n",
            "250/250 [==============================] - 0s 219us/sample - loss: 3.9106e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6517e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 919/1000\n",
            "250/250 [==============================] - 0s 201us/sample - loss: 3.9080e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6492e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 920/1000\n",
            "250/250 [==============================] - 0s 258us/sample - loss: 3.9053e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6467e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 921/1000\n",
            "250/250 [==============================] - 0s 218us/sample - loss: 3.9027e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6443e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 922/1000\n",
            "250/250 [==============================] - 0s 218us/sample - loss: 3.9000e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6418e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 923/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 3.8974e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6393e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 924/1000\n",
            "250/250 [==============================] - 0s 225us/sample - loss: 3.8948e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6368e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 925/1000\n",
            "250/250 [==============================] - 0s 262us/sample - loss: 3.8921e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6343e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 926/1000\n",
            "250/250 [==============================] - 0s 237us/sample - loss: 3.8895e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6318e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 927/1000\n",
            "250/250 [==============================] - 0s 230us/sample - loss: 3.8868e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6293e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 928/1000\n",
            "250/250 [==============================] - 0s 271us/sample - loss: 3.8842e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6269e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 929/1000\n",
            "250/250 [==============================] - 0s 229us/sample - loss: 3.8816e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6244e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 930/1000\n",
            "250/250 [==============================] - 0s 227us/sample - loss: 3.8790e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6219e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 931/1000\n",
            "250/250 [==============================] - 0s 217us/sample - loss: 3.8764e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6195e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 932/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 3.8738e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6170e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 933/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 3.8711e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6145e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 934/1000\n",
            "250/250 [==============================] - 0s 224us/sample - loss: 3.8685e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6121e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 935/1000\n",
            "250/250 [==============================] - 0s 221us/sample - loss: 3.8659e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6096e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 936/1000\n",
            "250/250 [==============================] - 0s 219us/sample - loss: 3.8633e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6072e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 937/1000\n",
            "250/250 [==============================] - 0s 218us/sample - loss: 3.8607e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6047e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 938/1000\n",
            "250/250 [==============================] - 0s 229us/sample - loss: 3.8581e-05 - tanh_accuracy: 1.0000 - val_loss: 3.6023e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 939/1000\n",
            "250/250 [==============================] - 0s 219us/sample - loss: 3.8555e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5999e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 940/1000\n",
            "250/250 [==============================] - 0s 211us/sample - loss: 3.8529e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5974e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 941/1000\n",
            "250/250 [==============================] - 0s 217us/sample - loss: 3.8504e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5950e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 942/1000\n",
            "250/250 [==============================] - 0s 209us/sample - loss: 3.8478e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5926e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 943/1000\n",
            "250/250 [==============================] - 0s 246us/sample - loss: 3.8452e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5902e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 944/1000\n",
            "250/250 [==============================] - 0s 225us/sample - loss: 3.8427e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5877e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 945/1000\n",
            "250/250 [==============================] - 0s 227us/sample - loss: 3.8401e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5853e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 946/1000\n",
            "250/250 [==============================] - 0s 224us/sample - loss: 3.8376e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5829e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 947/1000\n",
            "250/250 [==============================] - 0s 221us/sample - loss: 3.8350e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5805e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 948/1000\n",
            "250/250 [==============================] - 0s 245us/sample - loss: 3.8324e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5781e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 949/1000\n",
            "250/250 [==============================] - 0s 230us/sample - loss: 3.8299e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5757e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 950/1000\n",
            "250/250 [==============================] - 0s 224us/sample - loss: 3.8273e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5733e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 951/1000\n",
            "250/250 [==============================] - 0s 223us/sample - loss: 3.8248e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5709e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 952/1000\n",
            "250/250 [==============================] - 0s 241us/sample - loss: 3.8222e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5685e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 953/1000\n",
            "250/250 [==============================] - 0s 238us/sample - loss: 3.8197e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5661e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 954/1000\n",
            "250/250 [==============================] - 0s 208us/sample - loss: 3.8171e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5637e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 955/1000\n",
            "250/250 [==============================] - 0s 211us/sample - loss: 3.8146e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5613e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 956/1000\n",
            "250/250 [==============================] - 0s 213us/sample - loss: 3.8120e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5589e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 957/1000\n",
            "250/250 [==============================] - 0s 211us/sample - loss: 3.8095e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5565e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 958/1000\n",
            "250/250 [==============================] - 0s 201us/sample - loss: 3.8070e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5541e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 959/1000\n",
            "250/250 [==============================] - 0s 206us/sample - loss: 3.8044e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5518e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 960/1000\n",
            "250/250 [==============================] - 0s 216us/sample - loss: 3.8019e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5494e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 961/1000\n",
            "250/250 [==============================] - 0s 228us/sample - loss: 3.7994e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5470e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 962/1000\n",
            "250/250 [==============================] - 0s 222us/sample - loss: 3.7969e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5446e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 963/1000\n",
            "250/250 [==============================] - 0s 214us/sample - loss: 3.7944e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5423e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 964/1000\n",
            "250/250 [==============================] - 0s 229us/sample - loss: 3.7919e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5399e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 965/1000\n",
            "250/250 [==============================] - 0s 217us/sample - loss: 3.7894e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5376e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 966/1000\n",
            "250/250 [==============================] - 0s 230us/sample - loss: 3.7869e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5352e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 967/1000\n",
            "250/250 [==============================] - 0s 224us/sample - loss: 3.7844e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5329e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 968/1000\n",
            "250/250 [==============================] - 0s 203us/sample - loss: 3.7819e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5305e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 969/1000\n",
            "250/250 [==============================] - 0s 211us/sample - loss: 3.7794e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5282e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 970/1000\n",
            "250/250 [==============================] - 0s 212us/sample - loss: 3.7769e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5259e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 971/1000\n",
            "250/250 [==============================] - 0s 223us/sample - loss: 3.7745e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5235e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 972/1000\n",
            "250/250 [==============================] - 0s 209us/sample - loss: 3.7720e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5212e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 973/1000\n",
            "250/250 [==============================] - 0s 206us/sample - loss: 3.7695e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5189e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 974/1000\n",
            "250/250 [==============================] - 0s 215us/sample - loss: 3.7670e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5165e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 975/1000\n",
            "250/250 [==============================] - 0s 220us/sample - loss: 3.7646e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5142e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 976/1000\n",
            "250/250 [==============================] - 0s 228us/sample - loss: 3.7621e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5119e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 977/1000\n",
            "250/250 [==============================] - 0s 222us/sample - loss: 3.7596e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5096e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 978/1000\n",
            "250/250 [==============================] - 0s 241us/sample - loss: 3.7572e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5072e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 979/1000\n",
            "250/250 [==============================] - 0s 234us/sample - loss: 3.7547e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5049e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 980/1000\n",
            "250/250 [==============================] - 0s 259us/sample - loss: 3.7523e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5026e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 981/1000\n",
            "250/250 [==============================] - 0s 236us/sample - loss: 3.7498e-05 - tanh_accuracy: 1.0000 - val_loss: 3.5003e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 982/1000\n",
            "250/250 [==============================] - 0s 250us/sample - loss: 3.7474e-05 - tanh_accuracy: 1.0000 - val_loss: 3.4980e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 983/1000\n",
            "250/250 [==============================] - 0s 226us/sample - loss: 3.7449e-05 - tanh_accuracy: 1.0000 - val_loss: 3.4957e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 984/1000\n",
            "250/250 [==============================] - 0s 237us/sample - loss: 3.7425e-05 - tanh_accuracy: 1.0000 - val_loss: 3.4934e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 985/1000\n",
            "250/250 [==============================] - 0s 220us/sample - loss: 3.7400e-05 - tanh_accuracy: 1.0000 - val_loss: 3.4911e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 986/1000\n",
            "250/250 [==============================] - 0s 227us/sample - loss: 3.7376e-05 - tanh_accuracy: 1.0000 - val_loss: 3.4888e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 987/1000\n",
            "250/250 [==============================] - 0s 243us/sample - loss: 3.7352e-05 - tanh_accuracy: 1.0000 - val_loss: 3.4865e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 988/1000\n",
            "250/250 [==============================] - 0s 242us/sample - loss: 3.7328e-05 - tanh_accuracy: 1.0000 - val_loss: 3.4842e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 989/1000\n",
            "250/250 [==============================] - 0s 238us/sample - loss: 3.7303e-05 - tanh_accuracy: 1.0000 - val_loss: 3.4819e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 990/1000\n",
            "250/250 [==============================] - 0s 232us/sample - loss: 3.7278e-05 - tanh_accuracy: 1.0000 - val_loss: 3.4796e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 991/1000\n",
            "250/250 [==============================] - 0s 224us/sample - loss: 3.7254e-05 - tanh_accuracy: 1.0000 - val_loss: 3.4773e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 992/1000\n",
            "250/250 [==============================] - 0s 243us/sample - loss: 3.7230e-05 - tanh_accuracy: 1.0000 - val_loss: 3.4751e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 993/1000\n",
            "250/250 [==============================] - 0s 207us/sample - loss: 3.7206e-05 - tanh_accuracy: 1.0000 - val_loss: 3.4728e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 994/1000\n",
            "250/250 [==============================] - 0s 226us/sample - loss: 3.7182e-05 - tanh_accuracy: 1.0000 - val_loss: 3.4705e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 995/1000\n",
            "250/250 [==============================] - 0s 226us/sample - loss: 3.7158e-05 - tanh_accuracy: 1.0000 - val_loss: 3.4683e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 996/1000\n",
            "250/250 [==============================] - 0s 219us/sample - loss: 3.7133e-05 - tanh_accuracy: 1.0000 - val_loss: 3.4660e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 997/1000\n",
            "250/250 [==============================] - 0s 229us/sample - loss: 3.7109e-05 - tanh_accuracy: 1.0000 - val_loss: 3.4637e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 998/1000\n",
            "250/250 [==============================] - 0s 264us/sample - loss: 3.7085e-05 - tanh_accuracy: 1.0000 - val_loss: 3.4615e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 999/1000\n",
            "250/250 [==============================] - 0s 229us/sample - loss: 3.7062e-05 - tanh_accuracy: 1.0000 - val_loss: 3.4592e-05 - val_tanh_accuracy: 1.0000\n",
            "Epoch 1000/1000\n",
            "250/250 [==============================] - 0s 217us/sample - loss: 3.7038e-05 - tanh_accuracy: 1.0000 - val_loss: 3.4570e-05 - val_tanh_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr2hm9-SMbL7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CSVログ出力ファイルをダウンロード\n",
        "from google.colab import files\n",
        "files.download('training.log')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwX4x2a6XPyJ",
        "colab_type": "text"
      },
      "source": [
        "## ■⑧テスト： 未知データで推論と評価"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2igjG_3aqTC",
        "colab_type": "text"
      },
      "source": [
        "### リスト8-1　未知データによるテスト（推論と評価）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9L2DvJDlozl",
        "colab_type": "code",
        "outputId": "41a51e95-f170-4792-8345-140de3d5b58a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "import plygdata as pg\n",
        "import numpy as np\n",
        "\n",
        "# 未知のテストデータを生成\n",
        "PROBLEM_DATA_TYPE = pg.DatasetType.ClassifyTwoGaussData\n",
        "TEST_DATA_RATIO = 1.0  # データの何％を訓練【Training】用に？ (残りは精度検証【Validation】用) ： 100％\n",
        "DATA_NOISE = 0.0       # ノイズ： 0％\n",
        "data_list = pg.generate_data(PROBLEM_DATA_TYPE, DATA_NOISE)\n",
        "X_test, y_test, _, _ = pg.split_data(data_list, training_size=TEST_DATA_RATIO)\n",
        "\n",
        "# 学習済みモデルを使って推論\n",
        "result_proba = model.predict(X_test)\n",
        "result_class = np.frompyfunc(lambda x: 1 if (x >= 0.0) else -1, 1, 1)(result_proba) # 離散化\n",
        "# それぞれ5件ずつ出力\n",
        "print('proba:'); print(result_proba[:5])  # 予測\n",
        "print('class:'); print(result_class[:5])  # 分類\n",
        "\n",
        "# 未知のテストデータで学習済みモデルの汎化性能を評価\n",
        "score = model.evaluate(X_test, y_test)\n",
        "print('test loss:', score[0])  # 損失\n",
        "print('test acc:', score[1])   # 正解率"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "proba:\n",
            "[[-0.9952776 ]\n",
            " [ 0.99479544]\n",
            " [-0.9930786 ]\n",
            " [ 0.99473053]\n",
            " [-0.9950487 ]]\n",
            "class:\n",
            "[[-1]\n",
            " [1]\n",
            " [-1]\n",
            " [1]\n",
            " [-1]]\n",
            "\r500/1 [========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 36us/sample - loss: 3.6668e-05 - tanh_accuracy: 1.0000\n",
            "test loss: 3.6791478982195257e-05\n",
            "test acc: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhwqkgxTfwoa",
        "colab_type": "text"
      },
      "source": [
        "## ■おまけ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyIh_i_Jfx79",
        "colab_type": "text"
      },
      "source": [
        "### リスト9-1　ニューラルネットワーク内の重みやバイアスを調べるためのサンプルコード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSAKki03vMg3",
        "colab_type": "code",
        "outputId": "3d27bf4e-dec8-4d37-83a9-6d2afeb8fcb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "start_index = 0 # Sequential（積層型）モデルの場合は、0スタート\n",
        "#start_index = 1 # Functional（関数型）APIの場合は、0が入力層になっているので注意\n",
        "\n",
        "\n",
        "# 隠れ層1\n",
        "hidden1_layer = model.layers[start_index]\n",
        "print(' 隠れ層1：',hidden1_layer.name)\n",
        "hidden1_weights =  hidden1_layer.get_weights()\n",
        "print(hidden1_weights)\n",
        "# weights = hidden1_weights[0]\n",
        "h1_w1 = hidden1_weights[0][0, 0]\n",
        "h1_w2 = hidden1_weights[0][1, 0]\n",
        "# biases = hidden1_weights[1]\n",
        "h1_b = hidden1_weights[1][0]\n",
        "# 一部を出力\n",
        "print('h1_w1=',h1_w1)\n",
        "print('h1_w2=',h1_w2)\n",
        "print('h1_b=',h1_b)\n",
        "print()\n",
        "\n",
        "# 中間レイヤーにおける出力例\n",
        "print(' 隠れ層1の出力')\n",
        "test_data = np.array([[0.4, 3.2], [5.8, 3.1], [-5.8, -3.1]], dtype=np.float32)\n",
        "intermediate1_model = tf.keras.models.Model(inputs=model.input, outputs=hidden1_layer.output)\n",
        "intermediate1_output = intermediate1_model.predict(test_data)\n",
        "print(intermediate1_output)\n",
        "print()\n",
        "\n",
        "\n",
        "# 隠れ層2\n",
        "hidden2_layer = model.layers[start_index+1]\n",
        "print(' 隠れ層2：',hidden2_layer.name)\n",
        "hidden2_weights =  hidden2_layer.get_weights()\n",
        "print(hidden2_weights)\n",
        "# weights = hidden2_weights[0]\n",
        "h2_w1 = hidden2_weights[0][0, 0]\n",
        "h2_w2 = hidden2_weights[0][1, 0]\n",
        "# biases = hidden2_weights[1]\n",
        "h2_b = hidden2_weights[1][0]\n",
        "# 一部を出力\n",
        "print('h2_w1=',h2_w1)\n",
        "print('h2_w2=',h2_w2)\n",
        "print('h2_b=',h2_b)\n",
        "print()\n",
        "\n",
        "# 中間レイヤーにおける出力例\n",
        "print(' 隠れ層2の出力')\n",
        "test_data = np.array([[0.4, 3.2], [5.8, 3.1], [-5.8, -3.1]], dtype=np.float32)\n",
        "intermediate2_model = tf.keras.models.Model(inputs=model.input, outputs=hidden2_layer.output)\n",
        "intermediate2_output = intermediate2_model.predict(test_data)\n",
        "print(intermediate2_output)\n",
        "print()\n",
        "\n",
        "\n",
        "# 出力層\n",
        "output_layer = model.layers[start_index+2]\n",
        "print(' 出力層：',output_layer.name)\n",
        "output_weights =  output_layer.get_weights()\n",
        "print(output_weights)\n",
        "# weights = output_weights[0]\n",
        "o_w1 = output_weights[0][0, 0]\n",
        "o_w2 = output_weights[0][1, 0]\n",
        "# biases = output_weights[1]\n",
        "o_b = output_weights[1][0]\n",
        "# 一部を出力\n",
        "print('o_w1=',o_w1)\n",
        "print('o_w2=',o_w2)\n",
        "print('o_b=',o_b)\n",
        "print()\n",
        "\n",
        "# 出力レイヤーにおける出力例\n",
        "print('出力層の出力＝モデル全体の出力')\n",
        "output_model = tf.keras.models.Model(inputs=model.input, outputs=output_layer.output)\n",
        "output_output = output_model.predict(test_data)\n",
        "print(output_output)\n",
        "print()\n",
        "\n",
        "print('モデル全体の出力')\n",
        "test_data = np.array([[0.4, 3.2], [5.8, 3.1], [-5.8, -3.1]], dtype=np.float32)\n",
        "result = model.predict(test_data)\n",
        "print(result)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 隠れ層1： dense\n",
            "[array([[ 0.48216328, -0.7935021 , -0.6165635 ],\n",
            "       [ 0.8823196 , -0.51038545,  0.7070052 ]], dtype=float32), array([-0.02397198,  0.02960116,  0.0038539 ], dtype=float32)]\n",
            "h1_w1= 0.48216328\n",
            "h1_w2= 0.8823196\n",
            "h1_b= -0.023971979\n",
            "\n",
            " 隠れ層1の出力\n",
            "[[ 0.99497837 -0.95800227  0.9653895 ]\n",
            " [ 0.9999672  -0.99999106 -0.88106275]\n",
            " [-0.9999702   0.99999195  0.8827756 ]]\n",
            "\n",
            " 隠れ層2： dense_1\n",
            "[array([[ 0.23945466, -0.52975863,  0.6633203 ],\n",
            "       [-0.81996644,  0.22503906, -1.514059  ],\n",
            "       [-0.11152942, -1.0818968 ,  0.5646103 ]], dtype=float32), array([-0.00509438, -0.00965274, -0.03851714], dtype=float32)]\n",
            "h2_w1= 0.23945466\n",
            "h2_w2= -0.81996644\n",
            "h2_b= -0.0050943843\n",
            "\n",
            " 隠れ層2の出力\n",
            "[[ 0.7216206  -0.94647264  0.9893925 ]\n",
            " [ 0.81860566  0.18657652  0.92766374]\n",
            " [-0.8220012  -0.20691358 -0.937554  ]]\n",
            "\n",
            " 出力層： dense_2\n",
            "[array([[ 0.9164784 ],\n",
            "       [-0.20014854],\n",
            "       [ 2.165541  ]], dtype=float32), array([-0.01153944], dtype=float32)]\n",
            "o_w1= 0.9164784\n",
            "o_w2= -0.20014854\n",
            "o_b= -0.011539436\n",
            "\n",
            "出力層の出力＝モデル全体の出力\n",
            "[[ 0.99487203]\n",
            " [ 0.9911891 ]\n",
            " [-0.9919208 ]]\n",
            "\n",
            "モデル全体の出力\n",
            "[[ 0.99487203]\n",
            " [ 0.9911891 ]\n",
            " [-0.9919208 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5KufJ89cs2d",
        "colab_type": "text"
      },
      "source": [
        "# お疲れさまでした。『ニューラルネットワーク、仕組みの理解×初めての実装』は修了です。"
      ]
    }
  ]
}